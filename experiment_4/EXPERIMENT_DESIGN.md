# Experiment 4: 動的グラフ成長を伴うRAG実験

## 実験目的
experiment_1と同じ目標を、今度は**グラフも動的に成長させながら**実現する：
1. 動的RAGの埋め込み実験（エピソードとグラフ両方の成長）
2. 1000件以上のデータセットでの大規模実験
3. 実際の圧縮率評価
4. ベースラインRAGシステムとの比較

## 重要な発見に基づく実装
- グラフを成長させるには、`analyze_documents()`に**累積的に全ドキュメント**を渡す必要がある
- 各エピソード追加時に全ドキュメントリストを維持し、グラフを再構築する

## 実験計画

### Phase 1: 動的グラフ成長の実証
1. クリーンな状態から開始（5エピソード、1ノード）
2. 100件のドキュメントを追加
3. 各追加でグラフノードも成長することを確認
4. エピソード数とグラフノード数の相関を分析

### Phase 2: 大規模データセット実験
1. 1000件の多様なテキストデータを生成
2. バッチ処理で効率的に追加
3. グラフ成長のパフォーマンスを測定
4. メモリ使用量とファイルサイズを追跡

### Phase 3: 圧縮効率の評価
1. 生テキストサイズ vs 保存サイズを比較
2. グラフ構造による追加的な圧縮効果を測定
3. エピソード統合による効率化を定量化

### Phase 4: ベースラインRAGとの比較
1. 標準FAISS RAGシステムを実装
2. 同じデータセットで性能比較
3. 検索精度、速度、メモリ効率を評価

## 成功基準
- [ ] グラフが1ノードから100+ノードに成長
- [ ] 1000件のドキュメントを正常に処理
- [ ] 圧縮率の実測値を取得
- [ ] ベースラインRAGとの定量的比較完了

## 技術的実装のポイント

### 累積ドキュメント管理
```python
all_documents = []  # 全ドキュメントを追跡

for text in texts:
    # エピソード追加
    result = agent.add_episode_with_graph_update(text)
    
    # ドキュメントをリストに追加
    doc = {
        "text": text,
        "embedding": result['vector'],
        "c_value": result['c_value']
    }
    all_documents.append(doc)
    
    # 全ドキュメントでグラフを更新
    agent.l3_graph.analyze_documents(all_documents)
```

### メトリクス収集
- エピソード数の推移
- グラフノード数の推移
- ファイルサイズの推移
- 処理時間の測定
- メモリ使用量の監視

## 期待される成果
1. グラフとエピソードの同期的成長の実証
2. 大規模データでのスケーラビリティ確認
3. 実用的な圧縮率の測定
4. InsightSpike-AIの優位性の定量化