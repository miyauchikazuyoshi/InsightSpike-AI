# InsightSpike-AI
**Brain-Inspired Multi-Agent Architecture for â€œSpike of Insightâ€ (Î”GED Ã— Î”IG)**  

> Quantized RAG ï¼‹ GNN ï¼‹ Internal Reward (Î”GED/Î”IG)  
> Implementing a cerebellumâ€“LCâ€“hippocampusâ€“VTA loop to study *insight*.

[![License: InsightSpike Community License](https://img.shields.io/badge/License-InsightSpike--Community--1.0-blue)](https://github.com/miyauchikazuyoshi/InsightSpike-AI/blob/main/LICENSE)  
<a href="https://arxiv.org/abs/YYMM.NNNNN"><img src="https://img.shields.io/badge/arXiv-YYMM.NNNNN-b31b1b.svg" alt="arXiv"></a>  
<a href="https://github.com/miyauchikazuyoshi/InsightSpike-AI/releases"><img src="https://img.shields.io/github/v/release/miyauchikazuyoshi/InsightSpike-AI"></a>

## Patent Notice
The core Î”GED/Î”IG intrinsic-reward mechanism and the hierarchical VQ memory module
are **patent-pending** in Japan.

- JP Application No. **ç‰¹é¡˜2025-082988** â€” â€œÎ”GED/Î”IG å†…ç™ºå ±é…¬ç”Ÿæˆæ–¹æ³•â€
- JP Application No. **ç‰¹é¡˜2025-082989** â€” â€œéšå±¤ãƒ™ã‚¯ãƒˆãƒ«é‡å­åŒ–ã«ã‚ˆã‚‹å‹•çš„ãƒ¡ãƒ¢ãƒªæ–¹æ³•â€

<br> Further filings (US/PCT) will follow within the priority year.

---

### âœ¨ Features
* **Î”GED** â€“ Graph-edit distance between successive RAG search graphs  
* **Î”IG** â€“ Entropy gain from*

## âœ¨ Why
Human â€œaha!â€ moments often arise from abrupt structural re-arrangements of episodic memory.  
InsightSpike-AI models this process and exposes the *spike* as an internal reward signal.

## ğŸ§  Architecture (Enhanced v0.7-Eureka)

**Layer1: Enhanced Known/Unknown Information Separation**  
- ğŸ“‹ Intelligent query analysis and concept extraction
- ğŸ¯ Automatic synthesis requirement detection  
- ğŸ”„ Adaptive topK optimization for chain reaction insights
- ğŸ§  Human-like learning system with weak relationship formation

**Layer2: Quantum-RAG + C-value Memory (Faiss)**  
- ğŸ“š Vector quantized episodic memory with IVF-PQ
- ğŸ” Adaptive retrieval with Layer1-optimized topK values

**Layer3: GNN + Î”GED/Î”IG + Conflict Score**  
- ğŸ•¸ï¸ Graph neural network reasoning with PyTorch Geometric
- ğŸ“Š Î”GED/Î”IG metrics for insight spike detection
- âš¡ Enhanced graph density for chain reaction insights

**Layer4: LLM Interface**  
- ğŸ—£ï¸ Natural language generation with TinyLlama
- ğŸ¨ Context-aware response synthesis

<!-- <p align="center"><img src="docs/diagram/overview_v0.png" width="70%"></p> -->

# InsightSpike AI (v0.7-Eureka)

Proofâ€‘ofâ€‘concept brainâ€‘inspired architecture with a 4â€‘layer subcortical loop.

| Layer | Brain analog  | Main file(s)                  |
|-------|---------------|-------------------------------|
| L1    | Cerebellum    | layer1_error_monitor.py       |
| L2    | LC + Hippocampus | layer2_memory_manager.py  |
| L3    | PFC           | layer3_graph_pyg.py,<br>layer3_reasoner_gnn.py |
| L4    | Language area | layer4_llm.py                 |

EurekaSpike fires when **Î”GED drops â‰¥ 0.5** *and* **Î”IG rises â‰¥ 0.2**.

---

## Quickâ€‘start (local)
```bash
git clone ...
cd InsightSpike-AI
chmod +x [setup.sh]
[setup.sh]
```

## ğŸš€ Quick Demo

Try the insight detection capabilities immediately:

```bash
# Clone and setup
git clone https://github.com/miyauchikazuyoshi/InsightSpike-AI.git
cd InsightSpike-AI

# Run interactive demo (no setup required)
poetry run insightspike demo
```

This demo showcases InsightSpike's ability to synthesize insights across domains like probability theory, mathematics, and philosophy - even when the knowledge base contains no direct answers to the questions!

## Quickâ€‘start on GoogleColab(GPU)
```bash
git clone https://github.com/miyauchikazuyoshi/InsightSpike-AI.git
cd InsightSpike-AI
chmod +x scripts/setup.sh
./scripts/setup.sh
```

### Development & PoC/Experiment Environment Setup
---
## ğŸš€ Quick Start

### ğŸ”§ Three-Environment Installation Strategy

InsightSpike-AI supports three distinct environments, each optimized for specific use cases:

#### ğŸ  Local Development Environment (faiss-cpu)
**Best for**: Development, testing, CPU-only machines
```bash
# Clone repository
git clone https://github.com/miyauchikazuyoshi/InsightSpike-AI.git
cd InsightSpike-AI

# Install dependencies for local development
poetry install --with dev

# Run CLI commands
poetry run insightspike loop "What is quantum entanglement?"
```

#### â˜ï¸ Google Colab Environment (faiss-gpu-cu12)
**Best for**: GPU acceleration, large-scale experiments, research
```bash
# Method 1: Enhanced setup script (recommended)
!git clone https://github.com/miyauchikazuyoshi/InsightSpike-AI.git
%cd InsightSpike-AI
!chmod +x scripts/colab/setup_colab.sh
!bash scripts/colab/setup_colab.sh

# Method 2: Use pre-configured notebook
# Open: InsightSpike_Colab_Demo.ipynb
```

#### ğŸ”§ CI/Testing Environment (minimal dependencies)
**Best for**: Continuous integration, automated testing
```bash
# Minimal installation for CI
pip install pytest numpy pyyaml networkx scikit-learn psutil faiss-cpu typer rich click
pip install -e .
export INSIGHTSPIKE_LITE_MODE=1

# Run tests
python -m pytest development/tests/unit/ -v
```

### ğŸ“¦ Dependency Strategy
- **`dev`**: Local development with faiss-cpu, full testing suite
- **`colab`**: Google Colab optimized with faiss-gpu priority installation
- **`ci`**: Minimal dependencies for fast CI/CD pipelines

**Key Innovation**: Our setup prioritizes faiss-gpu installation in Colab before Poetry operations, ensuring GPU acceleration while maintaining compatibility across all environments.

For development, PoC, or experiments, please make sure to install all dependencies including dev packages:
```poetry install --with dev```

This ensures packages like matplotlib (for visualization) and pytest (for testing) are available.
When running `run_poc.py` offline, set the environment variable `EMBED_MODEL_PATH` to a locally downloaded SentenceTransformer model directory.

### Docker
---
The included `Dockerfile` is based on `pytorch/pytorch:2.2.0-cuda12.1-cudnn8-runtime`. It installs dependencies from `pyproject.toml` using Poetry, and then installs additional packages such as `torch-geometric` via `pip`. Note that local scripts use `torch==2.2.2`, so be aware of version differences. The base image uses **Python 3.10**, which differs from the Python 3.11 series required in `pyproject.toml`. Also, after installing `faiss-cpu` with Poetry, `faiss-gpu-cu11` is added; if you do not need the CPU version, please uninstall it.

## Minimal Working Example

```bash
# 1. Clone and set up environment
git clone https://github.com/miyauchikazuyoshi/InsightSpike-AI.git
cd InsightSpike-AI
chmod +x scripts/colab_setup.sh
./scripts/setup.sh
!chmod +x scripts/databake.py
!chmod +x scripts/run_poc.py

# 2. Prepare data (download & vectorize Wikipedia sentences)
poetry run python scripts/databake.py

# 3. Embed your own corpus (Specify any text file)
# Example: Convert data/raw/your_corpus.txt into episodic memory
# *Note: Each line in the text file is treated as a separate document.*
poetry run insightspike embed --path data/raw/your_corpus.txt

# 4. Build similarity graph
poetry run insightspike graph

# 5. Run a reasoning loop with a sample question
poetry run insightspike loop "What is quantum entanglement?"

# 6. Run the PoC pipeline (with visualization)
poetry run python scripts/run_poc.py
```

---

## CLI Commands

| Command                                      | Description                                                                                 |
|-----------------------------------------------|--------------------------------------------------------------------------------------------|
| `poetry run insightspike ask "question"`      | Ask a question using the new MainAgent architecture                                        |
| `poetry run insightspike demo`                | **Run interactive demo of insight detection capabilities**                             |
| `poetry run insightspike load_documents <path>` | Load documents into the agent's memory from file or directory                            |
| `poetry run insightspike stats`               | Show agent and memory statistics                                                           |
| `poetry run insightspike config_info`         | Display current configuration settings                                                      |
| `poetry run insightspike true_insight`        | **Run rigorous insight detection experiment (no direct answers)**                     |
| `poetry run insightspike compare_experiments` | **Compare different experimental designs (direct vs insight)**                        |
| `poetry run insightspike experiment_suite`    | **Run complete experimental validation suite with multiple experiment types**              |
| `poetry run insightspike experiment`          | **Run complete experimental validation suite** *(Legacy - use experiment_suite)*           |
| `poetry run insightspike benchmark [--dataset]` | **Run performance benchmarks (simple/enhanced/custom)**                                  |
| `poetry run insightspike embed --path <file>` | *(Legacy)* Embed a text corpus and save episodic memory                                   |
| `poetry run insightspike query "question"`    | *(Legacy)* Run one L1-L4 reasoning cycle                                                   |
| `poetry run databake`                         | Download 10,000 Wikipedia sentences, vectorize, and index with faiss                      |
| `poetry run run-poc`                          | Run the full PoC pipeline with visualization and logging                                   |

---

## Common Errors & Troubleshooting

| Error Message                                      | Cause / Solution                                                                                 |
|----------------------------------------------------|--------------------------------------------------------------------------------------------------|
| `ModuleNotFoundError: No module named 'matplotlib'`| Run `poetry install` to include dev dependencies, or add `matplotlib` to your environment.       |
| `FileNotFoundError: ... episodic memory ...`       | Run `poetry run insightspike embed` or `poetry run databake` to generate the required data files.|
| `torch version mismatch`                           | Ensure Docker and local environments use the same torch version (see Dockerfile notes).          |
| `CUDA not available`                               | If running on CPU, make sure to use CPU versions of torch/faiss; for GPU, check CUDA drivers.    |
| `RuntimeError: Failed to load embedding model`     | Pre-download the SentenceTransformer model and set `EMBED_MODEL_PATH` to its directory.           |

---

## Data Preparation & Preprocessing

To obtain 10,000 sentences from Wikipedia, save them in `data/raw/`, vectorize them using sentence-transformers, and index them with faiss:

```bash
poetry run databake
```

## PoC (Proof of Concept) Usage

To run the PoC pipeline after data preparation, follow these steps:

1. **Start the main process**  
    Run the main script to launch the multi-agent architecture:
    ```bash
    poetry run run-poc
    ```

2. **Monitor outputs**  
    Results, logs, and EurekaSpike events will be saved in the `outputs/` directory.

3. **Experiment with parameters**  
    You can adjust parameters such as thresholds for Î”GED and Î”IG in the configuration files (e.g., `config.yaml`) to observe different behaviors.

For detailed experiments or custom runs, refer to the scripts in the `experiments/` directory.

---

## ğŸ§ª Experimental Validation

InsightSpike-AI has been rigorously tested through controlled experiments demonstrating its effectiveness in detecting cognitive insights and improving response quality through two distinct experimental frameworks.

### Insight Detection Experiment Results (Rigorous Validation)

**ğŸ¯ Breakthrough: 108.3% improvement in synthesis tasks requiring genuine cross-domain reasoning**

- **âœ… 83.3% response quality** vs 40.0% baseline (108.3% improvement)
- **âœ… 66.7% synthesis rate** vs 0% baseline (successful cross-domain connections)  
- **âœ… 4/6 successful insight syntheses** on questions with NO direct answers in knowledge base
- **âœ… Insight detection** validates genuine reasoning rather than mere information retrieval

### Traditional Experiment Results (Legacy Framework)

- **âœ… 133.3% improvement** in response quality over baseline systems
- **âœ… 100% insight detection rate** on cognitive paradoxes (Monty Hall, Zeno's, Ship of Theseus)
- **âœ… 0% false positive rate** on control questions
- **âœ… 287x faster processing** than baseline approaches

### Running New Experimental Framework

```bash
# Run rigorous insight experiment (no direct answers in knowledge base)
poetry run insightspike true_insight

# Compare experimental designs (traditional vs insight)
poetry run insightspike compare_experiments

# Run complete validation suite with multiple experiment types
poetry run insightspike experiment_suite

# Legacy experiments
poetry run python scripts/databake_simple.py
poetry run python scripts/run_poc_simple.py
```

### Experimental Framework Design

InsightSpike-AI uses two complementary experimental approaches to validate its insight detection capabilities:

#### ğŸ¯ Insight Experiments (Rigorous Validation)
**Revolutionary experimental design with NO direct answers in knowledge base**

- **Indirect Knowledge Base**: 57 facts containing only related concepts, NOT direct answers
- **Synthesis-Required Questions**: 6 questions requiring genuine cross-domain reasoning
- **Examples**: Monty Hall (probability + information theory), Zeno's paradox (calculus + motion), Ship of Theseus (philosophy + practical criteria)
- **Validation**: Tests true synthesis capability rather than information retrieval

#### ğŸ“Š Traditional Experiments (Legacy Framework)
**Standard evaluation on cognitive paradoxes with complete knowledge base**

- **Direct Knowledge Base**: Contains answers alongside related information
- **Cognitive Paradoxes**: Monty Hall problem variations, mathematical paradoxes, philosophical questions
- **Validation**: Tests insight detection on known challenging problems

#### ğŸ”¬ Comparative Analysis
The experimental suite includes comparative analysis showing:
- **Insight experiments** eliminate confounding factors and validate genuine synthesis
- **Traditional experiments** demonstrate performance on standard cognitive challenges
- **Cross-validation** ensures robust insight detection across multiple domains

### Experimental Framework

The validation framework tests InsightSpike-AI across multiple cognitive domains:

- **Probability Paradoxes**: Monty Hall problem variations
- **Mathematical Paradoxes**: Zeno's paradox resolution  
- **Philosophical Paradoxes**: Ship of Theseus identity questions
- **Concept Hierarchies**: Mathematical abstraction levels
- **Conceptual Revolutions**: Physics paradigm shifts
- **Control Conditions**: Standard academic content

Results demonstrate that the Î”GED/Î”IG mechanism effectively identifies breakthrough moments in cognitive processing, validating the core hypothesis of spike-based insight detection.

ğŸ“„ **Full Reports**: 
- [`EXPERIMENTAL_VALIDATION_REPORT.md`](EXPERIMENTAL_VALIDATION_REPORT.md) - Traditional framework results
- [`COMPARATIVE_EXPERIMENTAL_ANALYSIS.md`](COMPARATIVE_EXPERIMENTAL_ANALYSIS.md) - Insight vs traditional comparison

---

## ğŸ¯ Layer1 Enhanced Features (v0.7-Eureka)

### Known/Unknown Information Separation
- **Concept Extraction**: Automatic identification of key concepts using regex and NLP
- **Certainty Analysis**: Context-based confidence scoring for concept familiarity  
- **Synthesis Detection**: Intelligent detection of queries requiring multi-concept synthesis

### Adaptive TopK Optimization  
- **Dynamic Scaling**: topK values scale 1.5x-6x based on query complexity
- **Chain Reaction Enablement**: Higher graph density for "é€£é–åå¿œçš„æ´å¯Ÿå‘ä¸Š"
- **Layer-Specific Tuning**: L1(20â†’50), L2(15â†’30), L3(12â†’25) adaptive scaling

### Human-Like Learning System
- **Weak Relationships**: Automatic registration of concept co-occurrences (confidence: 0.1)
- **Sleep-Mode Cleanup**: Background pruning of relationships below 0.15 confidence
- **Gradual Reinforcement**: +0.05 confidence boost per concept reappearance
- **Graph Explosion Prevention**: Maximum 1000 weak edges with natural pruning

### Integration Results
- âœ… **75% synthesis prediction accuracy** for Layer1 analysis
- âœ… **2.5x average topK scaling** for complex queries  
- âœ… **329 relationships learned** from 5 test questions
- âœ… **61.6% â†’ 84.1% chain reaction potential** scaling

---

## Makefile ã‚³ãƒãƒ³ãƒ‰ä¾‹
- `make test` ... ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- `make embed` ... ãƒ†ã‚¹ãƒˆç”¨Memoryç”Ÿæˆ
- `make clean` ... ãƒ†ã‚¹ãƒˆæˆæœç‰©ã®å‰Šé™¤

## .envãƒ•ã‚¡ã‚¤ãƒ«ã«ã¤ã„ã¦
- `PYTHONPATH=src` ãªã©ã€ç’°å¢ƒå¤‰æ•°ã‚’ä¸€å…ƒç®¡ç†ã§ãã¾ã™ã€‚
- å¿…è¦ã«å¿œã˜ã¦ `DATA_DIR` ã‚„ `API_KEY` ãªã©ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
