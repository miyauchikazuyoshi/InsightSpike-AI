#!/usr/bin/env python3
"""
çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../src')))

import numpy as np
import tempfile
from pathlib import Path

from insightspike.index import (
    IntegratedVectorGraphIndex,
    BackwardCompatibleWrapper,
    MigrationHelper
)
from insightspike.implementations.datastore.enhanced_filesystem_store import EnhancedFileSystemDataStore
from insightspike.config.index_config import IntegratedIndexConfig


class TestMainCodeIntegration:
    """ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰ã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    def test_enhanced_datastore_shadow_mode(self):
        """æ‹¡å¼µDataStoreã®ã‚·ãƒ£ãƒ‰ã‚¦ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ"""
        with tempfile.TemporaryDirectory() as tmpdir:
            # ã‚·ãƒ£ãƒ‰ã‚¦ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–
            config = {
                'use_integrated_index': True,
                'dimension': 128,
                'migration_mode': 'shadow'
            }
            
            store = EnhancedFileSystemDataStore(tmpdir, config)
            
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¿½åŠ 
            episodes = []
            for i in range(20):
                episode = {
                    'vec': list(np.random.randn(128)),
                    'text': f'Shadow mode episode {i}',
                    'c_value': 0.5 + i * 0.01
                }
                episodes.append(episode)
            
            # ä¿å­˜
            success = store.save_episodes(episodes)
            assert success
            
            # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
            query = np.random.randn(128)
            indices, scores = store.find_similar(query, k=5)
            assert len(indices) == 5
            
            # æ€§èƒ½çµ±è¨ˆç¢ºèª
            stats = store.get_performance_stats()
            assert stats['use_integrated_index'] is True
            assert stats['total_vectors'] == 20
    
    def test_migration_from_existing_store(self):
        """æ—¢å­˜DataStoreã‹ã‚‰ã®ç§»è¡Œãƒ†ã‚¹ãƒˆ"""
        with tempfile.TemporaryDirectory() as tmpdir:
            # 1. æ—¢å­˜å½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            old_store = EnhancedFileSystemDataStore(tmpdir, {'use_integrated_index': False})
            
            episodes = []
            for i in range(30):
                episode = {
                    'vec': list(np.random.randn(64)),
                    'text': f'Legacy episode {i}',
                    'timestamp': i
                }
                episodes.append(episode)
            
            old_store.save_episodes(episodes)
            
            # 2. çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ç§»è¡Œ
            new_index = IntegratedVectorGraphIndex(dimension=64)
            stats = MigrationHelper.migrate_from_filesystem_store(
                tmpdir, new_index
            )
            
            assert stats['episodes_migrated'] == 30
            assert len(stats['errors']) == 0
            
            # 3. æ¤œè¨¼
            validation = MigrationHelper.validate_migration(tmpdir, new_index)
            assert validation['success']
            assert validation['episode_count_match']
            assert validation['search_functionality']
    
    def test_config_based_switching(self):
        """è¨­å®šãƒ™ãƒ¼ã‚¹ã®åˆ‡ã‚Šæ›¿ãˆãƒ†ã‚¹ãƒˆ"""
        with tempfile.TemporaryDirectory() as tmpdir:
            # åˆæœŸã¯çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç„¡åŠ¹
            store = EnhancedFileSystemDataStore(
                tmpdir, 
                {'use_integrated_index': False, 'dimension': 256}
            )
            
            # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
            episodes = [
                {'vec': list(np.random.randn(256)), 'text': f'Ep {i}'}
                for i in range(10)
            ]
            store.save_episodes(episodes)
            
            # çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆ‡ã‚Šæ›¿ãˆ
            store.switch_to_integrated_index(migrate_existing=True)
            
            # åˆ‡ã‚Šæ›¿ãˆå¾Œã®å‹•ä½œç¢ºèª
            query = np.random.randn(256)
            indices, scores = store.find_similar(query, k=3)
            assert len(indices) == 3
            
            stats = store.get_performance_stats()
            assert stats['use_integrated_index'] is True
            assert stats['total_vectors'] == 10
    
    def test_performance_comparison(self):
        """æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
        import time
        
        with tempfile.TemporaryDirectory() as tmpdir1, \
             tempfile.TemporaryDirectory() as tmpdir2:
            
            # ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¹ãƒˆã‚¢
            legacy_store = EnhancedFileSystemDataStore(
                tmpdir1, {'use_integrated_index': False}
            )
            
            # çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¹ãƒˆã‚¢
            integrated_store = EnhancedFileSystemDataStore(
                tmpdir2, {'use_integrated_index': True, 'dimension': 512}
            )
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            episodes = []
            for i in range(100):
                episode = {
                    'vec': list(np.random.randn(512)),
                    'text': f'Performance test {i}'
                }
                episodes.append(episode)
            
            # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
            legacy_store.save_episodes(episodes)
            integrated_store.save_episodes(episodes)
            
            # æ¤œç´¢æ€§èƒ½æ¸¬å®š
            query = np.random.randn(512)
            
            # ãƒ¬ã‚¬ã‚·ãƒ¼
            start = time.time()
            for _ in range(10):
                legacy_store.find_similar(query, k=10)
            legacy_time = (time.time() - start) / 10
            
            # çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            start = time.time()
            for _ in range(10):
                integrated_store.find_similar(query, k=10)
            integrated_time = (time.time() - start) / 10
            
            print(f"\næ€§èƒ½æ¯”è¼ƒ:")
            print(f"  ãƒ¬ã‚¬ã‚·ãƒ¼: {legacy_time*1000:.2f}ms")
            print(f"  çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {integrated_time*1000:.2f}ms")
            print(f"  é«˜é€ŸåŒ–: {legacy_time/integrated_time:.1f}x")
            
            # çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ–¹ãŒé«˜é€Ÿã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert integrated_time < legacy_time


def test_config_model():
    """è¨­å®šãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
    config = IntegratedIndexConfig(
        enabled=True,
        dimension=384,
        similarity_threshold=0.5,
        migration_mode="partial"
    )
    
    assert config.enabled is True
    assert config.dimension == 384
    assert config.similarity_threshold == 0.5
    assert config.migration_mode == "partial"
    
    # JSONå¤‰æ›ãƒ†ã‚¹ãƒˆ
    config_dict = config.dict()
    assert 'faiss_threshold' in config_dict
    assert config_dict['auto_save'] is True


if __name__ == "__main__":
    # å˜ä½“å®Ÿè¡Œ
    tester = TestMainCodeIntegration()
    
    print("=== çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰çµ±åˆãƒ†ã‚¹ãƒˆ ===\n")
    
    print("1. ã‚·ãƒ£ãƒ‰ã‚¦ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ...")
    tester.test_enhanced_datastore_shadow_mode()
    print("âœ… æˆåŠŸ")
    
    print("\n2. ç§»è¡Œãƒ†ã‚¹ãƒˆ...")
    tester.test_migration_from_existing_store()
    print("âœ… æˆåŠŸ")
    
    print("\n3. è¨­å®šåˆ‡ã‚Šæ›¿ãˆãƒ†ã‚¹ãƒˆ...")
    tester.test_config_based_switching()
    print("âœ… æˆåŠŸ")
    
    print("\n4. æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ...")
    tester.test_performance_comparison()
    print("âœ… æˆåŠŸ")
    
    print("\n5. è¨­å®šãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ...")
    test_config_model()
    print("âœ… æˆåŠŸ")
    
    print("\nğŸ‰ å…¨ã¦ã®ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰çµ±åˆãƒ†ã‚¹ãƒˆã«åˆæ ¼ï¼")