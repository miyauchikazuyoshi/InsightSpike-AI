# Google Colab configuration
models:
  device: "cuda"
  batch_size: 32
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"

memory:
  max_episodes: 10000
  top_k: 5

graph:
  gnn_hidden_dim: 256

loop:
  max_loops: 10
  timeout_seconds: 600

logging:
  log_level: "INFO"
  enable_wandb: false
  save_artifacts: true

debug: false
