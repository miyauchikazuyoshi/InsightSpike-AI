{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ODClagKES74",
        "outputId": "597b4747-9ee9-4b16-aefe-a4573a915a51"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# ğŸ”’ ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’Colabã§cloneã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
        "# ===========================\n",
        "\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "# â‘  GitHubãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒªãƒã‚¸ãƒˆãƒªåã‚’å…¥åŠ›\n",
        "GITHUB_USER = \"miyauchikazuyoshi\"\n",
        "REPO_NAME   = \"InsightSpike-AI\"\n",
        "\n",
        "# â‘¡ å€‹äººã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›ï¼ˆç”»é¢ã«ã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ï¼‰\n",
        "GITHUB_TOKEN = getpass('GitHub Personal Access Tokenã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ')\n",
        "REPO_URL = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git\"\n",
        "\n",
        "!git clone $REPO_URL\n",
        "\n",
        "#  cloneã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ï¼ˆå¿…è¦ãªã‚‰ï¼‰\n",
        "%cd $REPO_NAME\n",
        "\n",
        "# ä»¥é™ã¯é€šå¸¸é€šã‚Špythonã‚„notebookã‚’å®Ÿè¡Œ\n",
        "# ä¾‹: !python demo.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyVpcCL8Eu0x",
        "outputId": "65c04231-273e-428b-bb49-6a61e9918dde"
      },
      "outputs": [],
      "source": [
        "# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«å®Ÿè¡Œæ¨©é™ã‚’ä»˜ä¸\n",
        "!chmod +x scripts/colab/setup_colab.sh\n",
        "\n",
        "# ä½œæˆã—ãŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œï¼\n",
        "# ã“ã‚Œã§å¿…è¦ãªã‚‚ã®ãŒã™ã¹ã¦ã€æ­£ã—ã„é †ç•ªã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã™ã€‚\n",
        "!scripts/colab/setup_colab.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g3-fe5li6EJ",
        "outputId": "393ed28e-b7e0-4b46-eec2-3b86c05d6d86"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import platform\n",
        "import subprocess\n",
        "\n",
        "print(\"ğŸ” InsightSpike-AI System Diagnostic\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Environment info\n",
        "print(f\"ğŸ Python: {sys.version}\")\n",
        "print(f\"ğŸ’» Platform: {platform.platform()}\")\n",
        "print(f\"ğŸ“‚ Working Dir: {os.getcwd()}\")\n",
        "\n",
        "# Check if in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    print(\"â˜ï¸  Environment: Google Colab âœ…\")\n",
        "    in_colab = True\n",
        "except ImportError:\n",
        "    print(\"ğŸ’» Environment: Local/Other\")\n",
        "    in_colab = False\n",
        "\n",
        "# Memory info\n",
        "try:\n",
        "    import psutil\n",
        "    memory = psutil.virtual_memory()\n",
        "    print(f\"ğŸ’¾ RAM: {memory.total / 1e9:.1f} GB total, {memory.available / 1e9:.1f} GB available\")\n",
        "except ImportError:\n",
        "    print(\"ğŸ’¾ RAM: Memory info not available\")\n",
        "\n",
        "# GPU info with detailed status\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"\\nğŸ® GPU Status:\")\n",
        "    print(f\"   PyTorch: {torch.__version__}\")\n",
        "    print(f\"   CUDA Available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "        print(f\"   CUDA Version: {torch.version.cuda}\")\n",
        "    else:\n",
        "        print(\"   Mode: CPU only (fully functional)\")\n",
        "except ImportError:\n",
        "    print(\"\\nğŸ® PyTorch: Not installed âŒ\")\n",
        "\n",
        "# Configuration check\n",
        "print(f\"\\nâš™ï¸  Configuration Status:\")\n",
        "try:\n",
        "    from src.insightspike.core.config import LLMConfig\n",
        "    config = LLMConfig()\n",
        "    print(f\"   âœ… LLM Model: {config.model_name}\")\n",
        "    print(f\"   âœ… Temperature: {config.temperature}\")\n",
        "except Exception as e:\n",
        "    print(f\"   âŒ Configuration error: {str(e)[:50]}...\")\n",
        "\n",
        "# Package diagnostics - ä¿®æ­£ç‰ˆ\n",
        "print(f\"\\nğŸ“¦ Package Diagnostics:\")\n",
        "critical_packages = [\n",
        "    'torch', 'torch_geometric', 'faiss', 'sentence_transformers',\n",
        "    'networkx', 'transformers', 'numpy', 'sklearn'  # scikit_learn â†’ sklearn ã«ä¿®æ­£\n",
        "]\n",
        "\n",
        "installed_packages = []\n",
        "missing_packages = []\n",
        "\n",
        "for package in critical_packages:\n",
        "    try:\n",
        "        if package == 'sklearn':  # scikit_learn â†’ sklearn ã«ä¿®æ­£\n",
        "            import sklearn\n",
        "            version = sklearn.__version__\n",
        "            package_name = 'scikit-learn'  # è¡¨ç¤ºåã‚‚ä¿®æ­£\n",
        "        elif package == 'sentence_transformers':\n",
        "            import sentence_transformers\n",
        "            version = sentence_transformers.__version__\n",
        "            package_name = 'sentence_transformers'\n",
        "        elif package == 'faiss':\n",
        "            import faiss\n",
        "            version = getattr(faiss, '__version__', 'unknown')\n",
        "            package_name = 'faiss'\n",
        "        elif package == 'torch_geometric':\n",
        "            import torch_geometric\n",
        "            version = torch_geometric.__version__\n",
        "            package_name = 'torch_geometric'\n",
        "        else:\n",
        "            module = __import__(package)\n",
        "            version = getattr(module, '__version__', 'unknown')\n",
        "            package_name = package\n",
        "\n",
        "        print(f\"   âœ… {package_name}: {version}\")\n",
        "        installed_packages.append(package_name)\n",
        "    except ImportError:\n",
        "        print(f\"   âŒ {package}: Not installed\")\n",
        "        missing_packages.append(package)\n",
        "\n",
        "# Project structure check\n",
        "print(f\"\\nğŸ“ Project Structure:\")\n",
        "structure_checks = [\n",
        "    ('InsightSpike source code', 'src/insightspike'),\n",
        "    ('core/ module', 'src/insightspike/core'),\n",
        "    ('utils/ module', 'src/insightspike/utils'),\n",
        "    ('agents/ module', 'src/insightspike/agents')\n",
        "]\n",
        "\n",
        "structure_ok = 0\n",
        "for name, path in structure_checks:\n",
        "    if os.path.exists(path):\n",
        "        print(f\"   âœ… {name} found\")\n",
        "        structure_ok += 1\n",
        "    else:\n",
        "        print(f\"   âŒ {name} missing\")\n",
        "\n",
        "# Summary\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"ğŸ“Š SUMMARY:\")\n",
        "print(f\"   Installed: {len(installed_packages)}/{len(critical_packages)} packages\")\n",
        "if missing_packages:\n",
        "    print(f\"   Missing: {len(missing_packages)} packages\")\n",
        "\n",
        "# Recommendations\n",
        "if missing_packages or structure_ok < len(structure_checks):\n",
        "    print(f\"\\nğŸ”§ RECOMMENDED ACTIONS:\")\n",
        "    if missing_packages:\n",
        "        print(f\"   1. Install missing packages: {', '.join(missing_packages)}\")\n",
        "    if structure_ok < len(structure_checks):\n",
        "        print(f\"   2. Check project directory structure\")\n",
        "    print(f\"   3. Re-run setup script if needed\")\n",
        "    print(f\"   4. Check troubleshooting section above for specific solutions\")\n",
        "\n",
        "print(f\"\\nğŸš€ QUICK ACTIONS:\")\n",
        "print(f\"   â€¢ Restart Runtime: Runtime > Restart Runtime\")\n",
        "print(f\"   â€¢ Re-run Setup: Execute cells 1-3 in order\")\n",
        "if missing_packages:\n",
        "    print(f\"   â€¢ Manual Fix: Use troubleshooting commands above\")\n",
        "\n",
        "print(f\"\\n{'='*50}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRIQnwtEEyG6",
        "outputId": "ada0d4c1-9f9c-4767-f8bd-0e5208f8e3fd"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import platform\n",
        "import subprocess\n",
        "\n",
        "print(\"ğŸ” InsightSpike-AI System Diagnostic\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Environment info\n",
        "print(f\"ğŸ Python: {sys.version}\")\n",
        "print(f\"ğŸ’» Platform: {platform.platform()}\")\n",
        "print(f\"ğŸ“‚ Working Dir: {os.getcwd()}\")\n",
        "\n",
        "# Check if in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    print(\"â˜ï¸  Environment: Google Colab âœ…\")\n",
        "    in_colab = True\n",
        "except ImportError:\n",
        "    print(\"ğŸ’» Environment: Local/Other\")\n",
        "    in_colab = False\n",
        "\n",
        "# Memory info\n",
        "try:\n",
        "    import psutil\n",
        "    memory = psutil.virtual_memory()\n",
        "    print(f\"ğŸ’¾ RAM: {memory.total / 1e9:.1f} GB total, {memory.available / 1e9:.1f} GB available\")\n",
        "except ImportError:\n",
        "    print(\"ğŸ’¾ RAM: Memory info not available\")\n",
        "\n",
        "# GPU info with detailed status\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"\\nğŸ® GPU Status:\")\n",
        "    print(f\"   PyTorch: {torch.__version__}\")\n",
        "    print(f\"   CUDA Available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "        print(f\"   CUDA Version: {torch.version.cuda}\")\n",
        "    else:\n",
        "        print(\"   Mode: CPU only (fully functional)\")\n",
        "except ImportError:\n",
        "    print(\"\\nğŸ® PyTorch: Not installed âŒ\")\n",
        "# Configuration check\n",
        "print(f\"\\nâš™ï¸  Configuration Status:\")\n",
        "try:\n",
        "    from src.insightspike.core.config import LLMConfig\n",
        "    config = LLMConfig()\n",
        "    print(f\"   âœ… LLM Model: {config.model_name}\")\n",
        "    print(f\"   âœ… Temperature: {config.temperature}\")\n",
        "except Exception as e:\n",
        "    print(f\"   âŒ Configuration error: {str(e)[:50]}...\")\n",
        "# Package diagnostics\n",
        "print(f\"\\nğŸ“¦ Package Diagnostics:\")\n",
        "critical_packages = [\n",
        "    'torch', 'torch_geometric', 'faiss', 'sentence_transformers',\n",
        "    'networkx', 'transformers', 'numpy', 'scikit_learn'\n",
        "]\n",
        "\n",
        "installed_packages = []\n",
        "missing_packages = []\n",
        "\n",
        "for package in critical_packages:\n",
        "    try:\n",
        "        if package == 'scikit_learn':\n",
        "            import sklearn\n",
        "            version = sklearn.__version__\n",
        "            package_name = 'scikit_learn'\n",
        "        elif package == 'faiss':\n",
        "            import faiss\n",
        "            version = getattr(faiss, '__version__', 'unknown')\n",
        "            package_name = 'faiss'\n",
        "        else:\n",
        "            module = __import__(package)\n",
        "            version = getattr(module, '__version__', 'unknown')\n",
        "            package_name = package\n",
        "\n",
        "        print(f\"   âœ… {package_name}: {version}\")\n",
        "        installed_packages.append(package_name)\n",
        "    except ImportError:\n",
        "        print(f\"   âŒ {package}: Not installed\")\n",
        "        missing_packages.append(package)\n",
        "\n",
        "# Directory structure check\n",
        "print(f\"\\nğŸ“ Project Structure:\")\n",
        "if os.path.exists('src/insightspike'):\n",
        "    print(\"   âœ… InsightSpike source code found\")\n",
        "    src_contents = os.listdir('src/insightspike')\n",
        "    key_modules = ['core', 'utils', 'agents']\n",
        "    for module in key_modules:\n",
        "        if module in src_contents:\n",
        "            print(f\"   âœ… {module}/ module present\")\n",
        "        else:\n",
        "            print(f\"   âŒ {module}/ module missing\")\n",
        "else:\n",
        "    print(\"   âŒ InsightSpike source code not found\")\n",
        "    print(\"       ğŸ’¡ Make sure you're in the correct directory\")\n",
        "\n",
        "\n",
        "\n",
        "# Summary and recommendations\n",
        "print(f\"\\n\" + \"=\" * 50)\n",
        "print(f\"ğŸ“Š SUMMARY:\")\n",
        "print(f\"   Installed: {len(installed_packages)}/{len(critical_packages)} packages\")\n",
        "print(f\"   Missing: {len(missing_packages)} packages\")\n",
        "\n",
        "if missing_packages:\n",
        "    print(f\"\\nğŸ”§ RECOMMENDED ACTIONS:\")\n",
        "    if 'torch_geometric' in missing_packages:\n",
        "        print(\"   1. Install PyTorch Geometric: Re-run Step 2 dependency cell\")\n",
        "    if 'faiss' in missing_packages:\n",
        "        print(\"   2. Install FAISS: !pip install faiss-gpu\")\n",
        "    if len(missing_packages) > 2:\n",
        "        print(\"   3. Complete reinstall: Restart runtime, re-run all setup cells\")\n",
        "    print(\"   4. Check troubleshooting section above for specific solutions\")\n",
        "else:\n",
        "    print(f\"\\nğŸ‰ SYSTEM STATUS: Ready for research!\")\n",
        "    print(f\"   All critical packages installed\")\n",
        "    print(f\"   InsightSpike-AI is fully functional\")\n",
        "\n",
        "# Quick action buttons for Colab\n",
        "if in_colab:\n",
        "    print(f\"\\nğŸš€ QUICK ACTIONS:\")\n",
        "    print(f\"   â€¢ Restart Runtime: Runtime > Restart Runtime\")\n",
        "    print(f\"   â€¢ Re-run Setup: Execute cells 1-3 in order\")\n",
        "    print(f\"   â€¢ Manual Fix: Use troubleshooting commands above\")\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "9CY50lSLlH0_",
        "outputId": "516bc86a-215e-4d09-ef72-e50979f06ff3"
      },
      "outputs": [],
      "source": [
        "# InsightSpike CLIãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª\n",
        "insightspike --help\n",
        "insightspike --version\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42cc8c32",
        "outputId": "3959aa28-fd07-4992-859e-2424daf7d17b"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
