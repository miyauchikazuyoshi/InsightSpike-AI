#!/usr/bin/env python3
"""
å‹•çš„è¨˜æ†¶æ´å¯Ÿå®Ÿé¨“ v2.0 - InsightSpike-AI
==========================================

æ´å¯Ÿã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å‹•çš„ã«è¨˜æ†¶ã«è¿½åŠ ã—ã¦ã€è‡ªå·±å¼·åŒ–ãƒ«ãƒ¼ãƒ—ã®åŠ¹æœã‚’è¦³å¯Ÿã™ã‚‹å®Ÿé¨“
ï¼ˆL2MemoryManager APIã®æ­£ç¢ºãªå®Ÿè£…ç‰ˆï¼‰

ä¿®æ­£å†…å®¹:
- L2MemoryManagerã®æ­£ç¢ºãªAPIã«åˆã‚ã›ã¦ä¿®æ­£
- æ¤œç´¢ã‚¨ãƒ©ãƒ¼ã®è§£æ±º
- ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹æ¸¬å®šã®é©åˆ‡ãªå®Ÿè£…
- ã‚ˆã‚Šå …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

å®Ÿé¨“ç›®çš„:
1. æ´å¯Ÿã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®è¨˜æ†¶è¿½åŠ ãŒæ–°ãŸãªæ´å¯Ÿç”Ÿæˆã‚’åŠ é€Ÿã™ã‚‹ã‹
2. è¨˜æ†¶ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒã‚«ã‚ªã‚¹åŒ–ã™ã‚‹ã‹ã€ãã‚Œã¨ã‚‚æ•´ç†ã•ã‚Œã‚‹ã‹
3. è‡ªå·±å‚ç…§çš„å­¦ç¿’ã«ã‚ˆã‚‹å‰µç™ºçš„åŠ¹æœã®è¦³æ¸¬
"""

import sys
from pathlib import Path

# ãƒ‘ã‚¹è¨­å®š
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root / "src"))

import json
import time
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

# å®‰å…¨ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from insightspike.core.config import get_config
    from insightspike.utils.embedder import get_model
    from insightspike.core.layers.layer2_memory_manager import L2MemoryManager
    IMPORTS_OK = True
except ImportError as e:
    print(f"âš ï¸ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ï¼ˆç°¡æ˜“ç‰ˆã§ç¶šè¡Œï¼‰: {e}")
    IMPORTS_OK = False

class DynamicMemoryInsightExperimentV2:
    """å‹•çš„è¨˜æ†¶æ´å¯Ÿå®Ÿé¨“ã‚¯ãƒ©ã‚¹ v2.0ï¼ˆAPIä¿®æ­£ç‰ˆï¼‰"""
    
    def __init__(self, output_dir: str = "experiments/01_realtime_insight_experiments/outputs/dynamic_memory_v2"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        if IMPORTS_OK:
            # å®Ÿã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            self.config = get_config()
            self.model = get_model()
            self.memory_manager = L2MemoryManager(dim=384)
            
            # ãƒ™ãƒ¼ã‚¹ã‚°ãƒ©ãƒ•ã®åŸ‹ã‚è¾¼ã¿ãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆæœŸåŒ–
            self._initialize_base_memory()
            print("âœ… å®Ÿã‚·ã‚¹ãƒ†ãƒ ã¨ãƒ™ãƒ¼ã‚¹ãƒ¡ãƒ¢ãƒªã§åˆæœŸåŒ– (v2.0)")
        else:
            # ãƒ€ãƒŸãƒ¼ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            self.config = {"dummy": True}
            self.model = None
            self.memory_manager = MockMemoryManagerV2()
            print("âš ï¸ ãƒ€ãƒŸãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã§åˆæœŸåŒ– (v2.0)")
        
        # å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.topk = 10
        self.ged_threshold = 0.15
        self.ig_threshold = 0.10
        
        # è¿½è·¡ãƒ‡ãƒ¼ã‚¿
        self.episodes = []
        self.insights = []
        self.memory_snapshots = []
        self.insight_episodes_added = 0
    
    def _initialize_base_memory(self):
        """ãƒ™ãƒ¼ã‚¹ãƒ¡ãƒ¢ãƒªã®åˆæœŸåŒ– - åŸºæœ¬çš„ãªå­¦è¡“æ¦‚å¿µã‚’äº‹å‰ã«è¨˜æ†¶"""
        base_concepts = [
            "Machine learning algorithms optimize parameters through gradient descent.",
            "Deep neural networks learn hierarchical representations of data.",
            "Computer vision systems recognize patterns in visual information.",
            "Natural language processing models understand semantic relationships.",
            "Graph neural networks propagate information through network structures.",
            "Reinforcement learning agents maximize rewards through exploration.",
            "Cybersecurity systems detect anomalies in network traffic patterns.",
            "Climate models simulate atmospheric and oceanic dynamics.",
            "Drug discovery pipelines identify molecular targets and compounds.",
            "Autonomous systems navigate environments using sensor fusion."
        ]
        
        added_count = 0
        for concept in base_concepts:
            try:
                success = self.memory_manager.store_episode(
                    text=concept,
                    c_value=0.3  # åŸºæœ¬æ¦‚å¿µãªã®ã§ä¸­ç¨‹åº¦ã®Cå€¤
                )
                if success:
                    added_count += 1
            except Exception as e:
                print(f"âš ï¸ ãƒ™ãƒ¼ã‚¹æ¦‚å¿µã®è¿½åŠ ã«å¤±æ•—: {e}")
        
        print(f"ğŸ“š {added_count}/{len(base_concepts)}å€‹ã®ãƒ™ãƒ¼ã‚¹æ¦‚å¿µã‚’ãƒ¡ãƒ¢ãƒªã«è¿½åŠ ")
    
    def generate_episode(self) -> Dict:
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç”Ÿæˆ"""
        domains = ["cybersecurity", "climate modeling", "drug discovery", 
                  "autonomous systems", "computer vision"]
        
        research_areas = ["Machine Learning", "Deep Learning", "Computer Vision", 
                         "Natural Language Processing", "Graph Neural Networks"]
        
        domain = np.random.choice(domains)
        research_area = np.random.choice(research_areas)
        
        templates = [
            f"Recent research in {research_area} achieves significant performance on {domain}.",
            f"Novel {research_area} architecture shows improvements in {domain} applications.",
            f"Study of {research_area} in {domain} reveals insights about scalability.",
            f"Advanced {research_area} techniques demonstrate robustness in {domain} scenarios.",
            f"Cross-domain transfer learning from {research_area} to {domain} shows promise.",
            f"Optimization methods in {research_area} enhance {domain} system efficiency.",
        ]
        
        episode_text = np.random.choice(templates)
        
        return {
            "episode_text": episode_text,
            "domain": domain,
            "research_area": research_area,
            "complexity": np.random.uniform(0.1, 1.0),
            "novelty": np.random.uniform(0.1, 1.0),
            "timestamp": datetime.now().isoformat()
        }
    
    def detect_insight(self, episode_data: Dict) -> Dict:
        """æ´å¯Ÿæ¤œå‡ºï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            if IMPORTS_OK and self.model:
                # å®Ÿéš›ã®ã‚¨ãƒ³ã¹ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç†
                embedding = self.model.encode([episode_data['episode_text']], 
                                           convert_to_numpy=True, 
                                           normalize_embeddings=True)[0]
                
                # æ­£ã—ã„ãƒ¡ã‚½ãƒƒãƒ‰åã§é¡ä¼¼ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ¤œç´¢
                try:
                    similar_episodes = self.memory_manager.search_episodes(embedding, k=self.topk)
                    
                    # é¡ä¼¼åº¦è¨ˆç®—ï¼ˆä¿®æ­£ç‰ˆï¼‰
                    if similar_episodes and len(similar_episodes) > 0:
                        # similar_episodesãŒEpisodeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã®å ´åˆ
                        c_values = []
                        for ep in similar_episodes:
                            if hasattr(ep, 'c'):
                                c_values.append(ep.c)
                            elif isinstance(ep, tuple) and len(ep) > 1:
                                c_values.append(ep[1])
                            else:
                                c_values.append(0.5)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                        
                        avg_similarity = np.mean(c_values) if c_values else 0.5
                        delta_ged = max(0.0, 0.5 - avg_similarity)
                        delta_ig = np.random.uniform(0.0, delta_ged * 2)  # GEDã«åŸºã¥ãIG
                    else:
                        delta_ged = 0.5
                        delta_ig = 0.3
                    
                except Exception as search_error:
                    print(f"âš ï¸ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {search_error}")
                    delta_ged = 0.5
                    delta_ig = 0.3
                
                # ãƒ¡ãƒ¢ãƒªã«è¿½åŠ 
                try:
                    self.memory_manager.store_episode(
                        text=episode_data['episode_text'],
                        c_value=0.5
                    )
                except Exception as store_error:
                    print(f"âš ï¸ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜ã‚¨ãƒ©ãƒ¼: {store_error}")
                
            else:
                # ãƒ€ãƒŸãƒ¼å‡¦ç†
                delta_ged = np.random.uniform(0.0, 0.7)
                delta_ig = np.random.uniform(0.0, 0.5)
            
            # æ´å¯Ÿåˆ¤å®š
            is_insight = (delta_ged > self.ged_threshold and delta_ig > self.ig_threshold)
            
            insight_result = {
                "is_insight": is_insight,
                "delta_ged": delta_ged,
                "delta_ig": delta_ig,
                "threshold_ged": self.ged_threshold,
                "threshold_ig": self.ig_threshold,
                "timestamp": datetime.now().isoformat()
            }
            
            return insight_result
            
        except Exception as e:
            print(f"âš ï¸ æ´å¯Ÿæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "is_insight": False,
                "delta_ged": 0.0,
                "delta_ig": 0.0,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def add_insight_to_memory(self, episode_data: Dict, insight_data: Dict):
        """æ´å¯Ÿã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ãƒ¡ãƒ¢ãƒªã«è¿½åŠ ï¼ˆå‹•çš„è¨˜æ†¶ï¼‰"""
        try:
            # æ´å¯Ÿã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®æ‹¡å¼µãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
            insight_text = f"""INSIGHT: {episode_data['episode_text']} 
            [GED:{insight_data['delta_ged']:.3f}, IG:{insight_data['delta_ig']:.3f}] 
            Domain: {episode_data['domain']}, Area: {episode_data['research_area']}"""
            
            if IMPORTS_OK and self.memory_manager:
                # é«˜ã„Cå€¤ã§æ´å¯Ÿã‚’è¨˜æ†¶
                success = self.memory_manager.store_episode(
                    text=insight_text,
                    c_value=0.8  # æ´å¯Ÿã¯é«˜ã„Cå€¤
                )
                
                if success:
                    self.insight_episodes_added += 1
                    print(f"ğŸ’¡ æ´å¯Ÿã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’è¨˜æ†¶ã«è¿½åŠ  (#{self.insight_episodes_added})")
                else:
                    print("âš ï¸ æ´å¯Ÿã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¿½åŠ ã«å¤±æ•—")
            else:
                # ãƒ€ãƒŸãƒ¼å‡¦ç†
                self.insight_episodes_added += 1
                
        except Exception as e:
            print(f"âš ï¸ æ´å¯Ÿè¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
    
    def measure_memory_chaos(self) -> float:
        """è¨˜æ†¶ã®æ··æ²Œåº¦ã‚’æ¸¬å®š"""
        try:
            if IMPORTS_OK and self.memory_manager:
                # ãƒ¡ãƒ¢ãƒªçµ±è¨ˆã‚’å–å¾—
                stats = self.memory_manager.get_memory_stats()
                
                # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ãƒ™ãƒ¼ã‚¹ã®æ··æ²Œåº¦
                num_episodes = stats.get('num_episodes', 0)
                
                if num_episodes > 0:
                    # Cå€¤ã®åˆ†æ•£ã‚’åŸºã«æ··æ²Œåº¦ã‚’è¨ˆç®—
                    c_variance = stats.get('c_variance', 0.0)
                    chaos_score = min(1.0, c_variance * 10)  # æ­£è¦åŒ–
                else:
                    chaos_score = 0.0
                
                return chaos_score
                
            else:
                # ãƒ€ãƒŸãƒ¼å‡¦ç†: å‹•çš„è¨˜æ†¶ã«åŸºã¥ãæ“¬ä¼¼æ··æ²Œåº¦
                base_chaos = 0.1
                insight_factor = self.insight_episodes_added * 0.05
                return min(1.0, base_chaos + insight_factor)
                
        except Exception as e:
            print(f"âš ï¸ è¨˜æ†¶çŠ¶æ…‹æ¸¬å®šã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def run_experiment(self, num_episodes: int = 100, progress_interval: int = 25) -> Dict:
        """å®Ÿé¨“å®Ÿè¡Œ"""
        print("\nğŸš€ å‹•çš„è¨˜æ†¶æ´å¯Ÿå®Ÿé¨“é–‹å§‹ v2.0")
        print(f"   ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {num_episodes}")
        
        start_time = time.time()
        initial_chaos = self.measure_memory_chaos()
        
        for i in range(num_episodes):
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç”Ÿæˆ
            episode_data = self.generate_episode()
            
            # æ´å¯Ÿæ¤œå‡º
            insight_result = self.detect_insight(episode_data)
            
            # ãƒ‡ãƒ¼ã‚¿è¨˜éŒ²
            episode_record = {
                **episode_data,
                **insight_result,
                "episode_id": i
            }
            self.episodes.append(episode_record)
            
            # æ´å¯Ÿã®å ´åˆã¯è¨˜æ†¶ã«è¿½åŠ 
            if insight_result.get("is_insight", False):
                self.insights.append(episode_record)
                self.add_insight_to_memory(episode_data, insight_result)
            
            # è¨˜æ†¶çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
            if (i + 1) % 10 == 0:
                chaos_score = self.measure_memory_chaos()
                snapshot = {
                    "episode": i + 1,
                    "chaos_score": chaos_score,
                    "insights_count": len(self.insights),
                    "memory_additions": self.insight_episodes_added,
                    "timestamp": datetime.now().isoformat()
                }
                self.memory_snapshots.append(snapshot)
            
            # é€²æ—å ±å‘Š
            if (i + 1) % progress_interval == 0:
                elapsed = time.time() - start_time
                insights_so_far = len(self.insights)
                chaos_score = self.measure_memory_chaos()
                speed = (i + 1) / elapsed
                
                print(f"ğŸ“Š [{i+1:3d}/{num_episodes}] æ´å¯Ÿ: {insights_so_far:3d} "
                      f"({insights_so_far/(i+1)*100:4.1f}%) è¨˜æ†¶è¿½åŠ : {self.insight_episodes_added:3d} "
                      f"ã‚«ã‚ªã‚¹: {chaos_score:.3f} é€Ÿåº¦: {speed:.1f} eps/s")
        
        # å®Ÿé¨“çµ‚äº†
        end_time = time.time()
        final_chaos = self.measure_memory_chaos()
        
        results = {
            'total_episodes': num_episodes,
            'insights_detected': len(self.insights),
            'insight_rate': len(self.insights) / num_episodes,
            'insight_episodes_added': self.insight_episodes_added,
            'experiment_duration': end_time - start_time,
            'processing_speed': num_episodes / (end_time - start_time),
            'initial_chaos_score': initial_chaos,
            'final_chaos_score': final_chaos,
            'chaos_change': final_chaos - initial_chaos,
        }
        
        print(f"\nâœ… å‹•çš„è¨˜æ†¶æ´å¯Ÿå®Ÿé¨“å®Œäº†! v2.0")
        print(f"   ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰: {results['total_episodes']}")
        print(f"   æ´å¯Ÿæ¤œå‡º: {results['insights_detected']} ({results['insight_rate']:.1%})")
        print(f"   è¨˜æ†¶è¿½åŠ : {results['insight_episodes_added']}")
        print(f"   å®Ÿé¨“æ™‚é–“: {results['experiment_duration']:.2f}ç§’")
        print(f"   å‡¦ç†é€Ÿåº¦: {results['processing_speed']:.1f} eps/s")
        print(f"   ã‚«ã‚ªã‚¹å¤‰åŒ–: {results['initial_chaos_score']:.3f} â†’ {results['final_chaos_score']:.3f} ({results['chaos_change']:+.3f})")
        
        # çµæœä¿å­˜
        self.save_results()
        
        return results
    
    def save_results(self):
        """çµæœã®ä¿å­˜"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿
            if self.episodes:
                episodes_df = pd.DataFrame(self.episodes)
                episodes_df.to_csv(self.output_dir / f"episodes_{timestamp}.csv", index=False)
            
            # æ´å¯Ÿãƒ‡ãƒ¼ã‚¿
            if self.insights:
                insights_df = pd.DataFrame(self.insights)
                insights_df.to_csv(self.output_dir / f"insights_{timestamp}.csv", index=False)
            
            # è¨˜æ†¶ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
            if self.memory_snapshots:
                memory_df = pd.DataFrame(self.memory_snapshots)
                memory_df.to_csv(self.output_dir / f"memory_snapshots_{timestamp}.csv", index=False)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            metadata = {
                'experiment': 'dynamic_memory_insight_v2',
                'timestamp': timestamp,
                'total_episodes': len(self.episodes),
                'total_insights': len(self.insights),
                'insight_rate': len(self.insights) / len(self.episodes) if self.episodes else 0,
                'insight_episodes_added': self.insight_episodes_added,
                'system_type': 'real' if IMPORTS_OK else 'dummy',
                'version': '2.0'
            }
            
            with open(self.output_dir / f"metadata_{timestamp}.json", 'w') as f:
                json.dump(metadata, f, indent=2, default=str)
            
            print(f"ğŸ’¾ çµæœä¿å­˜å®Œäº†: {self.output_dir}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


class MockMemoryManagerV2:
    """ãƒ€ãƒŸãƒ¼ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ v2.0"""
    def __init__(self):
        self.episodes = []
    
    def store_episode(self, text, c_value=0.5):
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰"""
        episode = {
            "text": text,
            "c_value": c_value,
            "timestamp": datetime.now().isoformat()
        }
        self.episodes.append(episode)
        return True
    
    def search_episodes(self, query, k=10):
        """é¡ä¼¼ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰"""
        class MockEpisode:
            def __init__(self, text, c):
                self.text = text
                self.c = c
        
        return [MockEpisode(ep.get("text", ""), ep.get("c_value", 0.5)) 
                for ep in self.episodes[:k]]
    
    def get_memory_stats(self):
        """ãƒ¡ãƒ¢ãƒªçµ±è¨ˆï¼ˆãƒ€ãƒŸãƒ¼ï¼‰"""
        if not self.episodes:
            return {'num_episodes': 0, 'c_variance': 0.0}
        
        c_values = [ep.get("c_value", 0.5) for ep in self.episodes]
        return {
            'num_episodes': len(self.episodes),
            'c_variance': np.var(c_values) if c_values else 0.0,
            'mean_c_value': np.mean(c_values) if c_values else 0.5
        }
    
    def get_recent_episodes(self, n=50):
        return self.episodes[-n:]


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ§  å‹•çš„è¨˜æ†¶æ´å¯Ÿå®Ÿé¨“ v2.0 - InsightSpike-AI")
    print("=" * 60)
    
    try:
        experiment = DynamicMemoryInsightExperimentV2()
        
        # å®Ÿé¨“å®Ÿè¡Œ
        results = experiment.run_experiment(
            num_episodes=150,  # ä¸­è¦æ¨¡ã§è©³ç´°è¦³å¯Ÿ
            progress_interval=25
        )
        
        print("\nğŸ‰ å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼:")
        print(f"   æ´å¯Ÿæ¤œå‡ºç‡: {results['insight_rate']:.1%}")
        print(f"   è¨˜æ†¶è¿½åŠ æ•°: {results['insight_episodes_added']}")
        print(f"   æœ€çµ‚ã‚«ã‚ªã‚¹åº¦: {results['final_chaos_score']:.3f}")
        
        # çµæœåˆ†æ
        if results['insight_episodes_added'] > 0:
            acceleration_ratio = results['insight_rate'] / (results['insight_episodes_added'] / results['insights_detected']) if results['insights_detected'] > 0 else 0
            print(f"   åŠ é€ŸåŠ¹æœ: {acceleration_ratio:.3f}")
            
            if results['final_chaos_score'] > 0.5:
                print("   ğŸ“ˆ è¨˜æ†¶ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯å¤šæ§˜åŒ–å‚¾å‘ï¼ˆè‰¯ã„ã‚«ã‚ªã‚¹ï¼‰")
            elif results['final_chaos_score'] < 0.2:
                print("   ğŸ“‰ è¨˜æ†¶ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯åæŸå‚¾å‘ï¼ˆç§©åºåŒ–ï¼‰")
            else:
                print("   âš–ï¸ è¨˜æ†¶ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯å®‰å®šçŠ¶æ…‹")
        
        print(f"\nğŸ“Š ã‚«ã‚ªã‚¹å¤‰åŒ–ã®è§£é‡ˆ:")
        if results['chaos_change'] > 0.1:
            print("   ğŸ”¥ å‹•çš„è¨˜æ†¶ãŒå‰µç™ºçš„è¤‡é›‘æ€§ã‚’ç”Ÿæˆ")
        elif results['chaos_change'] < -0.1:
            print("   ğŸ§˜ å‹•çš„è¨˜æ†¶ãŒç§©åºåŒ–ã‚’ä¿ƒé€²")
        else:
            print("   âš–ï¸ å‹•çš„è¨˜æ†¶ãŒå®‰å®šã—ãŸå­¦ç¿’ç’°å¢ƒã‚’ç¶­æŒ")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ å®Ÿé¨“ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
