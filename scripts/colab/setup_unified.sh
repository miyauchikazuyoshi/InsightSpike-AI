#!/bin/bash
# InsightSpike-AI Unified Colab Setup Script
# ==========================================
# Single script for seamless Colab/Local/CI compatibility

echo "ðŸš€ InsightSpike-AI Unified Setup Starting..."
echo "============================================"

# Check if running in Colab
if [ -n "$COLAB_GPU" ] || [ -n "$COLAB_TPU_ADDR" ] || [ -d "/content" ]; then
    echo "ðŸ“± Google Colab environment detected"
    IN_COLAB=true
else
    echo "ðŸ’» Local environment detected"
    IN_COLAB=false
fi

# Colab-specific configuration optimization
if [ "$IN_COLAB" = true ]; then
    echo "ðŸ”§ Optimizing for Colab environment..."
    
    # Switch to Colab-optimized pyproject.toml if available
    if [ -f "pyproject_colab.toml" ]; then
        echo "ðŸ“ Using Colab-optimized configuration..."
        cp pyproject.toml pyproject_backup.toml 2>/dev/null || true
        cp pyproject_colab.toml pyproject.toml
    fi
fi

# Install core dependencies first for CLI functionality  
echo "ðŸ“¦ Installing core dependencies for CLI..."
pip install typer click pydantic --quiet

# Install dependencies using pyproject.toml
echo "ðŸ“¦ Installing dependencies from pyproject.toml..."
pip install -e . --quiet

# Install FAISS CPU version (reliable and works everywhere)
echo "ðŸ”§ Installing FAISS (CPU version for stability)..."
pip install faiss-cpu --upgrade --quiet
echo "  âœ… faiss-cpu installed successfully"

# Install PyTorch Geometric for graph operations (Phase 2 support)
echo "ðŸ”§ Installing PyTorch Geometric for graph neural networks..."

# First install the main package
pip install torch_geometric --quiet

# Then install optional dependencies for enhanced functionality
if command -v nvidia-smi &> /dev/null && nvidia-smi > /dev/null 2>&1; then
    echo "ðŸŽ® Installing PyTorch Geometric extensions with CUDA support..."
    # Get PyTorch CUDA version for proper wheel selection
    CUDA_VERSION=$(python -c "import torch; print(torch.version.cuda)" 2>/dev/null || echo "118")
    TORCH_VERSION=$(python -c "import torch; print(torch.__version__.split('+')[0])" 2>/dev/null || echo "2.2.0")
    
    echo "ðŸ” Detected PyTorch ${TORCH_VERSION} with CUDA ${CUDA_VERSION}"
    
    # Install extensions from official PyG wheel repository
    pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv \
        -f https://data.pyg.org/whl/torch-${TORCH_VERSION}+cu${CUDA_VERSION}.html --quiet || {
        echo "âš ï¸ CUDA-specific extensions failed, trying CPU versions..."
        pip install torch_scatter torch_sparse torch_cluster torch_spline_conv \
            -f https://data.pyg.org/whl/torch-${TORCH_VERSION}+cpu.html --quiet
    }
else
    echo "ðŸ’» Installing PyTorch Geometric extensions (CPU version)..."
    TORCH_VERSION=$(python -c "import torch; print(torch.__version__.split('+')[0])" 2>/dev/null || echo "2.2.0")
    pip install torch_scatter torch_sparse torch_cluster torch_spline_conv \
        -f https://data.pyg.org/whl/torch-${TORCH_VERSION}+cpu.html --quiet
fi

# Verify installations
echo "ðŸ” Verifying core library installations..."
python -c "
# FAISS verification
try:
    import faiss
    print('âœ… FAISS: version ' + getattr(faiss, '__version__', 'unknown'))
except ImportError as e:
    print('âŒ FAISS: Import failed - ' + str(e))

# PyTorch Geometric verification
try:
    import torch_geometric
    print('âœ… PyTorch Geometric: version ' + torch_geometric.__version__)
    
    # Test basic functionality
    import torch_geometric.data
    print('âœ… PyTorch Geometric: Core functionality available')
    
except ImportError as e:
    print('âŒ PyTorch Geometric: Import failed - ' + str(e))
    print('âš ï¸  Graph neural network features will be unavailable')

# PyTorch Scatter/Sparse verification  
try:
    import torch_scatter
    import torch_sparse
    print('âœ… PyTorch extensions: torch-scatter and torch-sparse available')
except ImportError as e:
    print('âš ï¸ PyTorch extensions: Some graph operations may be limited - ' + str(e))
" 2>/dev/null || echo "âš ï¸ Library verification encountered errors"

# Ensure Python can find the insightspike module
echo "ðŸ”§ Setting up Python module paths..."
CURRENT_DIR=$(pwd)
SRC_PATH="$CURRENT_DIR/src"

# Add both src and project root to Python path
export PYTHONPATH="$SRC_PATH:$CURRENT_DIR:$PYTHONPATH"

# Create a .pth file for persistent Python path (Colab-specific)
if [ "$IN_COLAB" = true ]; then
    SITE_PACKAGES=$(python -c "import site; print(site.getsitepackages()[0])" 2>/dev/null || echo "/usr/local/lib/python3.10/dist-packages")
    echo "$SRC_PATH" > "$SITE_PACKAGES/insightspike-dev.pth"
    echo "$CURRENT_DIR" >> "$SITE_PACKAGES/insightspike-dev.pth"
    echo "âœ… Added Python paths to $SITE_PACKAGES/insightspike-dev.pth"
    
    # Also set in bashrc for persistent sessions
    echo "export PYTHONPATH=\"$SRC_PATH:$CURRENT_DIR:\$PYTHONPATH\"" >> ~/.bashrc
fi

# Additional Colab-specific optimizations
if [ "$IN_COLAB" = true ]; then
    echo "âš¡ Applying Colab optimizations..."
    
    # Enable GPU if available
    if command -v nvidia-smi &> /dev/null; then
        echo "ðŸŽ® NVIDIA GPU detected - enabling CUDA acceleration"
        export CUDA_VISIBLE_DEVICES=0
    fi
    
    # Colab-specific directory setup
    mkdir -p /content/data
    mkdir -p /content/models
    mkdir -p /content/outputs
    
    # Ensure CLI scripts are in PATH for Colab
    echo "ðŸ”§ Setting up CLI environment..."
    export PATH="/root/.local/bin:$PATH"
    
    # Add editable install to ensure CLI is accessible
    echo "ðŸ”§ Installing InsightSpike-AI in editable mode..."
    pip install -e .
    
    # Create a direct CLI symlink if needed
    if [ ! -f "/usr/local/bin/insightspike" ]; then
        echo "ðŸ”— Creating CLI symlink..."
        ln -sf "$(which python)" /usr/local/bin/insightspike-python
        cat > /usr/local/bin/insightspike << 'EOF'
#!/bin/bash
python -m insightspike.cli.main "$@"
EOF
        chmod +x /usr/local/bin/insightspike
    fi
    
    echo "ðŸ“ Colab directories created"
fi

# Verify installation with comprehensive status reporting
echo "ðŸ” Verifying installation..."
python -c "
import torch
import numpy as np
print(f'âœ… PyTorch: {torch.__version__}')
print(f'âœ… CUDA available: {torch.cuda.is_available()}')
print(f'âœ… NumPy: {np.__version__}')

# FAISS status
try:
    import faiss
    print(f'âœ… FAISS: {getattr(faiss, \"__version__\", \"unknown\")} - Ready for similarity search')
except ImportError:
    print('âŒ FAISS: Not available - Memory systems will use baseline implementation')

# PyTorch Geometric status with detailed reporting
try:
    import torch_geometric
    print(f'âœ… PyTorch Geometric: {torch_geometric.__version__} - Graph operations enabled')
    
    # Test core components
    try:
        import torch_geometric.nn
        import torch_geometric.data
        print('âœ… PyTorch Geometric: Neural network layers available')
    except ImportError:
        print('âš ï¸ PyTorch Geometric: Some components missing')
        
    try:
        import torch_scatter
        import torch_sparse
        print('âœ… PyTorch extensions: Scatter and sparse operations available')
    except ImportError:
        print('âš ï¸ PyTorch extensions: Limited graph operations')
        
except ImportError:
    print('âŒ PyTorch Geometric: Not available')
    print('   Phase 2 graph neural networks will be disabled')
    print('   Phase 1 experiments will work normally')

# InsightSpike status
try:
    from insightspike.core.agents.main_agent import MainAgent
    print('âœ… InsightSpike-AI: Core modules loaded successfully')
    
    # Test instantiation
    try:
        agent = MainAgent()
        print('âœ… InsightSpike-AI: MainAgent instantiation successful')
        del agent  # Clean up
    except Exception as e:
        print(f'âš ï¸ InsightSpike-AI: MainAgent instantiation failed - {e}')
        
except ImportError as e:
    print(f'âŒ InsightSpike-AI: Core import failed - {e}')
    print('   Standalone implementations will be used')
"

# Test CLI availability
echo "ðŸ”§ Testing CLI command availability..."
if command -v insightspike &> /dev/null; then
    echo "âœ… InsightSpike CLI: Available via 'insightspike' command"
    echo "ðŸ“‹ CLI Help:"
    insightspike --help 2>/dev/null | head -10 || echo "  (CLI help not available, but command exists)"
else
    echo "âš ï¸  InsightSpike CLI: Command not found in PATH"
    echo "   You can still use: python -m insightspike.cli.main"
    
    # Test alternative CLI access
    python -c "
try:
    from insightspike.cli.main import main
    print('âœ… CLI Module: Available via python -m insightspike.cli.main')
except ImportError:
    print('âŒ CLI Module: Not available')
" 2>/dev/null || echo "âŒ CLI Module: Import test failed"
fi

# Final Python import test to ensure everything works
echo "ðŸ§ª Final import test..."
python -c "
import sys
print(f'ðŸ“ Current working directory: {sys.path[0] if sys.path else \"Unknown\"}')

try:
    from insightspike.core.agents.main_agent import MainAgent
    print('âœ… MainAgent: Successfully imported')
    
    # Quick instantiation test
    try:
        agent = MainAgent()
        print('âœ… MainAgent: Successfully instantiated')
    except Exception as e:
        print(f'âš ï¸  MainAgent: Import OK, but instantiation failed - {e}')
        
except ImportError as e:
    print(f'âŒ MainAgent: Import failed - {e}')
    print('ðŸ’¡ You may need to run: import sys; sys.path.insert(0, \"/content/InsightSpike-AI/src\")')

try:
    import insightspike.config as config
    print('âœ… Config: Successfully imported')
except ImportError:
    print('âš ï¸  Config: Import failed (may be optional)')
"

echo ""
echo "ðŸŽ‰ Setup completed successfully!"
echo "=================================="

# Generate setup summary
echo "ðŸ“‹ Setup Summary:"
python -c "
# Check available components and generate status report
components = {
    'CUDA/GPU': False,
    'FAISS': False, 
    'PyTorch Geometric': False,
    'InsightSpike Core': False
}

try:
    import torch
    components['CUDA/GPU'] = torch.cuda.is_available()
except:
    pass

try:
    import faiss
    components['FAISS'] = True
except:
    pass

try:
    import torch_geometric
    components['PyTorch Geometric'] = True
except:
    pass

try:
    from insightspike.core.agents.main_agent import MainAgent
    components['InsightSpike Core'] = True
except:
    pass

print('âœ… Available Components:')
for comp, available in components.items():
    status = 'âœ…' if available else 'âŒ'
    print(f'   {status} {comp}')

print('')
print('ðŸ”¬ Experiment Capabilities:')
print('   âœ… Phase 1: Dynamic Memory Construction (Always available)')
if components['FAISS']:
    print('   âœ… Enhanced similarity search with FAISS')
else:
    print('   âš ï¸  Baseline similarity search (FAISS unavailable)')
    
if components['PyTorch Geometric']:
    print('   âœ… Phase 2: Graph neural networks ready')
else:
    print('   âš ï¸  Phase 2: Graph operations limited (PyTorch Geometric unavailable)')
    
if components['CUDA/GPU']:
    print('   âœ… GPU acceleration enabled')
else:
    print('   ðŸ’» CPU-only mode (No GPU detected)')
"

if [ "$IN_COLAB" = true ]; then
    echo ""
    echo "ðŸ’¡ Ready to use InsightSpike-AI in Google Colab!"
    echo "ðŸ”¬ Phase 1 experiments are fully supported"
    echo "ðŸ“Š Run the Phase 1 notebook to start your experiments"
else
    echo ""
    echo "ðŸ’¡ Ready to use InsightSpike-AI in local environment!"
fi

# =============================================================================
# CLI Setup for Phase 2 Compatibility
# =============================================================================
echo ""
echo "ðŸ”§ Setting up CLI for Phase 2 compatibility..."

# Environment variables for CLI
PROJECT_ROOT="$(pwd)"
SRC_PATH="$PROJECT_ROOT/src"
export PYTHONPATH="$SRC_PATH:$PROJECT_ROOT:$PYTHONPATH"
export TOKENIZERS_PARALLELISM=false
export INSIGHTSPIKE_ENV="colab"

if [ "$IN_COLAB" = true ]; then
    echo "ðŸ“± Configuring CLI for Colab environment..."
    
    # Create CLI wrapper script with proper paths
    cat > /usr/local/bin/insightspike << 'EOF'
#!/bin/bash
# InsightSpike CLI Wrapper for Colab - Multiple fallback methods
export PYTHONPATH="/content/InsightSpike-AI/src:/content/InsightSpike-AI:$PYTHONPATH"
export INSIGHTSPIKE_ENV="colab"
export TOKENIZERS_PARALLELISM="false"

cd /content/InsightSpike-AI

# Method 1: Try poetry (if available and configured)
if command -v poetry >/dev/null 2>&1; then
    if poetry run python -c "from insightspike.cli.main import main" >/dev/null 2>&1; then
        exec poetry run python -m insightspike.cli.main "$@"
    fi
fi

# Method 2: Try direct Python with proper paths
if python -c "import sys; sys.path.insert(0, 'src'); from insightspike.cli.main import main" >/dev/null 2>&1; then
    exec python -c "
import sys
sys.path.insert(0, 'src')
from insightspike.cli.main import main
main()
" "$@"
fi

# Method 3: Try system python with module path
export PYTHONPATH="/content/InsightSpike-AI/src:$PYTHONPATH"
if python -m insightspike.cli.main --help >/dev/null 2>&1; then
    exec python -m insightspike.cli.main "$@"
fi

# Method 4: Last resort - direct execution
echo "âŒ All CLI methods failed. Available alternatives:"
echo "  â€¢ python -c \"import sys; sys.path.insert(0, 'src'); from insightspike.cli.main import main; main()\""
echo "  â€¢ python -m insightspike.cli.main (after setting PYTHONPATH)"
exit 1
EOF
    
    # Make executable
    chmod +x /usr/local/bin/insightspike
    
    # Test CLI installation with comprehensive diagnostics
    echo "ðŸ§ª Testing CLI installation..."
    
    CLI_STATUS="failed"
    
    # Test 1: Direct Python module access
    echo "  ðŸ“‹ Test 1: Direct Python import"
    if cd /content/InsightSpike-AI && python -c "import sys; sys.path.insert(0, 'src'); from insightspike.cli.main import main" >/dev/null 2>&1; then
        echo "    âœ… CLI module import: Working"
        CLI_STATUS="import_ok"
    else
        echo "    âŒ CLI module import: Failed"
    fi
    
    # Test 2: Poetry execution (if available)
    echo "  ðŸ“‹ Test 2: Poetry CLI execution"
    if command -v poetry >/dev/null 2>&1; then
        if cd /content/InsightSpike-AI && poetry run python -c "from insightspike.cli.main import main" >/dev/null 2>&1; then
            echo "    âœ… Poetry CLI: Working"
            CLI_STATUS="poetry_ok"
            
            # Test actual command
            if poetry run insightspike --help >/dev/null 2>&1; then
                echo "    âœ… Poetry command execution: Working"
                CLI_STATUS="full"
            else
                echo "    âš ï¸  Poetry import OK, but command execution failed"
            fi
        else
            echo "    âŒ Poetry CLI: Module import failed"
        fi
    else
        echo "    âš ï¸  Poetry: Not available"
    fi
    
    # Test 3: Wrapper script
    echo "  ðŸ“‹ Test 3: CLI wrapper script"
    if /usr/local/bin/insightspike --help >/dev/null 2>&1; then
        echo "    âœ… CLI wrapper: Working"
        if [ "$CLI_STATUS" != "full" ]; then
            CLI_STATUS="wrapper_ok"
        fi
    else
        echo "    âš ï¸  CLI wrapper: Has issues"
    fi
    
    # Set CLI availability based on tests
    case "$CLI_STATUS" in
        "full")
            CLI_AVAILABLE=true
            echo "âœ… CLI Status: Fully functional"
            ;;
        "poetry_ok"|"wrapper_ok")
            CLI_AVAILABLE="partial"
            echo "âš ï¸  CLI Status: Partially functional"
            ;;
        "import_ok")
            CLI_AVAILABLE="import_only"
            echo "âš ï¸  CLI Status: Import only (manual execution required)"
            ;;
        *)
            CLI_AVAILABLE=false
            echo "âŒ CLI Status: Not functional"
            ;;
    esac
    
    # Install Poetry with proper configuration for Colab
    echo "ðŸ“¦ Installing Poetry for full CLI support..."
    if ! command -v poetry &> /dev/null; then
        echo "ðŸ”§ Installing Poetry with Colab-optimized settings..."
        
        # Install poetry in user space
        pip install poetry --quiet --user
        
        # Add poetry to PATH if not already there
        export PATH="$HOME/.local/bin:$PATH"
        echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc
        
        # Configure poetry to use system environment (not create venv in Colab)
        ~/.local/bin/poetry config virtualenvs.create false --local || {
            echo "âš ï¸  Poetry config failed, continuing..."
        }
        
        # Test poetry installation
        if ~/.local/bin/poetry --version >/dev/null 2>&1; then
            echo "âœ… Poetry installed successfully"
            # Create symlink for easier access
            sudo ln -sf ~/.local/bin/poetry /usr/local/bin/poetry 2>/dev/null || true
        else
            echo "âš ï¸  Poetry installation had issues - using alternative CLI methods"
        fi
    else
        echo "âœ… Poetry already installed"
        # Still configure it for Colab
        poetry config virtualenvs.create false --local 2>/dev/null || true
    fi
    
else
    echo "ðŸ’» Local environment - verifying Poetry CLI..."
    if command -v poetry &> /dev/null; then
        echo "âœ… Poetry CLI available"
        
        # Test direct CLI access
        if poetry run python -c "from insightspike.cli.main import main" >/dev/null 2>&1; then
            echo "âœ… CLI module accessible via Poetry"
            CLI_AVAILABLE=true
        else
            echo "âš ï¸  CLI module has import issues"
            CLI_AVAILABLE="partial"
        fi
    else
        echo "âš ï¸  Poetry not found - please install Poetry for full CLI functionality"
        CLI_AVAILABLE=false
    fi
fi

echo ""
echo "ðŸš€ Next Steps:"
echo "  1. Run Phase 1 notebook cells sequentially"
echo "  2. Start with device setup (Cell 8)"
echo "  3. Load data (Cell 11) and run experiments"
echo ""

if [ "$CLI_AVAILABLE" = true ]; then
    echo "ðŸŽ¯ CLI Ready for Phase 2:"
    echo "  â€¢ Full command line: insightspike --help"
    echo "  â€¢ Dependency management: insightspike deps --help"
    echo "  â€¢ Experiment control: insightspike ask --help"
    echo "  â€¢ All Poetry features available"
elif [ "$CLI_AVAILABLE" = "partial" ]; then
    echo "ðŸ”§ CLI Partially Available:"
    echo "  â€¢ Limited CLI: /usr/local/bin/insightspike --help"
    echo "  â€¢ Python module: python -m insightspike.cli.main --help"
    echo "  â€¢ Direct import: python -c 'from insightspike.cli.main import main; main()'"
    echo "  â€¢ Some commands may require manual execution"
elif [ "$CLI_AVAILABLE" = "import_only" ]; then
    echo "ðŸ CLI Import Only:"
    echo "  â€¢ Manual execution: python -c 'import sys; sys.path.insert(0, \"src\"); from insightspike.cli.main import main; main()'"
    echo "  â€¢ Notebook API: from insightspike.cli.main import app"
    echo "  â€¢ Poetry setup may need completion"
else
    echo "ðŸ”§ Alternative CLI methods:"
    echo "  â€¢ Check Python paths: import sys; print(sys.path)"
    echo "  â€¢ Manual setup: sys.path.insert(0, '/content/InsightSpike-AI/src')"
    echo "  â€¢ Direct execution from notebook cells"
    echo "  â€¢ Consider using Python API instead of CLI"
fi

echo ""
echo "ðŸ” Debug Information:"
echo "  â€¢ Python executable: $(which python)"
echo "  â€¢ Poetry location: $(which poetry 2>/dev/null || echo 'Not found')"
echo "  â€¢ Current PYTHONPATH: $PYTHONPATH"
echo "  â€¢ InsightSpike-AI location: $(pwd)"

echo ""
echo "âœ… Setup complete - ready for Phase 1 & 2 experiments!"
