#!/bin/bash
# InsightSpike-AI Unified Colab Setup Script
# ==========================================
# Single script for seamless Colab/Local/CI compatibility

echo "ğŸš€ InsightSpike-AI Unified Setup Starting..."
echo "============================================"

# Check if running in Colab
if [ -n "$COLAB_GPU" ] || [ -n "$COLAB_TPU_ADDR" ]; then
    echo "ğŸ“± Google Colab environment detected"
    IN_COLAB=true
else
    echo "ğŸ’» Local environment detected"
    IN_COLAB=false
fi

# Colab-specific configuration optimization
if [ "$IN_COLAB" = true ]; then
    echo "ğŸ”§ Optimizing for Colab environment..."
    
    # Switch to Colab-optimized pyproject.toml if available
    if [ -f "pyproject_colab.toml" ]; then
        echo "ğŸ“ Using Colab-optimized configuration..."
        cp pyproject.toml pyproject_backup.toml 2>/dev/null || true
        cp pyproject_colab.toml pyproject.toml
    fi
fi

# Install dependencies using pyproject.toml
echo "ğŸ“¦ Installing dependencies from pyproject.toml..."
pip install -e .

# Install FAISS separately with enhanced GPU/CPU detection
echo "ğŸ”§ Installing FAISS with optimal backend..."
if command -v nvidia-smi &> /dev/null && nvidia-smi > /dev/null 2>&1; then
    echo "ğŸ® GPU detected - trying faiss-gpu installation..."
    pip install faiss-gpu --upgrade --quiet --no-deps || {
        echo "âš ï¸ faiss-gpu failed, installing faiss-cpu..."
        pip install faiss-cpu --upgrade --quiet
    }
else
    echo "ğŸ’» CPU environment - installing faiss-cpu..."
    pip install faiss-cpu --upgrade --quiet
fi

# Install PyTorch Geometric for graph operations (Phase 2 support)
echo "ğŸ”§ Installing PyTorch Geometric for graph neural networks..."

# First install the main package
pip install torch_geometric --quiet

# Then install optional dependencies for enhanced functionality
if command -v nvidia-smi &> /dev/null && nvidia-smi > /dev/null 2>&1; then
    echo "ğŸ® Installing PyTorch Geometric extensions with CUDA support..."
    # Get PyTorch CUDA version for proper wheel selection
    CUDA_VERSION=$(python -c "import torch; print(torch.version.cuda)" 2>/dev/null || echo "118")
    TORCH_VERSION=$(python -c "import torch; print(torch.__version__.split('+')[0])" 2>/dev/null || echo "2.2.0")
    
    echo "ğŸ” Detected PyTorch ${TORCH_VERSION} with CUDA ${CUDA_VERSION}"
    
    # Install extensions from official PyG wheel repository
    pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv \
        -f https://data.pyg.org/whl/torch-${TORCH_VERSION}+cu${CUDA_VERSION}.html --quiet || {
        echo "âš ï¸ CUDA-specific extensions failed, trying CPU versions..."
        pip install torch_scatter torch_sparse torch_cluster torch_spline_conv \
            -f https://data.pyg.org/whl/torch-${TORCH_VERSION}+cpu.html --quiet
    }
else
    echo "ğŸ’» Installing PyTorch Geometric extensions (CPU version)..."
    TORCH_VERSION=$(python -c "import torch; print(torch.__version__.split('+')[0])" 2>/dev/null || echo "2.2.0")
    pip install torch_scatter torch_sparse torch_cluster torch_spline_conv \
        -f https://data.pyg.org/whl/torch-${TORCH_VERSION}+cpu.html --quiet
fi

# Verify installations
echo "ğŸ” Verifying core library installations..."
python -c "
# FAISS verification
try:
    import faiss
    print('âœ… FAISS: version ' + getattr(faiss, '__version__', 'unknown'))
except ImportError as e:
    print('âŒ FAISS: Import failed - ' + str(e))

# PyTorch Geometric verification
try:
    import torch_geometric
    print('âœ… PyTorch Geometric: version ' + torch_geometric.__version__)
    
    # Test basic functionality
    import torch_geometric.data
    print('âœ… PyTorch Geometric: Core functionality available')
    
except ImportError as e:
    print('âŒ PyTorch Geometric: Import failed - ' + str(e))
    print('âš ï¸  Graph neural network features will be unavailable')

# PyTorch Scatter/Sparse verification  
try:
    import torch_scatter
    import torch_sparse
    print('âœ… PyTorch extensions: torch-scatter and torch-sparse available')
except ImportError as e:
    print('âš ï¸ PyTorch extensions: Some graph operations may be limited - ' + str(e))
" 2>/dev/null || echo "âš ï¸ Library verification encountered errors"

# Ensure Python can find the insightspike module
echo "ğŸ”§ Setting up Python module paths..."
CURRENT_DIR=$(pwd)
SRC_PATH="$CURRENT_DIR/src"

# Add src directory to Python path for current session
export PYTHONPATH="$SRC_PATH:$PYTHONPATH"

# Create a .pth file for persistent Python path (Colab-specific)
if [ "$IN_COLAB" = true ]; then
    SITE_PACKAGES=$(python -c "import site; print(site.getsitepackages()[0])")
    echo "$SRC_PATH" > "$SITE_PACKAGES/insightspike-dev.pth"
    echo "âœ… Added $SRC_PATH to Python path permanently"
fi

# Additional Colab-specific optimizations
if [ "$IN_COLAB" = true ]; then
    echo "âš¡ Applying Colab optimizations..."
    
    # Enable GPU if available
    if command -v nvidia-smi &> /dev/null; then
        echo "ğŸ® NVIDIA GPU detected - enabling CUDA acceleration"
        export CUDA_VISIBLE_DEVICES=0
    fi
    
    # Colab-specific directory setup
    mkdir -p /content/data
    mkdir -p /content/models
    mkdir -p /content/outputs
    
    # Ensure CLI scripts are in PATH for Colab
    echo "ğŸ”§ Setting up CLI environment..."
    export PATH="/root/.local/bin:$PATH"
    
    # Add editable install to ensure CLI is accessible
    echo "ğŸ”§ Installing InsightSpike-AI in editable mode..."
    pip install -e .
    
    # Create a direct CLI symlink if needed
    if [ ! -f "/usr/local/bin/insightspike" ]; then
        echo "ğŸ”— Creating CLI symlink..."
        ln -sf "$(which python)" /usr/local/bin/insightspike-python
        cat > /usr/local/bin/insightspike << 'EOF'
#!/bin/bash
python -m insightspike.cli.main "$@"
EOF
        chmod +x /usr/local/bin/insightspike
    fi
    
    echo "ğŸ“ Colab directories created"
fi

# Verify installation with comprehensive status reporting
echo "ğŸ” Verifying installation..."
python -c "
import torch
import numpy as np
print(f'âœ… PyTorch: {torch.__version__}')
print(f'âœ… CUDA available: {torch.cuda.is_available()}')
print(f'âœ… NumPy: {np.__version__}')

# FAISS status
try:
    import faiss
    print(f'âœ… FAISS: {getattr(faiss, \"__version__\", \"unknown\")} - Ready for similarity search')
except ImportError:
    print('âŒ FAISS: Not available - Memory systems will use baseline implementation')

# PyTorch Geometric status with detailed reporting
try:
    import torch_geometric
    print(f'âœ… PyTorch Geometric: {torch_geometric.__version__} - Graph operations enabled')
    
    # Test core components
    try:
        import torch_geometric.nn
        import torch_geometric.data
        print('âœ… PyTorch Geometric: Neural network layers available')
    except ImportError:
        print('âš ï¸ PyTorch Geometric: Some components missing')
        
    try:
        import torch_scatter
        import torch_sparse
        print('âœ… PyTorch extensions: Scatter and sparse operations available')
    except ImportError:
        print('âš ï¸ PyTorch extensions: Limited graph operations')
        
except ImportError:
    print('âŒ PyTorch Geometric: Not available')
    print('   Phase 2 graph neural networks will be disabled')
    print('   Phase 1 experiments will work normally')

# InsightSpike status
try:
    from insightspike.core.agents.main_agent import MainAgent
    print('âœ… InsightSpike-AI: Core modules loaded successfully')
    
    # Test instantiation
    try:
        agent = MainAgent()
        print('âœ… InsightSpike-AI: MainAgent instantiation successful')
        del agent  # Clean up
    except Exception as e:
        print(f'âš ï¸ InsightSpike-AI: MainAgent instantiation failed - {e}')
        
except ImportError as e:
    print(f'âŒ InsightSpike-AI: Core import failed - {e}')
    print('   Standalone implementations will be used')

# Test CLI command availability (fixed)
echo \"Testing CLI commands...\"
if command -v insightspike >/dev/null 2>&1; then
    echo \"CLI: 'insightspike' command available directly\"
    insightspike --version || echo \"CLI: Version check failed\"
else
    echo \"CLI: 'insightspike' not in PATH, using 'python -m insightspike.cli.main'\"
    python -m insightspike.cli.main --version || echo \"CLI: Module execution failed\"
fi

# Test configuration loading
try:
    import insightspike.config as config
    print('âœ… InsightSpike-AI: Configuration loaded')
except ImportError:
    print('âš ï¸  InsightSpike-AI: Configuration module not found (optional)')
"

# Test CLI availability
echo "ğŸ”§ Testing CLI command availability..."
if command -v insightspike &> /dev/null; then
    echo "âœ… InsightSpike CLI: Available via 'insightspike' command"
    echo "ğŸ“‹ CLI Help:"
    insightspike --help 2>/dev/null | head -10 || echo "  (CLI help not available, but command exists)"
else
    echo "âš ï¸  InsightSpike CLI: Command not found in PATH"
    echo "   You can still use: python -m insightspike.cli.main"
    
    # Test alternative CLI access
    python -c "
try:
    from insightspike.cli.main import main
    print('âœ… CLI Module: Available via python -m insightspike.cli.main')
except ImportError:
    print('âŒ CLI Module: Not available')
" 2>/dev/null || echo "âŒ CLI Module: Import test failed"
fi

# Final Python import test to ensure everything works
echo "ğŸ§ª Final import test..."
python -c "
import sys
print(f'ğŸ“ Current working directory: {sys.path[0] if sys.path else \"Unknown\"}')

try:
    from insightspike.core.agents.main_agent import MainAgent
    print('âœ… MainAgent: Successfully imported')
    
    # Quick instantiation test
    try:
        agent = MainAgent()
        print('âœ… MainAgent: Successfully instantiated')
    except Exception as e:
        print(f'âš ï¸  MainAgent: Import OK, but instantiation failed - {e}')
        
except ImportError as e:
    print(f'âŒ MainAgent: Import failed - {e}')
    print('ğŸ’¡ You may need to run: import sys; sys.path.insert(0, \"/content/InsightSpike-AI/src\")')

try:
    import insightspike.config as config
    print('âœ… Config: Successfully imported')
except ImportError:
    print('âš ï¸  Config: Import failed (may be optional)')
"

echo ""
echo "ğŸ‰ Setup completed successfully!"
echo "=================================="

# Generate setup summary
echo "ğŸ“‹ Setup Summary:"
python -c "
# Check available components and generate status report
components = {
    'CUDA/GPU': False,
    'FAISS': False, 
    'PyTorch Geometric': False,
    'InsightSpike Core': False
}

try:
    import torch
    components['CUDA/GPU'] = torch.cuda.is_available()
except:
    pass

try:
    import faiss
    components['FAISS'] = True
except:
    pass

try:
    import torch_geometric
    components['PyTorch Geometric'] = True
except:
    pass

try:
    from insightspike.core.agents.main_agent import MainAgent
    components['InsightSpike Core'] = True
except:
    pass

print('âœ… Available Components:')
for comp, available in components.items():
    status = 'âœ…' if available else 'âŒ'
    print(f'   {status} {comp}')

print('')
print('ğŸ”¬ Experiment Capabilities:')
print('   âœ… Phase 1: Dynamic Memory Construction (Always available)')
if components['FAISS']:
    print('   âœ… Enhanced similarity search with FAISS')
else:
    print('   âš ï¸  Baseline similarity search (FAISS unavailable)')
    
if components['PyTorch Geometric']:
    print('   âœ… Phase 2: Graph neural networks ready')
else:
    print('   âš ï¸  Phase 2: Graph operations limited (PyTorch Geometric unavailable)')
    
if components['CUDA/GPU']:
    print('   âœ… GPU acceleration enabled')
else:
    print('   ğŸ’» CPU-only mode (No GPU detected)')
"

if [ "$IN_COLAB" = true ]; then
    echo ""
    echo "ğŸ’¡ Ready to use InsightSpike-AI in Google Colab!"
    echo "ğŸ”¬ Phase 1 experiments are fully supported"
    echo "ğŸ“Š Run the Phase 1 notebook to start your experiments"
else
    echo ""
    echo "ğŸ’¡ Ready to use InsightSpike-AI in local environment!"
fi

echo ""
echo "ğŸš€ Next Steps:"
echo "  1. Run Phase 1 notebook cells sequentially"
echo "  2. Start with device setup (Cell 8)"
echo "  3. Load data (Cell 11) and run experiments"
echo ""
echo "ğŸ”§ Alternative CLI usage:"
echo "  !insightspike --help  # If CLI is available"
echo "  !python -m insightspike.cli.main --help  # Alternative method"
