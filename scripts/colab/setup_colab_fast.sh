#!/usr/bin/env bash
# InsightSpike-AI Fast Setup for Google Colab - Optimized for Quick Testing
# Resolves PyTorch Geometric hanging issues with prebuilt wheels and timeouts

set -e

echo "âš¡ InsightSpike-AI Fast Setup for Google Colab"
echo "ðŸŽ¯ Optimized for quick testing and development"
echo "ðŸ“¦ Using prebuilt wheels and timeout handling"
echo "ðŸ”§ Coordinated dependency strategy"

# Function to install with timeout
install_with_timeout() {
    local package="$1"
    local timeout="$2"
    echo "ðŸ“¦ Installing $package with ${timeout}s timeout..."
    timeout "$timeout" pip install -q "$package" || {
        echo "âš ï¸ $package installation timed out, skipping..."
        return 1
    }
    return 0
}

# Function to verify installation
verify_package() {
    local package="$1"
    local import_name="${2:-$package}"
    python -c "import $import_name; print(f'âœ… $package verified')" 2>/dev/null || {
        echo "âŒ $package verification failed"
        return 1
    }
}

# GPU Detection
echo ""
echo "ðŸ” Detecting hardware..."
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader 2>/dev/null || echo "âš ï¸ No GPU detected"

# 1. Essential Python packages (quick)
echo ""
echo "ðŸ Installing essential Python packages..."
pip install -q --upgrade pip setuptools wheel
pip install -q "numpy>=1.24.0,<3.0.0" pandas matplotlib

# 2. PyTorch with CUDA (fast prebuilt wheels)
echo ""
echo "ðŸ”¥ Installing PyTorch (CUDA 12.1 optimized)..."
install_with_timeout "torch==2.2.2 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121" 300

verify_package "torch" "torch"

# 3. PyTorch Geometric (with prebuilt wheels and fallback)
echo ""
echo "ðŸŒ Installing PyTorch Geometric (optimized)..."

# Use specific PyG wheel repository for faster installation
TORCH_VERSION=$(python -c "import torch; print(torch.__version__)" 2>/dev/null | cut -d'+' -f1)
CUDA_VERSION="cu121"

echo "ðŸ“¦ Using PyG wheels for torch-${TORCH_VERSION}+${CUDA_VERSION}"

# Install PyG components with timeout and fallback
install_with_timeout "torch-scatter --find-links https://data.pyg.org/whl/torch-${TORCH_VERSION}+${CUDA_VERSION}.html" 180 || {
    echo "ðŸ”„ Fallback: Installing torch-scatter from PyPI..."
    pip install -q torch-scatter
}

install_with_timeout "torch-sparse --find-links https://data.pyg.org/whl/torch-${TORCH_VERSION}+${CUDA_VERSION}.html" 180 || {
    echo "ðŸ”„ Fallback: Installing torch-sparse from PyPI..."
    pip install -q torch-sparse
}

install_with_timeout "torch-cluster --find-links https://data.pyg.org/whl/torch-${TORCH_VERSION}+${CUDA_VERSION}.html" 180 || {
    echo "ðŸ”„ Fallback: Skipping torch-cluster (optional)..."
}

install_with_timeout "torch-geometric" 120 || {
    echo "âŒ PyTorch Geometric installation failed"
    echo "â„¹ï¸ Continuing without PyG - basic functionality will work"
}

# 4. FAISS with GPU support (critical for performance) - Improved dependency handling
echo ""
echo "ðŸ” Installing FAISS with GPU support..."

# First ensure CUDA runtime libraries are installed
echo "ðŸ“¦ Installing CUDA runtime libraries..."
pip install -q nvidia-cuda-runtime-cu12 nvidia-cublas-cu12

# Install FAISS-GPU with explicit version and dependency checking
install_with_timeout "faiss-gpu-cu12>=1.11.0" 180 || {
    echo "âš ï¸ FAISS-GPU installation failed, trying without version constraint..."
    install_with_timeout "faiss-gpu-cu12" 120 || {
        echo "ðŸ”„ Fallback: Installing faiss-cpu..."
        pip install -q faiss-cpu
        echo "â„¹ï¸ Using CPU-only FAISS - GPU acceleration unavailable"
    }
}

# Verify FAISS installation with detailed error reporting
python -c "
try:
    import faiss
    print(f'âœ… FAISS {faiss.__version__} installed successfully')
    
    # Test GPU availability
    try:
        res = faiss.StandardGpuResources()
        print('ðŸš€ FAISS GPU support available')
    except Exception as e:
        print(f'âš ï¸ FAISS GPU unavailable (using CPU): {e}')
except ImportError as e:
    print(f'âŒ FAISS import failed: {e}')
    exit(1)
"

# 5. Hugging Face (essential for datasets)
echo ""
echo "ðŸ¤— Installing Hugging Face libraries..."
pip install -q transformers datasets tokenizers sentence-transformers

verify_package "transformers" "transformers"
verify_package "datasets" "datasets"

# 6. Core dependencies for InsightSpike
echo ""
echo "ðŸŽ¯ Installing InsightSpike core dependencies..."
pip install -q typer rich click pyyaml networkx scikit-learn

# 7. Quick poetry setup (lightweight)
echo ""
echo "ðŸ“¦ Setting up Poetry (lightweight)..."
curl -sSL https://install.python-poetry.org | python3 - &
POETRY_PID=$!

# Don't wait for Poetry, continue with essentials
echo "â© Continuing while Poetry installs in background..."

# 8. Install project in development mode
echo ""
echo "ðŸš€ Installing InsightSpike-AI..."
pip install -q -e .

# 9. Create necessary directories
echo ""
echo "ðŸ“ Creating project structure..."
mkdir -p experiment_results logs data/processed data/raw

# 10. Download minimal NLTK data
echo ""
echo "ðŸ“ Downloading essential NLTK data..."
python -c "
import nltk
import ssl
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

for corpus in ['punkt', 'stopwords']:
    try:
        nltk.download(corpus, quiet=True)
        print(f'âœ… {corpus} downloaded')
    except:
        print(f'âš ï¸ {corpus} download failed')
"

# 11. Wait for Poetry if still running
if kill -0 $POETRY_PID 2>/dev/null; then
    echo "â³ Waiting for Poetry installation to complete..."
    wait $POETRY_PID
fi

export PATH="/root/.local/bin:$PATH"
if command -v poetry &> /dev/null; then
    echo "âœ… Poetry available"
    
    # Clear Poetry cache for clean environment
    echo "ðŸ§¹ Clearing Poetry cache..."
    rm -rf ~/.cache/pypoetry || true
    rm -f poetry.lock || true
    
    poetry config virtualenvs.create false
    
    echo "ðŸ“¦ Installing remaining dependencies with Poetry..."
    poetry install --only main
else
    echo "âš ï¸ Poetry not available - using pip only"
fi

# 12. Final validation
echo ""
echo "ðŸ”¬ Running fast validation..."
python -c "
import sys
print(f'Python: {sys.version}')

# Core imports
try:
    import torch
    print(f'âœ… PyTorch {torch.__version__} (CUDA: {torch.cuda.is_available()})')
except:
    print('âŒ PyTorch failed')

try:
    import torch_geometric
    print(f'âœ… PyTorch Geometric {torch_geometric.__version__}')
except:
    print('âš ï¸ PyTorch Geometric not available (fallback mode)')

try:
    import faiss
    print(f'âœ… FAISS {faiss.__version__}')
    if hasattr(faiss, 'get_num_gpus'):
        print(f'   GPU support: {faiss.get_num_gpus()} GPUs')
except:
    print('âŒ FAISS failed')

try:
    import transformers, datasets
    print(f'âœ… HuggingFace: transformers-{transformers.__version__}, datasets-{datasets.__version__}')
except:
    print('âŒ HuggingFace libraries failed')

try:
    from insightspike.core.config import get_config
    print('âœ… InsightSpike-AI project available')
except:
    print('âš ï¸ InsightSpike-AI import issues (may work with PYTHONPATH)')
"

echo ""
echo "âš¡ Fast setup complete!"
echo "ðŸŽ¯ Total setup time: ~3-5 minutes"
echo ""
echo "ðŸ“‹ Dependencies coordinated via:"
echo "   â€¢ GPU packages installed first via pip (torch, faiss)"
echo "   â€¢ Remaining dependencies via Poetry (when available)"
echo "   â€¢ Strategic conflict avoidance"
echo ""
echo "ðŸ“ Quick start commands:"
echo "   ðŸ”¬ Test basic functionality:"
echo "     PYTHONPATH=src python scripts/colab/test_colab_env.py"
echo ""
echo "   ðŸ§ª Run minimal experiment:"
echo "     PYTHONPATH=src python scripts/colab/colab_large_scale_experiment.py --mode quick"
echo ""
echo "   ðŸš€ CLI test:"
echo "     PYTHONPATH=src python -m insightspike.cli --help"

# Save setup log
echo "$(date): Fast setup completed" >> logs/colab_setup.log
