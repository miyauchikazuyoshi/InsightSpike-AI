#!/usr/bin/env python3
"""
Colab faiss-gpu validation script
ãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ: Colabã§faiss-gpuãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ç¢ºèª
"""

import sys
import os

def test_faiss_gpu():
    """Faiss-GPUã®å‹•ä½œã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ” Testing faiss-gpu functionality...")
    
    try:
        import faiss
        print(f"âœ… Faiss imported successfully, version: {faiss.__version__}")
        
        # CPU Indexã®ãƒ†ã‚¹ãƒˆ
        dimension = 128
        n_vectors = 1000
        
        import numpy as np
        vectors = np.random.random((n_vectors, dimension)).astype('float32')
        
        # CPU Index
        index_cpu = faiss.IndexFlatL2(dimension)
        index_cpu.add(vectors)
        print(f"âœ… CPU Index created with {index_cpu.ntotal} vectors")
        
        # GPUå¯ç”¨æ€§ãƒ†ã‚¹ãƒˆ
        if hasattr(faiss, 'StandardGpuResources'):
            print("ğŸš€ GPU resources available, testing GPU index...")
            
            try:
                # GPU Resourcesã®ä½œæˆ
                gpu_res = faiss.StandardGpuResources()
                
                # CPU Indexã‚’GPUã«è»¢é€
                gpu_index = faiss.index_cpu_to_gpu(gpu_res, 0, index_cpu)
                print(f"âœ… GPU Index created with {gpu_index.ntotal} vectors")
                
                # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
                query = np.random.random((1, dimension)).astype('float32')
                distances, indices = gpu_index.search(query, 5)
                print(f"âœ… GPU search completed: found {len(indices[0])} results")
                
                return True
                
            except Exception as e:
                print(f"âŒ GPU index creation failed: {e}")
                return False
        else:
            print("âŒ GPU resources not available in this faiss installation")
            return False
            
    except ImportError as e:
        print(f"âŒ Faiss import failed: {e}")
        return False

def test_torch_gpu():
    """PyTorchã®GPUå‹•ä½œã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ” Testing PyTorch GPU functionality...")
    
    try:
        import torch
        print(f"âœ… PyTorch imported, version: {torch.__version__}")
        print(f"âœ… CUDA available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"âœ… CUDA device count: {torch.cuda.device_count()}")
            print(f"âœ… Current device: {torch.cuda.current_device()}")
            print(f"âœ… Device name: {torch.cuda.get_device_name(0)}")
            
            # ç°¡å˜ãªãƒ†ãƒ³ã‚µãƒ¼æ¼”ç®—ãƒ†ã‚¹ãƒˆ
            x = torch.randn(100, 100).cuda()
            y = torch.randn(100, 100).cuda()
            z = torch.mm(x, y)
            print("âœ… GPU tensor operations working")
            return True
        else:
            print("âŒ CUDA not available")
            return False
            
    except ImportError as e:
        print(f"âŒ PyTorch import failed: {e}")
        return False

def test_sentence_transformers():
    """SentenceTransformersã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ” Testing SentenceTransformers...")
    
    try:
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # ãƒ†ã‚¹ãƒˆæ–‡ã®åŸ‹ã‚è¾¼ã¿
        sentences = ["This is a test sentence.", "Another test sentence."]
        embeddings = model.encode(sentences)
        print(f"âœ… SentenceTransformers working, embedding shape: {embeddings.shape}")
        return True
        
    except ImportError as e:
        print(f"âŒ SentenceTransformers import failed: {e}")
        return False
    except Exception as e:
        print(f"âŒ SentenceTransformers test failed: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ Colab Environment Validation for InsightSpike-AI")
    print("=" * 50)
    
    results = []
    
    # PyTorchãƒ†ã‚¹ãƒˆ
    results.append(("PyTorch GPU", test_torch_gpu()))
    
    # Faiss-GPUãƒ†ã‚¹ãƒˆ  
    results.append(("Faiss GPU", test_faiss_gpu()))
    
    # SentenceTransformersãƒ†ã‚¹ãƒˆ
    results.append(("SentenceTransformers", test_sentence_transformers()))
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 50)
    print("ğŸ“Š Test Results Summary:")
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {test_name}: {status}")
    
    all_passed = all(result for _, result in results)
    
    if all_passed:
        print("\nğŸ‰ All tests passed! Colab environment is ready for InsightSpike-AI")
        print("ğŸ’¡ You can now run:")
        print("   - !PYTHONPATH=src python -m insightspike.cli embed --path data/raw/test_sentences.txt")
        print("   - !PYTHONPATH=src python -m insightspike.cli graph")
        print("   - !PYTHONPATH=src python -m insightspike.cli loop 'Your question here'")
    else:
        print("\nâŒ Some tests failed. Please check the setup.")
        sys.exit(1)

if __name__ == "__main__":
    main()
