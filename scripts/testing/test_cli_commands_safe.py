#!/usr/bin/env python3
"""
Safe CLI Command Testing
========================

Test CLI commands without triggering the LLM model loading segmentation fault.
"""

import sys
from pathlib import Path
import subprocess

# Add project root to Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "src"))

def test_config_info():
    """Test config-info command"""
    print("Testing config-info command...")
    try:
        result = subprocess.run([
            "poetry", "run", "insightspike", "config-info"
        ], 
        cwd=project_root,
        capture_output=True, 
        text=True, 
        timeout=10
        )
        
        if result.returncode == 0:
            print("‚úì config-info command works")
            return True
        else:
            print(f"‚úó config-info failed: {result.stderr}")
            return False
    except subprocess.TimeoutExpired:
        print("‚úó config-info command timed out")
        return False
    except Exception as e:
        print(f"‚úó config-info error: {e}")
        return False

def test_help_command():
    """Test help command"""
    print("Testing help command...")
    try:
        result = subprocess.run([
            "poetry", "run", "insightspike", "--help"
        ], 
        cwd=project_root,
        capture_output=True, 
        text=True, 
        timeout=10
        )
        
        if result.returncode == 0 and "Commands" in result.stdout:
            print("‚úì help command works")
            return True
        else:
            print(f"‚úó help failed: {result.stderr}")
            return False
    except subprocess.TimeoutExpired:
        print("‚úó help command timed out")
        return False
    except Exception as e:
        print(f"‚úó help error: {e}")
        return False

def test_insights_command():
    """Test insights command (should be safe as it just shows registry)"""
    print("Testing insights command...")
    try:
        result = subprocess.run([
            "poetry", "run", "insightspike", "insights"
        ], 
        cwd=project_root,
        capture_output=True, 
        text=True, 
        timeout=15
        )
        
        if result.returncode == 0:
            print("‚úì insights command works")
            return True
        else:
            print(f"‚úó insights failed: {result.stderr}")
            return False
    except subprocess.TimeoutExpired:
        print("‚úó insights command timed out")
        return False
    except Exception as e:
        print(f"‚úó insights error: {e}")
        return False

if __name__ == "__main__":
    print("=== Safe CLI Command Testing ===")
    
    tests = [
        test_help_command,
        test_config_info,
        test_insights_command,
    ]
    
    results = []
    for test in tests:
        results.append(test())
    
    print(f"\n=== Results ===")
    print(f"Help command: {'PASS' if results[0] else 'FAIL'}")
    print(f"Config info: {'PASS' if results[1] else 'FAIL'}")
    print(f"Insights command: {'PASS' if results[2] else 'FAIL'}")
    
    if all(results):
        print("\nüéâ All safe CLI commands work! Configuration issues resolved.")
        print("‚úì CLI can access config without 'llm' attribute errors")
        print("‚úì Basic commands execute successfully")
        print("‚ö†Ô∏è Note: LLM model loading still causes segmentation faults")
        sys.exit(0)
    else:
        print("\n‚ùå Some CLI commands still failing")
        sys.exit(1)
