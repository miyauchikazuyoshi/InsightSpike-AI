#!/usr/bin/env python3
"""
æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿé¨“å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
==============================

å®Ÿé¨“ã®æˆåŠŸç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã®å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
import json
import time
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from src.insightspike.config import load_config
from src.insightspike.implementations.datastore.sqlite_store import SQLiteDataStore
from src.insightspike.implementations.agents.datastore_agent import DataStoreMainAgent


def prepare_experiment(experiment_name: str):
    """å®Ÿé¨“ã®æº–å‚™"""
    print(f"=== å®Ÿé¨“æº–å‚™: {experiment_name} ===\n")
    
    # 1. å®Ÿé¨“ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    exp_dir = Path(f"experiments/{experiment_name}")
    exp_dir.mkdir(parents=True, exist_ok=True)
    
    # 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æº–å‚™
    db_path = exp_dir / "data" / "experiment.db"
    db_path.parent.mkdir(exist_ok=True)
    
    # 3. çµæœä¿å­˜å…ˆã®æº–å‚™
    results_dir = exp_dir / "results"
    results_dir.mkdir(exist_ok=True)
    
    return exp_dir, db_path, results_dir


def run_insightspike_experiment(db_path: Path, results_dir: Path):
    """InsightSpikeå®Ÿé¨“ã®å®Ÿè¡Œ"""
    print("\n=== InsightSpikeå®Ÿé¨“ ===\n")
    
    # 1. è¨­å®šã®èª­ã¿è¾¼ã¿
    config = load_config(config_path="./config_experiment_optimized.yaml")
    
    # 2. DataStoreã¨Agentã®åˆæœŸåŒ–
    datastore = SQLiteDataStore(str(db_path))
    agent = DataStoreMainAgent(datastore, config)
    
    # 3. å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    experiment_data = [
        # åŸºç¤çŸ¥è­˜ã®æŠ•å…¥
        "é‡å­åŠ›å­¦ã§ã¯ã€ç²’å­ã¯è¦³æ¸¬ã•ã‚Œã‚‹ã¾ã§è¤‡æ•°ã®çŠ¶æ…‹ã®é‡ã­åˆã‚ã›ã¨ã—ã¦å­˜åœ¨ã™ã‚‹",
        "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€è„³ã®ã‚·ãƒŠãƒ—ã‚¹çµåˆã‚’æ¨¡å€£ã—ãŸè¨ˆç®—ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹",
        "é€²åŒ–ã¯ã€è‡ªç„¶é¸æŠã«ã‚ˆã£ã¦æœ‰åˆ©ãªå½¢è³ªãŒæ¬¡ä¸–ä»£ã«å—ã‘ç¶™ãŒã‚Œã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚ã‚‹",
        "æ„è­˜ã¯ã€ä¸»è¦³çš„ãªçµŒé¨“ã¨è‡ªå·±èªè­˜ã‚’å«ã‚€è¤‡é›‘ãªç¾è±¡ã§ã‚ã‚‹",
        "æƒ…å ±ç†è«–ã§ã¯ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¯æƒ…å ±ã®ä¸ç¢ºå®Ÿæ€§ã‚’æ¸¬ã‚‹å°ºåº¦ã§ã‚ã‚‹",
        
        # é–¢é€£ã™ã‚‹æ¦‚å¿µ
        "é‡å­ã‚‚ã¤ã‚Œã¯ã€è¤‡æ•°ã®ç²’å­ãŒç›¸é–¢ã‚’æŒã¤éå±€æ‰€çš„ãªç¾è±¡ã§ã‚ã‚‹",
        "æ·±å±¤å­¦ç¿’ã¯ã€å¤šå±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸæ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã§ã‚ã‚‹",
        "å‰µç™ºã¨ã¯ã€å€‹ã€…ã®è¦ç´ ã®ç›¸äº’ä½œç”¨ã‹ã‚‰äºˆæ¸¬ä¸å¯èƒ½ãªæ€§è³ªãŒç”Ÿã¾ã‚Œã‚‹ã“ã¨ã§ã‚ã‚‹",
        "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ã€é‡å­ã®é‡ã­åˆã‚ã›ã‚’åˆ©ç”¨ã—ãŸæ–°ã—ã„è¨ˆç®—ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§ã‚ã‚‹",
        "è„³ã®å¯å¡‘æ€§ã«ã‚ˆã‚Šã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯çµŒé¨“ã«åŸºã¥ã„ã¦å¤‰åŒ–ã™ã‚‹",
    ]
    
    results = []
    
    # 4. çŸ¥è­˜ã®æŠ•å…¥ã¨å‡¦ç†
    print("çŸ¥è­˜ã‚’æŠ•å…¥ä¸­...")
    for i, text in enumerate(experiment_data):
        start_time = time.time()
        result = agent.process(text)
        processing_time = time.time() - start_time
        
        results.append({
            'index': i,
            'text': text,
            'has_spike': result.get('has_spike', False),
            'spike_confidence': result.get('spike_info', {}).get('confidence', 0),
            'processing_time': processing_time,
            'timestamp': datetime.now().isoformat()
        })
        
        if result.get('has_spike'):
            print(f"  âœ¨ ã‚¤ãƒ³ã‚µã‚¤ãƒˆæ¤œå‡º: {text[:50]}...")
        else:
            print(f"  ğŸ“ çŸ¥è­˜è¿½åŠ : {text[:50]}...")
    
    # 5. æ´å¯Ÿã‚’å¼•ãå‡ºã™è³ªå•
    print("\næ´å¯Ÿã‚’å¼•ãå‡ºã™è³ªå•ã‚’å‡¦ç†ä¸­...")
    insight_questions = [
        "é‡å­ã‚‚ã¤ã‚Œã¨æ„è­˜ã®é–“ã«é–¢é€£æ€§ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨é‡å­åŠ›å­¦ã®é¡ä¼¼ç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "å‰µç™ºç¾è±¡ã¯æ„è­˜ã®ç™ºç”Ÿã‚’èª¬æ˜ã§ãã¾ã™ã‹ï¼Ÿ",
        "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯äººå·¥æ„è­˜ã®å®Ÿç¾ã«è²¢çŒ®ã§ãã¾ã™ã‹ï¼Ÿ",
        "æƒ…å ±ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¨æ„è­˜ã®è¤‡é›‘æ€§ã«é–¢ä¿‚ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
    ]
    
    for question in insight_questions:
        start_time = time.time()
        result = agent.process(question)
        processing_time = time.time() - start_time
        
        results.append({
            'index': len(results),
            'text': question,
            'has_spike': result.get('has_spike', False),
            'spike_confidence': result.get('spike_info', {}).get('confidence', 0),
            'response': result.get('response', ''),
            'processing_time': processing_time,
            'timestamp': datetime.now().isoformat()
        })
        
        print(f"\nè³ªå•: {question}")
        if result.get('has_spike'):
            print(f"âœ¨ ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚¹ãƒ‘ã‚¤ã‚¯æ¤œå‡ºï¼ï¼ˆç¢ºä¿¡åº¦: {result.get('spike_info', {}).get('confidence', 0):.2f}ï¼‰")
        print(f"å›ç­”: {result.get('response', 'No response')[:200]}...")
    
    # 6. çµæœã®ä¿å­˜
    results_file = results_dir / f"insightspike_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {results_file}")
    
    # 7. çµ±è¨ˆæƒ…å ±
    total_spikes = sum(1 for r in results if r.get('has_spike'))
    avg_confidence = sum(r.get('spike_confidence', 0) for r in results if r.get('has_spike')) / max(total_spikes, 1)
    
    print(f"\n=== å®Ÿé¨“çµ±è¨ˆ ===")
    print(f"ç·å‡¦ç†æ•°: {len(results)}")
    print(f"ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚¹ãƒ‘ã‚¤ã‚¯æ•°: {total_spikes}")
    print(f"å¹³å‡ç¢ºä¿¡åº¦: {avg_confidence:.2f}")
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º: {datastore.get_stats()['db_size_bytes'] / 1024 / 1024:.2f} MB")
    
    return results


def compare_with_baseline(results_dir: Path):
    """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"""
    print("\n=== ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ ===\n")
    
    # ã“ã“ã§ã¯ãƒ¢ãƒƒã‚¯ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨æ¯”è¼ƒ
    from src.insightspike.config.models import InsightSpikeConfig, LLMConfig
    
    mock_config = InsightSpikeConfig(
        llm=LLMConfig(provider="mock", model="mock-model")
    )
    
    # ç°¡å˜ãªæ¯”è¼ƒå®Ÿè£…...
    print("ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒã¯åˆ¥é€”å®Ÿè£…ï¼‰")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("InsightSpikeæœ€é©åŒ–å®Ÿé¨“")
    print("=" * 50)
    
    # APIã‚­ãƒ¼ã®ç¢ºèª
    if not os.getenv("OPENAI_API_KEY") and not os.getenv("ANTHROPIC_API_KEY"):
        print("\nâš ï¸  è­¦å‘Š: LLM APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("MockProviderã§å®Ÿè¡Œã•ã‚Œã¾ã™")
        print("\næœ€è‰¯ã®çµæœã‚’å¾—ã‚‹ã«ã¯:")
        print("export OPENAI_API_KEY='your-key'")
        print("ã¾ãŸã¯")
        print("export ANTHROPIC_API_KEY='your-key'")
        input("\nEnterã‚­ãƒ¼ã§ç¶šè¡Œ...")
    
    # å®Ÿé¨“åã®è¨­å®š
    experiment_name = f"optimized_experiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # å®Ÿé¨“ã®æº–å‚™
    exp_dir, db_path, results_dir = prepare_experiment(experiment_name)
    
    # å®Ÿé¨“ã®å®Ÿè¡Œ
    results = run_insightspike_experiment(db_path, results_dir)
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    # compare_with_baseline(results_dir)
    
    print(f"\nâœ… å®Ÿé¨“å®Œäº†ï¼")
    print(f"çµæœã¯ä»¥ä¸‹ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™: {exp_dir}")


if __name__ == "__main__":
    main()