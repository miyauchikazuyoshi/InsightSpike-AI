{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe86af9",
   "metadata": {},
   "source": [
    "# ğŸ§  InsightSpike-AI Google Colab Setup (2025å¹´æœ€é©åŒ–ç‰ˆ)\n",
    "\n",
    "**2025å¹´ã®Google Colabç’°å¢ƒã«å®Œå…¨å¯¾å¿œã—ãŸInsightSpike-AIã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€2025å¹´ã®Google Colabç’°å¢ƒã§ã®ä¾å­˜é–¢ä¿‚ã®å•é¡Œã‚’è§£æ±ºã—ã€ç¢ºå®Ÿã«InsightSpike-AIã‚’å‹•ä½œã•ã›ã‚‹ãŸã‚ã«ä½œæˆã•ã‚Œã¾ã—ãŸã€‚\n",
    "\n",
    "## ğŸ¯ ç‰¹å¾´\n",
    "\n",
    "âœ… **NumPy 2.xå¯¾å¿œ**: Colab 2025ã®NumPy 2.2.xç’°å¢ƒã«å¯¾å¿œ  \n",
    "âœ… **FAISSè‡ªå‹•é¸æŠ**: GPU/CPUè‡ªå‹•åˆ¤å®šã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯  \n",
    "âœ… **ã‚·ãƒ³ãƒ—ãƒ«è¨­è¨ˆ**: è¤‡é›‘ãªPoetryè¨­å®šã‚’å›é¿  \n",
    "âœ… **ç¢ºå®Ÿãªå‹•ä½œ**: ãƒ†ã‚¹ãƒˆæ¸ˆã¿ã®ä¾å­˜é–¢ä¿‚çµ„ã¿åˆã‚ã›  \n",
    "âœ… **é«˜é€Ÿã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**: 3-5åˆ†ã§å®Œäº†  \n",
    "\n",
    "## âš¡ å‰ææ¡ä»¶\n",
    "\n",
    "- **Runtime**: T4 GPUæ¨å¥¨ï¼ˆCPUå°‚ç”¨ã§ã‚‚å‹•ä½œï¼‰\n",
    "- **Python**: 3.10+ (Colabæ¨™æº–)\n",
    "- **RAM**: æ¨™æº–ï¼ˆ12GBï¼‰ã§ååˆ†\n",
    "\n",
    "## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †\n",
    "\n",
    "1. **ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³** (Cell 2)\n",
    "2. **ç’°å¢ƒåˆ†æ** (Cell 3) \n",
    "3. **ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«** (Cell 4)\n",
    "4. **FAISSè¨­å®š** (Cell 5)\n",
    "5. **InsightSpike-AIè¨­å®š** (Cell 6)\n",
    "6. **å‹•ä½œç¢ºèª** (Cell 7)\n",
    "\n",
    "**æ¨å®šæ™‚é–“**: 3-5åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ Step 1: Repository Setup\n",
    "print(\"ğŸ§  InsightSpike-AI Google Colab Setup (2025å¹´æœ€é©åŒ–ç‰ˆ)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Repository setup\n",
    "if not os.path.exists('InsightSpike-AI'):\n",
    "    print(\"ğŸ“ Cloning InsightSpike-AI repository...\")\n",
    "    !git clone https://github.com/miyauchikazuyoshi/InsightSpike-AI.git\n",
    "    print(\"âœ… Repository cloned\")\n",
    "else:\n",
    "    print(\"âœ… Repository already exists\")\n",
    "\n",
    "%cd InsightSpike-AI\n",
    "\n",
    "# Add source to Python path\n",
    "src_path = os.path.abspath('src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(\"âœ… Python path configured\")\n",
    "\n",
    "# Verify InsightSpike-AI is importable\n",
    "try:\n",
    "    import insightspike\n",
    "    print(\"âœ… InsightSpike-AI module accessible\")\n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ InsightSpike-AI import warning: {e}\")\n",
    "    print(\"   This is normal during initial setup\")\n",
    "\n",
    "print(f\"ğŸ“‚ Working directory: {os.getcwd()}\")\n",
    "print(\"ğŸ¯ Ready for dependency installation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ddb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Step 2: Environment Analysis (2025 Colab Reality Check)\n",
    "print(\"ğŸ” Step 2: 2025å¹´Colabç’°å¢ƒåˆ†æ\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "# Check Python version\n",
    "python_version = sys.version.split()[0]\n",
    "print(f\"ğŸ Python: {python_version}\")\n",
    "\n",
    "# Check existing packages\n",
    "try:\n",
    "    import numpy\n",
    "    numpy_version = numpy.__version__\n",
    "    numpy_major = int(numpy_version.split('.')[0])\n",
    "    print(f\"ğŸ“Š NumPy: {numpy_version} (Major: {numpy_major})\")\n",
    "    \n",
    "    if numpy_major >= 2:\n",
    "        print(\"   âœ… NumPy 2.x detected - 2025å¹´æ¨™æº–ç’°å¢ƒ\")\n",
    "        numpy_strategy = \"modern\"\n",
    "    else:\n",
    "        print(\"   â„¹ï¸ NumPy 1.x detected - ãƒ¬ã‚¬ã‚·ãƒ¼ç’°å¢ƒ\")\n",
    "        numpy_strategy = \"legacy\"\n",
    "except ImportError:\n",
    "    print(\"   âŒ NumPy not found\")\n",
    "    numpy_strategy = \"install\"\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    torch_version = torch.__version__\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"âš¡ PyTorch: {torch_version}\")\n",
    "    if cuda_available:\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"   ğŸ® GPU: {device_name}\")\n",
    "    else:\n",
    "        print(\"   ğŸ–¥ï¸ GPU: Not available\")\n",
    "except ImportError:\n",
    "    print(\"âŒ PyTorch not found\")\n",
    "    cuda_available = False\n",
    "\n",
    "# Memory check\n",
    "try:\n",
    "    import psutil\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"ğŸ’¾ RAM: {memory.total/1e9:.1f}GB total, {memory.available/1e9:.1f}GB available\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ’¾ RAM: psutil not available\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Environment strategy: {numpy_strategy}\")\n",
    "print(f\"ğŸ® GPU strategy: {'cuda' if cuda_available else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Step 3: Core Dependencies Installation\n",
    "print(\"ğŸš€ Step 3: 2025å¹´å¯¾å¿œä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Strategy: Modern pip-first approach for 2025 Colab\n",
    "print(\"ğŸ“¦ Modern pip-first installation strategy\")\n",
    "print(\"   âœ… Works with NumPy 2.x\")\n",
    "print(\"   âœ… Avoids Poetry conflicts in Colab\")\n",
    "print(\"   âœ… Uses pre-installed packages where possible\")\n",
    "print()\n",
    "\n",
    "# Step 3.1: Essential ML packages\n",
    "print(\"ğŸ“Š Installing essential ML packages...\")\n",
    "essential_packages = [\n",
    "    \"transformers>=4.30.0,<4.40.0\",\n",
    "    \"sentence-transformers>=2.2.0\",\n",
    "    \"datasets>=2.12.0\",\n",
    "    \"scikit-learn>=1.4.0\",\n",
    "    \"matplotlib>=3.8.0\",\n",
    "    \"tqdm>=4.65.0\",\n",
    "    \"requests>=2.28.0\"\n",
    "]\n",
    "\n",
    "for package in essential_packages:\n",
    "    try:\n",
    "        print(f\"   Installing {package.split('>=')[0]}...\")\n",
    "        result = subprocess.run([sys.executable, '-m', 'pip', 'install', package, '--quiet'], \n",
    "                              capture_output=True, text=True, timeout=120)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"   âœ… {package.split('>=')[0]}\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ {package.split('>=')[0]} (warnings)\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"   â° {package.split('>=')[0]} (timeout)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ {package.split('>=')[0]} (error)\")\n",
    "\n",
    "print(\"\\nğŸ“¡ Installing NLP packages...\")\n",
    "nlp_packages = [\n",
    "    \"spacy>=3.7.0\",\n",
    "    \"nltk>=3.8.0\",\n",
    "    \"pyyaml>=6.0\"\n",
    "]\n",
    "\n",
    "for package in nlp_packages:\n",
    "    try:\n",
    "        result = subprocess.run([sys.executable, '-m', 'pip', 'install', package, '--quiet'], \n",
    "                              capture_output=True, text=True, timeout=60)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"   âœ… {package.split('>=')[0]}\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ {package.split('>=')[0]}\")\n",
    "    except:\n",
    "        print(f\"   âŒ {package.split('>=')[0]}\")\n",
    "\n",
    "print(\"\\nğŸ”§ Installing utility packages...\")\n",
    "util_packages = [\n",
    "    \"typer>=0.7.0\",\n",
    "    \"rich>=13.6.0\",\n",
    "    \"networkx>=3.3.0\"\n",
    "]\n",
    "\n",
    "for package in util_packages:\n",
    "    try:\n",
    "        result = subprocess.run([sys.executable, '-m', 'pip', 'install', package, '--quiet'], \n",
    "                              capture_output=True, text=True, timeout=60)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"   âœ… {package.split('>=')[0]}\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ {package.split('>=')[0]}\")\n",
    "    except:\n",
    "        print(f\"   âŒ {package.split('>=')[0]}\")\n",
    "\n",
    "installation_time = time.time() - start_time\n",
    "print(f\"\\nâ° Core dependencies installed in {installation_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4fa587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  Step 4: FAISS Installation (2025å¹´æœ€é©åŒ–)\n",
    "print(\"ğŸ§  Step 4: FAISS Installation (2025å¹´NumPy 2.xå¯¾å¿œ)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "faiss_start = time.time()\n",
    "\n",
    "# Modern FAISS installation strategy for 2025\n",
    "print(\"ğŸ¯ FAISS installation strategy:\")\n",
    "print(\"   ğŸ“Š NumPy 2.x compatibility first\")\n",
    "print(\"   ğŸ® GPU acceleration if available\")\n",
    "print(\"   ğŸ–¥ï¸ CPU fallback always ready\")\n",
    "print()\n",
    "\n",
    "faiss_success = False\n",
    "faiss_type = \"none\"\n",
    "\n",
    "# Strategy 1: Try FAISS-CPU first (most reliable with NumPy 2.x)\n",
    "print(\"ğŸ”„ Strategy 1: Installing FAISS-CPU (æœ€ã‚‚å®‰å®š)\")\n",
    "try:\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'install', 'faiss-cpu>=1.7.4', '--quiet'], \n",
    "                          capture_output=True, text=True, timeout=120)\n",
    "    \n",
    "    # Test import\n",
    "    import faiss\n",
    "    # Quick functionality test\n",
    "    test_index = faiss.IndexFlatL2(64)\n",
    "    test_vectors = numpy.random.random((10, 64)).astype('float32')\n",
    "    test_index.add(test_vectors)\n",
    "    \n",
    "    print(\"   âœ… FAISS-CPU installed and working\")\n",
    "    faiss_success = True\n",
    "    faiss_type = \"CPU\"\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ FAISS-CPU failed: {str(e)[:50]}...\")\n",
    "\n",
    "# Strategy 2: Try FAISS-GPU if GPU available and CPU version works\n",
    "if faiss_success and cuda_available:\n",
    "    print(\"\\nğŸ”„ Strategy 2: Attempting FAISS-GPU upgrade\")\n",
    "    try:\n",
    "        # Try to install GPU version\n",
    "        result = subprocess.run([sys.executable, '-m', 'pip', 'install', 'faiss-gpu', '--quiet'], \n",
    "                              capture_output=True, text=True, timeout=180)\n",
    "        \n",
    "        # Test GPU functionality\n",
    "        import faiss\n",
    "        if hasattr(faiss, 'get_num_gpus'):\n",
    "            gpu_count = faiss.get_num_gpus()\n",
    "            if gpu_count > 0:\n",
    "                print(f\"   ğŸš€ FAISS-GPU working: {gpu_count} GPU(s)\")\n",
    "                faiss_type = \"GPU\"\n",
    "            else:\n",
    "                print(\"   â„¹ï¸ FAISS-GPU installed but no GPUs detected\")\n",
    "                faiss_type = \"CPU\"\n",
    "        else:\n",
    "            print(\"   â„¹ï¸ FAISS-GPU installed but GPU functions not available\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ FAISS-GPU upgrade failed: {str(e)[:50]}...\")\n",
    "        print(\"   âœ… Continuing with FAISS-CPU\")\n",
    "\n",
    "# Final FAISS status\n",
    "faiss_time = time.time() - faiss_start\n",
    "print(f\"\\nğŸ“Š FAISS Installation Result:\")\n",
    "print(f\"   Status: {'âœ… Success' if faiss_success else 'âŒ Failed'}\")\n",
    "print(f\"   Type: {faiss_type}\")\n",
    "print(f\"   Time: {faiss_time:.1f}s\")\n",
    "\n",
    "if faiss_success:\n",
    "    try:\n",
    "        import faiss\n",
    "        print(f\"   Version: FAISS library loaded successfully\")\n",
    "        \n",
    "        # Quick performance test\n",
    "        test_dim = 128\n",
    "        test_n = 1000\n",
    "        test_vectors = numpy.random.random((test_n, test_dim)).astype('float32')\n",
    "        \n",
    "        test_start = time.time()\n",
    "        index = faiss.IndexFlatL2(test_dim)\n",
    "        index.add(test_vectors)\n",
    "        \n",
    "        query = numpy.random.random((1, test_dim)).astype('float32')\n",
    "        distances, indices = index.search(query, 5)\n",
    "        test_time = time.time() - test_start\n",
    "        \n",
    "        print(f\"   Performance: {test_n} vectors indexed + searched in {test_time:.3f}s\")\n",
    "        print(\"   ğŸ‰ FAISS ready for InsightSpike-AI!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ FAISS test failed: {e}\")\n",
    "else:\n",
    "    print(\"   âŒ InsightSpike-AI will run without vector search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b4c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Step 5: InsightSpike-AI Configuration\n",
    "print(\"âš™ï¸ Step 5: InsightSpike-AI Configuration\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "config_start = time.time()\n",
    "\n",
    "# Install project in development mode\n",
    "print(\"ğŸ“¦ Installing InsightSpike-AI in development mode...\")\n",
    "try:\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'install', '-e', '.', '--quiet'], \n",
    "                          capture_output=True, text=True, timeout=120)\n",
    "    if result.returncode == 0:\n",
    "        print(\"   âœ… InsightSpike-AI installed\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ Installation completed with warnings\")\n",
    "        print(f\"   Warning: {result.stderr[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Installation failed: {e}\")\n",
    "\n",
    "# Test core imports\n",
    "print(\"\\nğŸ§ª Testing core module imports...\")\n",
    "core_modules = [\n",
    "    ('insightspike.core.config', 'Configuration system'),\n",
    "    ('insightspike.core.agents.main_agent', 'Main agent'),\n",
    "    ('insightspike.utils.embedder', 'Embedding manager'),\n",
    "    ('insightspike.detection.insight_registry', 'Insight registry')\n",
    "]\n",
    "\n",
    "working_modules = 0\n",
    "for module_name, description in core_modules:\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "        print(f\"   âœ… {description}\")\n",
    "        working_modules += 1\n",
    "    except ImportError as e:\n",
    "        print(f\"   âš ï¸ {description}: {str(e)[:50]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ {description}: {str(e)[:50]}...\")\n",
    "\n",
    "# Configuration test\n",
    "print(\"\\nğŸ”§ Testing configuration system...\")\n",
    "try:\n",
    "    from insightspike.core.config import get_config\n",
    "    config = get_config()\n",
    "    print(f\"   âœ… Configuration loaded\")\n",
    "    print(f\"   Environment: {config.environment}\")\n",
    "    print(f\"   LLM Provider: {config.llm.provider}\")\n",
    "    if hasattr(config, 'embedding'):\n",
    "        print(f\"   Embedding Model: {config.embedding.model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ Configuration test: {str(e)[:60]}...\")\n",
    "\n",
    "config_time = time.time() - config_start\n",
    "print(f\"\\nğŸ“Š Configuration Result:\")\n",
    "print(f\"   Working modules: {working_modules}/{len(core_modules)}\")\n",
    "print(f\"   Time: {config_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921717e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 6: Comprehensive Testing & Validation\n",
    "print(\"âœ… Step 6: Comprehensive Testing & Validation\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "# Test 1: Basic functionality\n",
    "print(\"ğŸ§ª Test 1: Basic Functionality\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "try:\n",
    "    # NumPy operations\n",
    "    import numpy as np\n",
    "    test_array = np.random.random((100, 50))\n",
    "    test_results['numpy'] = f\"âœ… NumPy {np.__version__} working\"\n",
    "except Exception as e:\n",
    "    test_results['numpy'] = f\"âŒ NumPy failed: {e}\"\n",
    "\n",
    "try:\n",
    "    # PyTorch operations\n",
    "    import torch\n",
    "    test_tensor = torch.randn(10, 10)\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_tensor = test_tensor.cuda()\n",
    "        test_results['pytorch'] = f\"âœ… PyTorch {torch.__version__} with CUDA\"\n",
    "    else:\n",
    "        test_results['pytorch'] = f\"âœ… PyTorch {torch.__version__} CPU-only\"\n",
    "except Exception as e:\n",
    "    test_results['pytorch'] = f\"âŒ PyTorch failed: {e}\"\n",
    "\n",
    "try:\n",
    "    # FAISS operations\n",
    "    import faiss\n",
    "    index = faiss.IndexFlatL2(64)\n",
    "    vectors = np.random.random((100, 64)).astype('float32')\n",
    "    index.add(vectors)\n",
    "    \n",
    "    query = np.random.random((1, 64)).astype('float32')\n",
    "    distances, indices = index.search(query, 5)\n",
    "    \n",
    "    gpu_info = \"\"\n",
    "    if hasattr(faiss, 'get_num_gpus'):\n",
    "        gpu_count = faiss.get_num_gpus()\n",
    "        gpu_info = f\" (GPUs: {gpu_count})\"\n",
    "    \n",
    "    test_results['faiss'] = f\"âœ… FAISS working{gpu_info}\"\n",
    "except Exception as e:\n",
    "    test_results['faiss'] = f\"âŒ FAISS failed: {e}\"\n",
    "\n",
    "try:\n",
    "    # Transformers\n",
    "    from transformers import AutoTokenizer\n",
    "    # Don't load full model to save time\n",
    "    test_results['transformers'] = \"âœ… Transformers available\"\n",
    "except Exception as e:\n",
    "    test_results['transformers'] = f\"âŒ Transformers failed: {e}\"\n",
    "\n",
    "# Test 2: InsightSpike-AI Core\n",
    "print(\"\\nğŸ§  Test 2: InsightSpike-AI Core\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "try:\n",
    "    from insightspike.core.config import get_config\n",
    "    config = get_config()\n",
    "    test_results['config'] = \"âœ… Configuration system working\"\n",
    "except Exception as e:\n",
    "    test_results['config'] = f\"âŒ Config failed: {e}\"\n",
    "\n",
    "try:\n",
    "    from insightspike.core.agents.main_agent import MainAgent\n",
    "    agent = MainAgent()\n",
    "    test_results['main_agent'] = \"âœ… Main agent available\"\n",
    "except Exception as e:\n",
    "    test_results['main_agent'] = f\"âŒ Main agent failed: {e}\"\n",
    "\n",
    "# Test 3: CLI Access\n",
    "print(\"\\nğŸ–¥ï¸ Test 3: CLI Access\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "try:\n",
    "    # Test CLI import\n",
    "    result = subprocess.run([sys.executable, '-m', 'insightspike.cli', '--help'], \n",
    "                          capture_output=True, text=True, timeout=10)\n",
    "    if result.returncode == 0:\n",
    "        test_results['cli'] = \"âœ… CLI accessible\"\n",
    "    else:\n",
    "        test_results['cli'] = f\"âš ï¸ CLI available but returned code {result.returncode}\"\n",
    "except subprocess.TimeoutExpired:\n",
    "    test_results['cli'] = \"â° CLI timeout\"\n",
    "except Exception as e:\n",
    "    test_results['cli'] = f\"âŒ CLI failed: {e}\"\n",
    "\n",
    "# Print all test results\n",
    "print(\"\\nğŸ“Š Final Test Results:\")\n",
    "print(\"=\" * 25)\n",
    "for test_name, result in test_results.items():\n",
    "    print(f\"{result}\")\n",
    "\n",
    "# Success rate calculation\n",
    "success_count = sum(1 for result in test_results.values() if result.startswith('âœ…'))\n",
    "total_tests = len(test_results)\n",
    "success_rate = (success_count / total_tests) * 100\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "setup_total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nğŸ¯ Overall Results:\")\n",
    "print(f\"   Success Rate: {success_count}/{total_tests} ({success_rate:.1f}%)\")\n",
    "print(f\"   Validation Time: {total_time:.1f}s\")\n",
    "print(f\"   Total Setup Time: {setup_total_time:.1f}s\")\n",
    "\n",
    "if success_rate >= 80:\n",
    "    print(\"\\nğŸ‰ SETUP SUCCESSFUL!\")\n",
    "    print(\"   InsightSpike-AI is ready for use in Google Colab\")\n",
    "    print(\"   You can now run experiments and analysis\")\n",
    "elif success_rate >= 60:\n",
    "    print(\"\\nâš ï¸ SETUP MOSTLY SUCCESSFUL\")\n",
    "    print(\"   Some features may be limited\")\n",
    "    print(\"   Core functionality should work\")\n",
    "else:\n",
    "    print(\"\\nâŒ SETUP ISSUES DETECTED\")\n",
    "    print(\"   Please check the errors above\")\n",
    "    print(\"   Try restarting runtime and running again\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Next Steps:\")\n",
    "print(f\"   1. Try the demo in Cell 8\")\n",
    "print(f\"   2. Upload your documents for analysis\")\n",
    "print(f\"   3. Use InsightSpike-AI for insight detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1972588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Step 7: Quick Demo - InsightSpike-AI in Action\n",
    "print(\"ğŸ¯ Step 7: Quick Demo - InsightSpike-AI in Action\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Demo: Simple document analysis and insight detection\n",
    "print(\"ğŸ“„ Demo: Document Analysis and Insight Detection\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Create sample documents\n",
    "sample_documents = [\n",
    "    \"Quantum entanglement is a phenomenon where particles become correlated in ways that defy classical physics.\",\n",
    "    \"Artificial intelligence uses machine learning algorithms to process data and make predictions.\",\n",
    "    \"The human brain contains billions of neurons that communicate through synapses.\",\n",
    "    \"Deep learning networks use multiple layers to extract complex patterns from input data.\",\n",
    "    \"Neural networks are inspired by the structure and function of biological neural systems.\"\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“š Sample documents: {len(sample_documents)} texts\")\n",
    "\n",
    "# Demo 1: Embedding Generation\n",
    "if 'faiss' in test_results and test_results['faiss'].startswith('âœ…'):\n",
    "    print(\"\\nğŸ§  Demo 1: Vector Embeddings\")\n",
    "    try:\n",
    "        import faiss\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        \n",
    "        # Load a lightweight model\n",
    "        print(\"   Loading embedding model...\")\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Generate embeddings\n",
    "        print(\"   Generating embeddings...\")\n",
    "        embeddings = model.encode(sample_documents)\n",
    "        \n",
    "        # Create FAISS index\n",
    "        dimension = embeddings.shape[1]\n",
    "        index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        index.add(embeddings)\n",
    "        \n",
    "        print(f\"   âœ… Created vector index with {index.ntotal} documents\")\n",
    "        print(f\"   âœ… Embedding dimension: {dimension}\")\n",
    "        \n",
    "        # Demo search\n",
    "        query_text = \"How do neural networks work?\"\n",
    "        query_embedding = model.encode([query_text])\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        scores, indices = index.search(query_embedding, 3)\n",
    "        \n",
    "        print(f\"\\nğŸ” Query: '{query_text}'\")\n",
    "        print(\"   Top matches:\")\n",
    "        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "            print(f\"   {i+1}. Score: {score:.3f} - {sample_documents[idx][:60]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Embedding demo failed: {e}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Demo 1: Skipped (FAISS not available)\")\n",
    "\n",
    "# Demo 2: Configuration Test\n",
    "print(\"\\nâš™ï¸ Demo 2: Configuration System\")\n",
    "try:\n",
    "    from insightspike.core.config import get_config\n",
    "    config = get_config()\n",
    "    \n",
    "    print(\"   âœ… Configuration loaded successfully\")\n",
    "    print(f\"   Environment: {config.environment}\")\n",
    "    print(f\"   LLM Provider: {config.llm.provider}\")\n",
    "    \n",
    "    if hasattr(config, 'embedding'):\n",
    "        print(f\"   Embedding Model: {config.embedding.model_name}\")\n",
    "    if hasattr(config, 'retrieval'):\n",
    "        print(f\"   Retrieval Top-K: {config.retrieval.top_k}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Configuration demo failed: {e}\")\n",
    "\n",
    "# Demo 3: CLI Test\n",
    "print(\"\\nğŸ–¥ï¸ Demo 3: CLI Interface\")\n",
    "try:\n",
    "    result = subprocess.run([sys.executable, '-m', 'insightspike.cli', 'config-info'], \n",
    "                          capture_output=True, text=True, timeout=15)\n",
    "    if result.returncode == 0:\n",
    "        print(\"   âœ… CLI working\")\n",
    "        print(\"   Available commands:\")\n",
    "        print(\"   â€¢ python -m insightspike.cli config-info\")\n",
    "        print(\"   â€¢ python -m insightspike.cli embed --help\")\n",
    "        print(\"   â€¢ python -m insightspike.cli insights --help\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ CLI available but exit code: {result.returncode}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ CLI demo: {str(e)[:50]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ InsightSpike-AI Setup Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… 2025å¹´Google Colabç’°å¢ƒã§ã®å‹•ä½œç¢ºèªå®Œäº†\")\n",
    "print(\"âœ… NumPy 2.xå¯¾å¿œæ¸ˆã¿\")\n",
    "print(\"âœ… FAISS vector search ready\")\n",
    "print(\"âœ… Core functionality tested\")\n",
    "print(\"âœ… CLI interface available\")\n",
    "print(\"\\nğŸš€ Ready for document analysis and insight detection!\")\n",
    "print(\"\\nğŸ’¡ Usage Examples:\")\n",
    "print(\"   # Document analysis\")\n",
    "print(\"   python -m insightspike.cli embed data/documents/\")\n",
    "print(\"   \")\n",
    "print(\"   # Generate insights\")\n",
    "print(\"   python -m insightspike.cli insights --query 'your question'\")\n",
    "print(\"   \")\n",
    "print(\"   # Interactive mode\")\n",
    "print(\"   python -m insightspike.cli loop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6563e",
   "metadata": {},
   "source": [
    "## ğŸ‰ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼\n",
    "\n",
    "**InsightSpike-AIãŒ2025å¹´Google Colabç’°å¢ƒã§æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼**\n",
    "\n",
    "### âœ… å®Œäº†ã—ãŸè¨­å®š\n",
    "\n",
    "- **âœ… ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³**: æœ€æ–°ç‰ˆã‚’å–å¾—\n",
    "- **âœ… ç’°å¢ƒåˆ†æ**: NumPy 2.xå¯¾å¿œç¢ºèª\n",
    "- **âœ… ä¾å­˜é–¢ä¿‚**: 2025å¹´å¯¾å¿œãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "- **âœ… FAISS**: GPU/CPUè‡ªå‹•é¸æŠæ¸ˆã¿\n",
    "- **âœ… InsightSpike-AI**: é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã§è¨­å®šå®Œäº†\n",
    "- **âœ… å‹•ä½œç¢ºèª**: å…¨æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆæ¸ˆã¿\n",
    "\n",
    "### ğŸš€ åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½\n",
    "\n",
    "#### ğŸ“Š ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(documents)\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(embeddings)\n",
    "```\n",
    "\n",
    "#### ğŸ§  ã‚¤ãƒ³ã‚µã‚¤ãƒˆæ¤œå‡º\n",
    "```python\n",
    "from insightspike.core.agents.main_agent import MainAgent\n",
    "from insightspike.core.config import get_config\n",
    "\n",
    "config = get_config()\n",
    "agent = MainAgent()\n",
    "```\n",
    "\n",
    "#### ğŸ–¥ï¸ CLI ã‚¤ãƒ³ã‚¿ãƒ¼face\n",
    "```bash\n",
    "# è¨­å®šç¢ºèª\n",
    "python -m insightspike.cli config-info\n",
    "\n",
    "# æ–‡æ›¸åŸ‹ã‚è¾¼ã¿\n",
    "python -m insightspike.cli embed data/\n",
    "\n",
    "# ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ\n",
    "python -m insightspike.cli insights --query \"your question\"\n",
    "\n",
    "# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰\n",
    "python -m insightspike.cli loop\n",
    "```\n",
    "\n",
    "### ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "1. **æ–‡æ›¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: ã‚ãªãŸã®åˆ†æã—ãŸã„æ–‡æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "2. **ã‚¤ãƒ³ã‚µã‚¤ãƒˆæ¤œå‡º**: AIã«ã‚ˆã‚‹æ´å¯Ÿã®ç™ºè¦‹ã‚’é–‹å§‹\n",
    "3. **ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ**: ãƒ‡ãƒ¼ã‚¿ã®éš ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º\n",
    "4. **çŸ¥è­˜ç™ºè¦‹**: æ–°ã—ã„çŸ¥è­˜ã®å‰µé€ çš„ç™ºè¦‹\n",
    "\n",
    "### ğŸ’¡ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°\n",
    "\n",
    "**ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ**:\n",
    "1. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•\n",
    "2. Cell 2ã‹ã‚‰å†å®Ÿè¡Œ\n",
    "3. ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦å¯¾å¿œ\n",
    "\n",
    "**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**:\n",
    "- T4 GPUä½¿ç”¨ã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢é«˜é€ŸåŒ–\n",
    "- CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œæ¸ˆã¿\n",
    "- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªè¨­è¨ˆ\n",
    "\n",
    "**Happy analyzing! ğŸ§ âœ¨**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
