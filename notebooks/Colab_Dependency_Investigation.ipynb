{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Quick Test - Run a Simple InsightSpike-AI Function\n",
    "print(\"üß™ Testing InsightSpike-AI functionality...\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Test basic functionality that doesn't require complex setup\n",
    "    import numpy as np\n",
    "    import faiss\n",
    "    \n",
    "    # Simple embedding similarity test\n",
    "    print(\"üîç Testing basic embedding operations...\")\n",
    "    \n",
    "    # Create some sample embeddings (simulating document embeddings)\n",
    "    embeddings = np.random.random((5, 128)).astype('float32')\n",
    "    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)  # Normalize\n",
    "    \n",
    "    # Create FAISS index and add embeddings\n",
    "    index = faiss.IndexFlatIP(128)  # Inner product for cosine similarity\n",
    "    index.add(embeddings)\n",
    "    \n",
    "    # Test similarity search\n",
    "    query = embeddings[:1]  # Use first embedding as query\n",
    "    scores, indices = index.search(query, 3)  # Find top 3 similar\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(indices[0])} similar embeddings\")\n",
    "    print(f\"‚úÖ Similarity scores: {scores[0][:3]}\")\n",
    "    print(f\"‚úÖ FAISS index contains {index.ntotal} vectors\")\n",
    "    \n",
    "    print()\n",
    "    print(\"üéâ Basic functionality test passed!\")\n",
    "    print(\"üöÄ InsightSpike-AI is ready for document analysis and insights generation\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Test failed: {e}\")\n",
    "    print(\"üõ†Ô∏è Check the setup steps above\")\n",
    "\n",
    "print()\n",
    "print(\"üìù Next steps:\")\n",
    "print(\"   1. Upload your documents or data\")\n",
    "print(\"   2. Use InsightSpike-AI's document processing pipeline\")\n",
    "print(\"   3. Generate insights and embeddings\")\n",
    "print(\"   4. Analyze patterns and extract knowledge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b3d3a",
   "metadata": {},
   "source": [
    "## üéâ Setup Complete!\n",
    "\n",
    "**Congratulations!** You've successfully set up InsightSpike-AI with a Poetry-first approach.\n",
    "\n",
    "### üì¶ What's Installed\n",
    "\n",
    "- **Poetry** - Modern Python dependency management\n",
    "- **Core Dependencies** - All required packages from `pyproject.toml`\n",
    "- **FAISS-CPU** - Vector similarity search (reliable CPU version)\n",
    "- **NumPy, PyTorch** - Already available in Colab\n",
    "\n",
    "### üéØ What's Different from the Old Approach\n",
    "\n",
    "‚ùå **Before**: 1857 lines of complex large-scale experiment code  \n",
    "‚úÖ **Now**: Simple, reliable 7-cell setup\n",
    "\n",
    "‚ùå **Before**: Complex GPU detection and fallback logic  \n",
    "‚úÖ **Now**: Stable FAISS-CPU for consistent results\n",
    "\n",
    "‚ùå **Before**: Resource monitoring and checkpoint systems  \n",
    "‚úÖ **Now**: Focus on core functionality\n",
    "\n",
    "### üöÄ Ready to Go!\n",
    "\n",
    "Your InsightSpike-AI environment is now ready for:\n",
    "- Document processing and analysis\n",
    "- Embedding generation and similarity search\n",
    "- AI-powered insights extraction\n",
    "- Knowledge discovery and pattern analysis\n",
    "\n",
    "**Happy analyzing! üß†‚ú®**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a40e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Install Dependencies with Poetry\n",
    "print(\"üì¶ Installing project dependencies with Poetry...\")\n",
    "\n",
    "# Install dependencies from pyproject.toml\n",
    "!poetry install --only main\n",
    "\n",
    "print(\"‚úÖ Main dependencies installed\")\n",
    "\n",
    "# Install FAISS-CPU for maximum stability\n",
    "print(\"üß† Installing FAISS-CPU for vector operations...\")\n",
    "!poetry add faiss-cpu\n",
    "\n",
    "print(\"‚úÖ FAISS-CPU installed\")\n",
    "print(\"üéØ All dependencies ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c488ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verify Installation\n",
    "print(\"üîç Verifying installation...\")\n",
    "print()\n",
    "\n",
    "# Test core imports\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"‚úÖ NumPy: {np.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå NumPy import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "    print(f\"‚úÖ FAISS: CPU version ready\")\n",
    "    \n",
    "    # Quick functionality test\n",
    "    index = faiss.IndexFlatL2(64)  # 64-dimensional vectors\n",
    "    test_vectors = np.random.random((10, 64)).astype('float32')\n",
    "    index.add(test_vectors)\n",
    "    \n",
    "    # Search test\n",
    "    D, I = index.search(test_vectors[:2], 5)\n",
    "    print(f\"‚úÖ FAISS: Search test passed ({D.shape[0]} queries, {D.shape[1]} results)\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå FAISS import failed: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è FAISS functionality test failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è CUDA: Not available (using CPU)\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå PyTorch import failed: {e}\")\n",
    "\n",
    "print()\n",
    "print(\"üöÄ Setup complete! Ready to use InsightSpike-AI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6269db",
   "metadata": {},
   "source": [
    "## üéØ Usage Example\n",
    "\n",
    "Now you can use InsightSpike-AI with a simple, reliable setup:\n",
    "\n",
    "```python\n",
    "# Import InsightSpike-AI components\n",
    "from src.core.document_processor import DocumentProcessor\n",
    "from src.embeddings.vector_store import VectorStore\n",
    "from src.analysis.insight_engine import InsightEngine\n",
    "\n",
    "# Initialize components\n",
    "processor = DocumentProcessor()\n",
    "vector_store = VectorStore(use_gpu=False)  # Using CPU FAISS\n",
    "insight_engine = InsightEngine()\n",
    "\n",
    "# Process documents and generate insights\n",
    "documents = [\"Your documents here...\"]\n",
    "processed_docs = processor.process_batch(documents)\n",
    "vector_store.add_documents(processed_docs)\n",
    "insights = insight_engine.generate_insights(processed_docs)\n",
    "```\n",
    "\n",
    "### üéâ Benefits of This Setup\n",
    "\n",
    "- **Simple**: No complex GPU detection or large-scale experiment code\n",
    "- **Reliable**: Poetry manages dependencies consistently\n",
    "- **Stable**: FAISS-CPU works on all Colab environments\n",
    "- **Fast**: Sufficient performance for most use cases\n",
    "- **Compatible**: Works with free T4 GPU runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e60573",
   "metadata": {},
   "source": [
    "# üöÄ InsightSpike-AI Google Colab Setup (Poetry-First Approach)\n",
    "\n",
    "**Simple, Reliable Setup for InsightSpike-AI in Google Colab**\n",
    "\n",
    "This notebook provides a streamlined setup process for InsightSpike-AI using Poetry as the primary dependency manager. Designed for reliability and simplicity rather than complex large-scale experiments.\n",
    "\n",
    "‚ö° **Recommended Runtime**: T4 GPU (Free Tier Compatible)  \n",
    "üî• **Memory**: Standard RAM is sufficient  \n",
    "üí° **Focus**: FAISS-CPU for maximum stability\n",
    "\n",
    "## üéØ Setup Process\n",
    "\n",
    "1. **Repository Setup** - Clone and navigate to project\n",
    "2. **Poetry Installation** - Install Poetry package manager\n",
    "3. **Dependencies** - Install project dependencies via Poetry\n",
    "4. **FAISS Setup** - Use CPU version for reliability\n",
    "5. **Verification** - Test core functionality\n",
    "\n",
    "## ‚úÖ Key Features\n",
    "\n",
    "- Poetry-managed dependencies for consistency\n",
    "- FAISS-CPU for maximum compatibility\n",
    "- T4 GPU support (free tier friendly)\n",
    "- Simple, reliable installation process\n",
    "- Quick verification steps\n",
    "\n",
    "üéØ **Perfect for**: Document analysis, embeddings, and AI insights without complex GPU requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee6df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Repository Setup\n",
    "import os\n",
    "\n",
    "# Check if already cloned (for re-runs)\n",
    "if not os.path.exists('InsightSpike-AI'):\n",
    "    print(\"üìã Cloning InsightSpike-AI repository...\")\n",
    "    !git clone https://github.com/miyauchikazuyoshi/InsightSpike-AI.git\n",
    "    print(\"‚úÖ Repository cloned successfully\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists\")\n",
    "\n",
    "%cd InsightSpike-AI\n",
    "print(\"üìÇ Working directory set to InsightSpike-AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ba942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPUtil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "  Installing build dependencies ... \u001b[?25l  Installing build dependencies ... \u001b[?25l-done\n",
      "\bdone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-done\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25done\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-done\n",
      "\u001b[?25hBuilding wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (pyproject.toml) ... \u001b[?25done\n",
      "\u001b[?25hBuilding wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (pyproject.toml) ... \u001b[?25l-done\n",
      "\u001b[?25done\n",
      "\u001b[?25h  Created wheel for GPUtil: filename=gputil-1.4.0-py3-none-any.whl size=7436 sha256=a721152230d4507648df370c3beb0e3962536052e462aa30e0816d1710ff170d\n",
      "  Stored in directory: /Users/miyauchikazuyoshi/Library/Caches/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
      "Successfully built GPUtil\n",
      "  Created wheel for GPUtil: filename=gputil-1.4.0-py3-none-any.whl size=7436 sha256=a721152230d4507648df370c3beb0e3962536052e462aa30e0816d1710ff170d\n",
      "  Stored in directory: /Users/miyauchikazuyoshi/Library/Caches/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
      "Successfully built GPUtil\n",
      "Installing collected packages: GPUtil\n",
      "Successfully installed GPUtil-1.4.0\n",
      "Installing collected packages: GPUtil\n",
      "Successfully installed GPUtil-1.4.0\n",
      "üìä Initial Setup:\n",
      "   CPU: 13.3% | Memory: 64.7% (8.74GB)\n",
      "   N/A\n",
      "üöÄ Large-Scale Resource Monitoring Active\n",
      "üí° Use resource_monitor.log_resources('stage_name') throughout experiment\n",
      "üìä Initial Setup:\n",
      "   CPU: 13.3% | Memory: 64.7% (8.74GB)\n",
      "   N/A\n",
      "üöÄ Large-Scale Resource Monitoring Active\n",
      "üí° Use resource_monitor.log_resources('stage_name') throughout experiment\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Install Poetry Package Manager\n",
    "print(\"üîß Installing Poetry...\")\n",
    "\n",
    "# Install Poetry using the official installer\n",
    "!curl -sSL https://install.python-poetry.org | python3 -\n",
    "\n",
    "# Add Poetry to PATH for current session\n",
    "import os\n",
    "os.environ['PATH'] = f\"/root/.local/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Verify Poetry installation\n",
    "!poetry --version\n",
    "print(\"‚úÖ Poetry installed successfully\")\n",
    "\n",
    "# Configure Poetry for this environment\n",
    "!poetry config virtualenvs.create false\n",
    "print(\"‚úÖ Poetry configured for Colab environment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insightspike-ai-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
