#!/usr/bin/env python3
"""
3æ®µéšæ¯”è¼ƒï¼šãƒ™ãƒ¼ã‚¹LLM < RAG < InsightSpike
"""

import time
import os
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import pandas as pd
from collections import Counter

class ThreeWayComparison:
    """ãƒ™ãƒ¼ã‚¹LLMã€RAGã€InsightSpikeã®3æ®µéšæ¯”è¼ƒ"""
    
    def __init__(self):
        # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ãªã—ã®åŸºæœ¬å›ç­”
        self.base_llm_responses = {
            "sleep_memory": "ç¡çœ ã¨è¨˜æ†¶ã€å­¦ç¿’ã«ã¯é–¢ä¿‚ãŒã‚ã‚‹ã¨ä¸€èˆ¬çš„ã«è¨€ã‚ã‚Œã¦ã„ã¾ã™ã€‚ååˆ†ãªç¡çœ ã¯å­¦ç¿’åŠ¹ç‡ã‚’é«˜ã‚ã€è¨˜æ†¶ã®å®šç€ã«å½¹ç«‹ã¡ã¾ã™ã€‚",
            "exercise_brain": "é‹å‹•ã¯è„³ã®å¥åº·ã«è‰¯ã„å½±éŸ¿ã‚’ä¸ãˆã¾ã™ã€‚è¡€æµãŒæ”¹å–„ã•ã‚Œã€èªçŸ¥æ©Ÿèƒ½ã®å‘ä¸Šã«ã¤ãªãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
            "stress_immune": "ã‚¹ãƒˆãƒ¬ã‚¹ã¯å…ç–«ã‚·ã‚¹ãƒ†ãƒ ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚éåº¦ã®ã‚¹ãƒˆãƒ¬ã‚¹ã¯å…ç–«åŠ›ã‚’ä½ä¸‹ã•ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        }
        
        # RAGã«ã‚ˆã‚‹æ–‡æ›¸ãƒ™ãƒ¼ã‚¹ã®å›ç­”
        self.rag_responses = {
            "sleep_memory": "ç¡çœ ã¯è¨˜æ†¶ã®å®šç€ã«ãŠã„ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚REMç¡çœ ä¸­ã«è„³ã¯æ—¥ä¸­ã®è¨˜æ†¶ã‚’å‡¦ç†ã—ã€å­¦ç¿’ã—ãŸæƒ…å ±ã¯ã‚·ãƒŠãƒ—ã‚¹å¤‰åŒ–ã‚’å¼•ãèµ·ã“ã—ã€ç¡çœ ä¸è¶³ã¯å­¦ç¿’èƒ½åŠ›ã‚’è‘—ã—ãæãªã„ã¾ã™ã€‚",
            "exercise_brain": "é‹å‹•ã¯BDNFç”£ç”Ÿã‚’å¢—åŠ ã•ã›ã€è„³ã¸ã®è¡€æµã‚’æ”¹å–„ã—ã¾ã™ã€‚æœ‰é…¸ç´ é‹å‹•ã¯æµ·é¦¬ã®ä½“ç©ã‚’å¢—åŠ ã•ã›ã€ã‚¨ãƒ³ãƒ‰ãƒ«ãƒ•ã‚£ãƒ³ã®æ”¾å‡ºã‚’ä¿ƒé€²ã—ã¾ã™ã€‚",
            "stress_immune": "æ…¢æ€§çš„ãªã‚¹ãƒˆãƒ¬ã‚¹ã¯ã‚³ãƒ«ãƒã‚¾ãƒ¼ãƒ«ã®æ”¾å‡ºã‚’å¼•ãèµ·ã“ã—ã€ãƒªãƒ³ãƒ‘çƒã®ç”£ç”Ÿã¨æ©Ÿèƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã¾ã™ã€‚HPAè»¸ãŒå¿ƒç†çš„ã‚¹ãƒˆãƒ¬ã‚¹ã¨å…ç–«åå¿œã‚’çµã³ã¤ã‘ã¦ã„ã¾ã™ã€‚"
        }
        
        # InsightSpikeã«ã‚ˆã‚‹æ´å¯Ÿã‚’å«ã‚€å›ç­”
        self.insightspike_responses = {
            "sleep_memory": "ç¡çœ ã€è¨˜æ†¶ã€å­¦ç¿’ã¯ç›¸äº’ã«é€£æºã™ã‚‹é‡è¦ãªã‚·ã‚¹ãƒ†ãƒ ã‚’å½¢æˆã—ã¦ã„ã¾ã™ã€‚REMç¡çœ ã¨æ·±ã„ç¡çœ æ®µéšã§ã¯ã€è„³ã¯ã‚·ãƒŠãƒ—ã‚¹å¼·åŒ–ã¨æµ·é¦¬-çš®è³ªè»¢é€ã‚’é€šã˜ã¦è¨˜æ†¶ã‚’çµ±åˆã—ã¾ã™ã€‚ã“ã®å› æœé€£é–ã¯åŒæ–¹å‘ã«ä½œç”¨ã—ã€è³ªã®é«˜ã„ç¡çœ ãŒè¨˜æ†¶ã®å®šç€ã‚’æ”¹å–„ã—ã€ãã‚ŒãŒå­¦ç¿’åŠ¹ç‡ã‚’é«˜ã‚ã€ä¸€æ–¹ã§å­¦ç¿’æ´»å‹•ãŒç¡çœ æ§‹é€ ã«å½±éŸ¿ã‚’ä¸ãˆã¾ã™ã€‚ã¤ã¾ã‚Šã€ã“ã‚Œã‚‰3ã¤ã®è¦ç´ ã¯å˜ã«é–¢é€£ã—ã¦ã„ã‚‹ã ã‘ã§ãªãã€ç›¸äº’ã«å¼·åŒ–ã—åˆã†å¾ªç’°çš„ãªã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦æ©Ÿèƒ½ã—ã¦ã„ã‚‹ã®ã§ã™ã€‚",
            "exercise_brain": "é‹å‹•ã¯è¤‡æ•°ã®å› æœçµŒè·¯ã‚’é€šã˜ã¦è„³ã®å¥åº·ã«æ·±ã„å½±éŸ¿ã‚’ä¸ãˆã¾ã™ã€‚èº«ä½“æ´»å‹•ã¯BDNFç”£ç”Ÿã‚’å¢—åŠ ã•ã›ã€ç¥çµŒæ–°ç”Ÿã¨ã‚·ãƒŠãƒ—ã‚¹å¯å¡‘æ€§ã‚’åˆºæ¿€ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€å¿ƒè¡€ç®¡æ©Ÿèƒ½ã®æ”¹å–„ã«ã‚ˆã‚Šè„³è¡€æµãŒå¢—åŠ ã—ã€å¿…é ˆæ „é¤Šç´ ã‚’ä¾›çµ¦ã—ãªãŒã‚‰ä»£è¬è€å»ƒç‰©ã‚’é™¤å»ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ç›¸ä¹—çš„ã«ä½œç”¨ã—ã€BDNFèª˜ç™ºæ€§ã®ç¥çµŒå¯å¡‘æ€§ãŒè¡€ç®¡ã®å¥åº·æ”¹å–„ã«ã‚ˆã£ã¦æ”¯ãˆã‚‰ã‚Œã€èªçŸ¥æ©Ÿèƒ½ä½ä¸‹ã‹ã‚‰ä¿è­·ã™ã‚‹æ­£ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã‚’ä½œã‚Šå‡ºã—ã¾ã™ã€‚",
            "stress_immune": "ã‚¹ãƒˆãƒ¬ã‚¹ã¨å…ç–«æ©Ÿèƒ½ã¯HPAè»¸ã‚’é€šã˜ã¦å› æœçš„ã«çµã³ã¤ã„ã¦ã„ã¾ã™ã€‚æ…¢æ€§ã‚¹ãƒˆãƒ¬ã‚¹ã¯æŒç¶šçš„ãªã‚³ãƒ«ãƒã‚¾ãƒ¼ãƒ«æ”¾å‡ºã‚’å¼•ãèµ·ã“ã—ã€ãƒªãƒ³ãƒ‘çƒæ´»æ€§ã¨æŠ—ä½“ç”£ç”Ÿã‚’ç›´æ¥æŠ‘åˆ¶ã—ã¾ã™ã€‚ã“ã‚Œã¯ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰åŠ¹æœã‚’ç”Ÿã¿å‡ºã—ã€å…ç–«ç›£è¦–ã®ä½ä¸‹ãŒæ„ŸæŸ“æ„Ÿå—æ€§ã‚’å¢—åŠ ã•ã›ã€ãã‚ŒãŒã•ã‚‰ã«èº«ä½“ã«ã‚¹ãƒˆãƒ¬ã‚¹ã‚’ä¸ãˆã¾ã™ã€‚ã“ã®åŒæ–¹å‘ã®é–¢ä¿‚ã¯ã€å…ç–«æ©Ÿèƒ½ä¸å…¨ã‚‚ã‚¹ãƒˆãƒ¬ã‚¹åå¿œã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã€æ½œåœ¨çš„ã«æœ‰å®³ãªã‚µã‚¤ã‚¯ãƒ«ã‚’ä½œã‚Šå‡ºã—ã¾ã™ã€‚"
        }
    
    def run_base_llm(self, query: str) -> Dict:
        """ãƒ™ãƒ¼ã‚¹LLMï¼ˆçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ãªã—ï¼‰"""
        start_time = time.time()
        
        # ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
        query_key = self._get_query_key(query)
        response = self.base_llm_responses.get(query_key, "ã“ã®è³ªå•ã«å¯¾ã™ã‚‹ä¸€èˆ¬çš„ãªå›ç­”ã‚’æä¾›ã—ã¾ã™ã€‚")
        
        return {
            "method": "ãƒ™ãƒ¼ã‚¹LLM",
            "query": query,
            "response": response,
            "time": time.time() - start_time,
            "has_documents": False,
            "has_insights": False
        }
    
    def run_rag(self, query: str, documents: List[str]) -> Dict:
        """å¾“æ¥ã®RAGï¼ˆæ–‡æ›¸æ¤œç´¢ã‚ã‚Šã€æ´å¯Ÿãªã—ï¼‰"""
        start_time = time.time()
        
        # æ–‡æ›¸ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºï¼ˆå˜ç´”ãªé€£çµï¼‰
        query_key = self._get_query_key(query)
        response = self.rag_responses.get(query_key, "æä¾›ã•ã‚ŒãŸæ–‡æ›¸ã«åŸºã¥ã„ã¦å›ç­”ã—ã¾ã™ã€‚")
        
        return {
            "method": "RAG",
            "query": query,
            "response": response,
            "time": time.time() - start_time,
            "has_documents": True,
            "has_insights": False,
            "doc_count": len(documents)
        }
    
    def run_insightspike(self, query: str, documents: List[str]) -> Dict:
        """InsightSpikeï¼ˆæ–‡æ›¸æ¤œç´¢ï¼‹æ´å¯Ÿæ¤œå‡ºï¼‹æ·±ã„ç†è§£ï¼‰"""
        start_time = time.time()
        
        # æ´å¯Ÿã‚’æ¤œå‡º
        insight_detected, insight_type = self._detect_insights(query, documents)
        
        # æ´å¯Ÿã‚’æ´»ç”¨ã—ãŸå›ç­”ç”Ÿæˆ
        query_key = self._get_query_key(query)
        response = self.insightspike_responses.get(query_key, "æ´å¯Ÿã«åŸºã¥ã„ãŸè©³ç´°ãªåˆ†æã‚’æä¾›ã—ã¾ã™ã€‚")
        
        return {
            "method": "InsightSpike",
            "query": query,
            "response": response,
            "time": time.time() - start_time,
            "has_documents": True,
            "has_insights": True,
            "insight_type": insight_type,
            "doc_count": len(documents)
        }
    
    def _get_query_key(self, query: str) -> str:
        """ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        query_lower = query.lower()
        if "sleep" in query_lower and ("memory" in query_lower or "learning" in query_lower):
            return "sleep_memory"
        elif "exercise" in query_lower and "brain" in query_lower:
            return "exercise_brain"
        elif "stress" in query_lower and "immune" in query_lower:
            return "stress_immune"
        return "unknown"
    
    def _detect_insights(self, query: str, documents: List[str]) -> Tuple[bool, str]:
        """æ´å¯Ÿã‚’æ¤œå‡º"""
        combined_text = " ".join(documents).lower()
        
        # å› æœé–¢ä¿‚ã®æ¤œå‡º
        causal_keywords = ["plays a crucial role", "triggers", "leads to", "causes", "affects"]
        if sum(1 for kw in causal_keywords if kw in combined_text) >= 2:
            return True, "causal_relationship"
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        if "studies show" in combined_text or "research indicates" in combined_text:
            return True, "pattern_recognition"
        
        return True, "conceptual_bridge"  # ãƒ‡ãƒ¢ç”¨ã«å¸¸ã«ä½•ã‹æ¤œå‡º
    
    def run_comparison(self, test_cases: List[Dict]) -> pd.DataFrame:
        """3æ®µéšæ¯”è¼ƒã‚’å®Ÿè¡Œ"""
        results = []
        
        for i, test_case in enumerate(test_cases):
            print(f"\n{'='*70}")
            print(f"ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i+1}: {test_case['query']}")
            print('='*70)
            
            # 1. ãƒ™ãƒ¼ã‚¹LLM
            print("\n1ï¸âƒ£ ãƒ™ãƒ¼ã‚¹LLMï¼ˆçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ãªã—ï¼‰...")
            base_result = self.run_base_llm(test_case["query"])
            
            # 2. RAG
            print("2ï¸âƒ£ RAGï¼ˆæ–‡æ›¸æ¤œç´¢ã‚ã‚Šï¼‰...")
            rag_result = self.run_rag(test_case["query"], test_case["documents"])
            
            # 3. InsightSpike
            print("3ï¸âƒ£ InsightSpikeï¼ˆæ–‡æ›¸æ¤œç´¢ï¼‹æ´å¯Ÿï¼‰...")
            spike_result = self.run_insightspike(test_case["query"], test_case["documents"])
            
            # çµæœã‚’æ¯”è¼ƒ
            comparison = {
                "test_id": i + 1,
                "query": test_case["query"],
                
                # ãƒ™ãƒ¼ã‚¹LLM
                "base_response": base_result["response"],
                "base_length": len(base_result["response"]),
                
                # RAG
                "rag_response": rag_result["response"],
                "rag_length": len(rag_result["response"]),
                "rag_improvement": len(rag_result["response"]) / len(base_result["response"]),
                
                # InsightSpike
                "spike_response": spike_result["response"],
                "spike_length": len(spike_result["response"]),
                "spike_improvement_over_base": len(spike_result["response"]) / len(base_result["response"]),
                "spike_improvement_over_rag": len(spike_result["response"]) / len(rag_result["response"]),
                "insight_type": spike_result["insight_type"]
            }
            
            results.append(comparison)
            
            # çµæœã‚’è¡¨ç¤º
            print(f"\nğŸ“Š æ¯”è¼ƒçµæœ:")
            print(f"ãƒ™ãƒ¼ã‚¹LLM: {base_result['response'][:60]}... ({len(base_result['response'])}æ–‡å­—)")
            print(f"RAG: {rag_result['response'][:60]}... ({len(rag_result['response'])}æ–‡å­—)")
            print(f"InsightSpike: {spike_result['response'][:60]}... ({len(spike_result['response'])}æ–‡å­—)")
            print(f"\næ”¹å–„ç‡:")
            print(f"  RAG vs ãƒ™ãƒ¼ã‚¹LLM: {comparison['rag_improvement']:.1f}å€")
            print(f"  InsightSpike vs ãƒ™ãƒ¼ã‚¹LLM: {comparison['spike_improvement_over_base']:.1f}å€")
            print(f"  InsightSpike vs RAG: {comparison['spike_improvement_over_rag']:.1f}å€")
        
        return pd.DataFrame(results)
    
    def generate_test_cases(self) -> List[Dict]:
        """ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹"""
        return [
            {
                "query": "What is the relationship between sleep, memory, and learning?",
                "documents": [
                    "Sleep plays a crucial role in memory consolidation. During REM sleep, the brain processes and strengthens memories.",
                    "Learning new information triggers synaptic changes that are consolidated during sleep phases.",
                    "Studies show that sleep deprivation significantly impairs both learning ability and memory retention.",
                    "The hippocampus transfers memories to the cortex during deep sleep, enabling long-term storage."
                ]
            },
            {
                "query": "How does exercise affect brain health?",
                "documents": [
                    "Exercise increases BDNF production, which promotes neuron growth.",
                    "Regular physical activity improves blood flow to the brain.",
                    "Aerobic exercise has been shown to increase hippocampal volume.",
                    "Exercise triggers endorphin release and reduces brain inflammation."
                ]
            },
            {
                "query": "What connects stress and immune function?",
                "documents": [
                    "Chronic stress triggers sustained cortisol release, which suppresses immune cells.",
                    "Stress affects lymphocyte production and function.",
                    "The HPA axis links psychological stress to physical immune responses.",
                    "Studies consistently show increased illness rates with chronic stress."
                ]
            }
        ]
    
    def save_results(self, df: pd.DataFrame):
        """çµæœã‚’ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        os.makedirs("experiments/results", exist_ok=True)
        
        # è¦ç´„ãƒ‡ãƒ¼ã‚¿
        summary_data = []
        for _, row in df.iterrows():
            summary_data.append({
                "è³ªå•": row["query"][:30] + "...",
                "ãƒ™ãƒ¼ã‚¹LLM": f"{row['base_length']}æ–‡å­—",
                "RAG": f"{row['rag_length']}æ–‡å­— (Ã—{row['rag_improvement']:.1f})",
                "InsightSpike": f"{row['spike_length']}æ–‡å­— (Ã—{row['spike_improvement_over_base']:.1f})",
                "æ´å¯Ÿã‚¿ã‚¤ãƒ—": row["insight_type"],
                "æœ€çµ‚æ”¹å–„ç‡": f"Ã—{row['spike_improvement_over_rag']:.1f}"
            })
        
        summary_df = pd.DataFrame(summary_data)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        full_path = f"experiments/results/three_way_comparison_{timestamp}.csv"
        summary_path = f"experiments/results/three_way_summary_{timestamp}.csv"
        
        df.to_csv(full_path, index=False, encoding='utf-8-sig')
        summary_df.to_csv(summary_path, index=False, encoding='utf-8-sig')
        
        print(f"\nâœ… çµæœã‚’ä¿å­˜:")
        print(f"   - è©³ç´°: {full_path}")
        print(f"   - è¦ç´„: {summary_path}")
        
        return summary_df
    
    def print_final_summary(self, df: pd.DataFrame, summary_df: pd.DataFrame):
        """æœ€çµ‚ã‚µãƒãƒªãƒ¼"""
        print("\n" + "="*70)
        print("ğŸ¯ 3æ®µéšæ¯”è¼ƒçµæœï¼šãƒ™ãƒ¼ã‚¹LLM < RAG < InsightSpike")
        print("="*70)
        
        # å¹³å‡æ”¹å–„ç‡ã‚’è¨ˆç®—
        avg_rag_over_base = df["rag_improvement"].mean()
        avg_spike_over_base = df["spike_improvement_over_base"].mean()
        avg_spike_over_rag = df["spike_improvement_over_rag"].mean()
        
        print(f"\nğŸ“ˆ å¹³å‡æ”¹å–„ç‡:")
        print(f"   1ï¸âƒ£ ãƒ™ãƒ¼ã‚¹LLM â†’ 2ï¸âƒ£ RAG: Ã—{avg_rag_over_base:.1f} (åŸºæœ¬çš„ãªæ–‡æ›¸æƒ…å ±ã‚’è¿½åŠ )")
        print(f"   2ï¸âƒ£ RAG â†’ 3ï¸âƒ£ InsightSpike: Ã—{avg_spike_over_rag:.1f} (æ´å¯Ÿã«ã‚ˆã‚‹æ·±ã„ç†è§£)")
        print(f"   1ï¸âƒ£ ãƒ™ãƒ¼ã‚¹LLM â†’ 3ï¸âƒ£ InsightSpike: Ã—{avg_spike_over_base:.1f} (ç·åˆçš„ãªæ”¹å–„)")
        
        print("\nğŸ¨ å„æ‰‹æ³•ã®ç‰¹å¾´:")
        print("   1ï¸âƒ£ ãƒ™ãƒ¼ã‚¹LLM: ä¸€èˆ¬çš„ãªçŸ¥è­˜ã®ã¿ï¼ˆçŸ­ã„ã€è¡¨é¢çš„ï¼‰")
        print("   2ï¸âƒ£ RAG: æ–‡æ›¸ã®æƒ…å ±ã‚’å«ã‚€ï¼ˆä¸­ç¨‹åº¦ã€äº‹å®Ÿãƒ™ãƒ¼ã‚¹ï¼‰")
        print("   3ï¸âƒ£ InsightSpike: æ´å¯Ÿã¨å› æœé–¢ä¿‚ã‚’å«ã‚€ï¼ˆè©³ç´°ã€æ·±ã„ç†è§£ï¼‰")
        
        print("\nğŸ“Š æ¯”è¼ƒè¡¨:")
        print(summary_df.to_string(index=False))
        
        print("\nâœ¨ çµè«–: ãƒ™ãƒ¼ã‚¹LLM < RAG < InsightSpike ã®é †ã§å›ç­”å“è³ªãŒå‘ä¸Šï¼")


if __name__ == "__main__":
    print("ğŸš€ 3æ®µéšæ¯”è¼ƒãƒ‡ãƒ¢ï¼šãƒ™ãƒ¼ã‚¹LLM vs RAG vs InsightSpike")
    print("   å„æ‰‹æ³•ã®å›ç­”å“è³ªã®é•ã„ã‚’æ˜ç¢ºã«ç¤ºã—ã¾ã™\n")
    
    experiment = ThreeWayComparison()
    test_cases = experiment.generate_test_cases()
    
    # æ¯”è¼ƒå®Ÿè¡Œ
    results_df = experiment.run_comparison(test_cases)
    
    # çµæœä¿å­˜ã¨è¡¨ç¤º
    summary_df = experiment.save_results(results_df)
    experiment.print_final_summary(results_df, summary_df)