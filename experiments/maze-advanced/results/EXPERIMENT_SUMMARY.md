# 純粋経験学習実験まとめ

## 実験結果比較

### 1. 純粋経験学習（ゴールエピソードのみ）
- **5x5迷路**: 失敗（100ステップで位置(1,0)に停滞）
- **10x10迷路**: 失敗（200ステップで10位置のみ訪問）
- **問題点**: ゴール情報だけでは行動選択の手がかりが不足

### 2. 純粋経験学習（5初期エピソード版）
- **5x5迷路**: **成功！8ステップで到達（最短経路）**
- **10x10迷路**: 失敗（(1,1)で停滞、「51%攻撃」問題）
- **改善点**: 初期の4方向探索情報が5x5では十分だった
- **新たな問題**: 訪問回数が多い場所のエピソードが支配的になる

### 3. 純粋経験学習＋ドーナツ検索
- **5x5迷路**: 失敗（(1,0)で停滞）
- **10x10迷路**: **成功！20ステップで到達（効率100%）**
- **改善点**: ドーナツ検索により「51%攻撃」問題を回避
- **興味深い点**: より大きな迷路で成功（逆転現象）

## 重要な発見

1. **初期エピソードの重要性**
   - ゴールエピソードだけでは不十分
   - スタート地点の4方向情報が探索の基盤となる

2. **「51%攻撃」問題**
   - 訪問回数が多い場所のエピソードが類似度検索を支配
   - 同じ場所に留まる自己強化ループが発生
   - ブロックチェーンの51%攻撃と同じメカニズム

3. **ドーナツ検索の有効性**
   - 既に探索した領域から適度な距離を保つことで探索を促進
   - 純粋な類似性ベース学習と組み合わせることで効果的
   - 大きな迷路ほど効果が顕著（探索空間が広いため）

## 結論

**純粋な経験ベース学習は、適切な初期エピソードとドーナツ検索の組み合わせで実用的になる**ことが証明された。これは人間の探索行動に近く：
- 目的（ゴール）を知っている
- 基本的な行動の結果を学習する
- 既に調べた場所から適度に離れた場所を探索する

チートやペナルティなしで、純粋な類似性と空間的な探索戦略だけで迷路を解くことができた。