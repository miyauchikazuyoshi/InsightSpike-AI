{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Comparison Setup\n",
    "\n",
    "Colab notebook to run official GraphRAG / DyG-RAG / KEDKG pipelines\n",
    "on the 25/168/500 query datasets exported from this repo.\n",
    "\n",
    "**Steps**\n",
    "1. Mount Google Drive and clone the InsightSpike-AI repo (or upload datasets).\n",
    "2. Install required dependencies for each baseline.\n",
    "3. Run the baseline pipeline and collect metrics (PER, acceptance, FMR, latency).\n",
    "4. Save results back to JSON for later aggregation.\n",
    "\n",
    "Replace paths as necessary when running in Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment / Repository Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Colab: mount Google Drive (optional)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# clone InsightSpike-AI if not yet available\n",
    "# !git clone https://github.com/<USER>/InsightSpike-AI.git\n",
    "# %cd InsightSpike-AI\n",
    "\n",
    "# optional: install poetry if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Baseline Dependencies\n",
    "\n",
    "Each baseline has its own requirements. Run the appropriate cell(s) depending on which baseline you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphRAG dependencies\n",
    "# !pip install langchain==0.2.0 faiss-cpu pygraphviz pydantic==1.10.12 sentence-transformers\n",
    "# !git clone https://github.com/microsoft/graphrag.git external/graphrag\n",
    "# (Add SBERT integration as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DyG-RAG dependencies (example; adjust versions accordingly)\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
    "# (Add repository clone / setup commands here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEDKG dependencies (example)\n",
    "# !pip install torch torch-geometric networkx\n",
    "# (Clone the official repo or add direct implementation commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Datasets (25 / 168 / 500)\n",
    "\n",
    "Assumes `experiments/rag-baselines-data/*` artifacts (documents TSV, questions JSONL) are present in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path('experiments/baseline-comparison/data')\n",
    "DATASETS = {\n",
    "    '25': DATA_ROOT / 'sample_queries.jsonl',\n",
    "    '168': DATA_ROOT / 'sample_queries_168.jsonl',\n",
    "    '500': DATA_ROOT / 'sample_queries_500.jsonl',\n",
    "}\n",
    "\n",
    "def load_jsonl(path: Path):\n",
    "    with path.open('r', encoding='utf-8') as fh:\n",
    "        for line in fh:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                yield json.loads(line)\n",
    "\n",
    "datasets = {k: list(load_jsonl(p)) for k, p in DATASETS.items()}\n",
    "print({k: len(v) for k, v in datasets.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run GraphRAG\n",
    "\n",
    "Example: call the GraphRAG pipeline with SBERT embedding. Collect `per_mean`, `acceptance_rate`, `fmr`, `latency_p50` etc.\n",
    "This will depend heavily on the repository's CLI/SDK; pseudocode shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "EXPERIMENTS_DIR = NOTEBOOK_DIR.parents[2]\n",
    "RAG_LITE_ROOT = EXPERIMENTS_DIR / 'rag-dynamic-db-v3-lite'\n",
    "BASELINES_DIR = EXPERIMENTS_DIR / 'rag-baselines'\n",
    "\n",
    "DATASET = RAG_LITE_ROOT / 'data' / 'sample_queries.jsonl'\n",
    "OUTPUT = RAG_LITE_ROOT / 'results' / 'graph_rag_baseline_25.json'\n",
    "\n",
    "print(f'▶︎ dataset: {DATASET}')\n",
    "print(f'▶︎ output:  {OUTPUT}')\n",
    "OUTPUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    str(BASELINES_DIR / 'run_graphrag_baseline.py'),\n",
    "    '--dataset', str(DATASET),\n",
    "    '--output', str(OUTPUT),\n",
    "    '--embedding-model', 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "]\n",
    "print('$', ' '.join(cmd))\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run DyG-RAG / KEDKG\n",
    "\n",
    "Add cells similar to GraphRAG, using the official code or adapted scripts. Ensure that outputs include comparable metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": 0,
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "EXPERIMENTS_DIR = NOTEBOOK_DIR.parents[2]\n",
    "RAG_LITE_ROOT = EXPERIMENTS_DIR / 'rag-dynamic-db-v3-lite'\n",
    "BASELINES_DIR = EXPERIMENTS_DIR / 'rag-baselines'\n",
    "\n",
    "DATASET = RAG_LITE_ROOT / 'data' / 'sample_queries.jsonl'\n",
    "OUTPUT = RAG_LITE_ROOT / 'results' / 'dygrag_like_baseline_25.json'\n",
    "\n",
    "print(f'▶︎ dataset: {DATASET}')\n",
    "print(f'▶︎ output:  {OUTPUT}')\n",
    "OUTPUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    str(BASELINES_DIR / 'run_dygrag_like_baseline.py'),\n",
    "    '--dataset', str(DATASET),\n",
    "    '--output', str(OUTPUT),\n",
    "    '--embedding-model', 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    '--ag-margin', '0.05',\n",
    "    '--dg-threshold', '0.7',\n",
    "]\n",
    "print('$', ' '.join(cmd))\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aggregate Metrics\n",
    "\n",
    "Use the provided aggregation utility (or inline code) to compare with geDIG results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "GEDIG_RESULTS = {\n",
    "    '25': Path('experiments/baseline-comparison/geDIG_results/rag_v3_lite_sample_queries_20251014_075707.json'),\n",
    "    '168': Path('experiments/baseline-comparison/geDIG_results/rag_v3_lite_168_20251014_075956.json'),\n",
    "    '500': Path('experiments/baseline-comparison/geDIG_results/rag_v3_lite_500_20251014_064807.json'),\n",
    "}\n",
    "\n",
    "def load_metrics(path: Path, key: str):\n",
    "    data = json.loads(path.read_text())\n",
    "    return data['results'][key]\n",
    "\n",
    "# Example aggregation\n",
    "summary = {}\n",
    "for k, gedig_path in GEDIG_RESULTS.items():\n",
    "    summary[k] = {\n",
    "        'geDIG': load_metrics(gedig_path, 'gedig_ag_dg'),\n",
    "        # 'GraphRAG_official': load_metrics(Path(f'results/graph_rag_official_{k}.json'), 'graphrag'),\n",
    "        # 'DyG-RAG_official': load_metrics(Path(f'results/dygrag_official_{k}.json'), 'dygrag'),\n",
    "    }\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Adapt the pseudocode sections with actual CLI/SDK calls.\n",
    "- Save each baseline's outputs (JSON/CSV) so they can be pulled into the main repo and aggregated.\n",
    "- Document the compute environment (Colab GPU/CPU specs) when reporting results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}