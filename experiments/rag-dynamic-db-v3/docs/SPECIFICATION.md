# geDIG-RAG v3 æŠ€è¡“ä»•æ§˜æ›¸

## 1. ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 1.1 å…¨ä½“æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    geDIG-RAG v3 System                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Query Processing Layer                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Query       â”‚  â”‚ Embedding    â”‚  â”‚ Context         â”‚    â”‚
â”‚  â”‚ Analyzer    â”‚â†’ â”‚ Generator    â”‚â†’ â”‚ Extractor       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  geDIG Evaluation Layer                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Î”GED        â”‚  â”‚ Î”IG          â”‚  â”‚ geDIG           â”‚    â”‚
â”‚  â”‚ Calculator  â”‚  â”‚ Calculator   â”‚â†’ â”‚ Evaluator       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Knowledge Management Layer                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Dynamic     â”‚  â”‚ Update       â”‚  â”‚ Maintenance     â”‚    â”‚
â”‚  â”‚ Graph       â”‚  â”‚ Decision     â”‚  â”‚ Manager         â”‚    â”‚
â”‚  â”‚ Manager     â”‚  â”‚ Engine       â”‚  â”‚                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Retrieval & Generation Layer                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ geDIG-aware â”‚  â”‚ Context      â”‚  â”‚ Response        â”‚    â”‚
â”‚  â”‚ Retriever   â”‚â†’ â”‚ Composer     â”‚â†’ â”‚ Generator       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Evaluation & Analysis Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Performance â”‚  â”‚ Growth       â”‚  â”‚ Report          â”‚    â”‚
â”‚  â”‚ Metrics     â”‚  â”‚ Analyzer     â”‚  â”‚ Generator       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant U as User Query
    participant QP as Query Processor
    participant GE as geDIG Evaluator
    participant KM as Knowledge Manager
    participant R as Retriever
    participant RG as Response Generator
    participant EA as Evaluator

    U->>QP: Input Query
    QP->>QP: Generate Embedding
    QP->>R: Retrieve Candidates
    R->>R: geDIG-aware Ranking
    R->>RG: Provide Context
    RG->>RG: Generate Response
    RG->>GE: Propose Knowledge Update
    GE->>GE: Calculate Î”GED & Î”IG
    GE->>KM: Update Decision
    KM->>KM: Apply Graph Changes
    KM->>EA: Log Performance Metrics
    EA->>EA: Analyze Growth Patterns
```

## 2. ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè¨­è¨ˆ

### 2.1 geDIGè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 

#### 2.1.1 GeDIGEvaluator ã‚¯ãƒ©ã‚¹
```python
class GeDIGEvaluator:
    """geDIGè©•ä¾¡é–¢æ•°ã®æ ¸å¿ƒå®Ÿè£…"""
    
    def __init__(self, k_coefficient: float = 0.5, radius: int = 2):
        """
        Args:
            k_coefficient: Î”IGé …ã®é‡ã¿ï¼ˆè«–æ–‡ã§ã®æœ€é©åŒ–å¯¾è±¡ï¼‰
            radius: å±€æ‰€ã‚°ãƒ©ãƒ•æŠ½å‡ºã®åŠå¾„
        """
        self.k = k_coefficient
        self.radius = radius
        self.ged_calculator = DeltaGEDCalculator()
        self.ig_calculator = DeltaIGCalculator()
    
    def evaluate_update(self, 
                       graph_before: KnowledgeGraph,
                       proposed_update: GraphUpdate) -> GeDIGResult:
        """æ›´æ–°ææ¡ˆã®geDIGè©•ä¾¡"""
        
        # ä»®æƒ³çš„ã«æ›´æ–°ã‚’é©ç”¨
        graph_after = self._simulate_update(graph_before, proposed_update)
        affected_nodes = proposed_update.get_affected_nodes()
        
        # Î”GEDè¨ˆç®—ï¼ˆæ§‹é€ å¤‰åŒ–é‡ï¼‰
        delta_ged = self.ged_calculator.calculate(
            graph_before, graph_after, affected_nodes
        )
        
        # Î”IGè¨ˆç®—ï¼ˆæƒ…å ±åˆ©å¾—ï¼‰  
        delta_ig = self.ig_calculator.calculate(
            graph_before, graph_after, affected_nodes
        )
        
        # geDIGçµ±åˆè©•ä¾¡
        delta_gedig = delta_ged - self.k * delta_ig
        
        return GeDIGResult(
            delta_ged=delta_ged,
            delta_ig=delta_ig,
            delta_gedig=delta_gedig,
            confidence=self._calculate_confidence(delta_ged, delta_ig),
            affected_nodes=affected_nodes
        )
```

#### 2.1.2 Î”GEDè¨ˆç®—è©³ç´°
```python
class DeltaGEDCalculator:
    """ã‚°ãƒ©ãƒ•æ§‹é€ å¤‰åŒ–é‡ã®åŠ¹ç‡è¨ˆç®—"""
    
    def __init__(self):
        self.structural_weights = {
            'node_count_change': 0.3,      # ãƒãƒ¼ãƒ‰æ•°å¤‰åŒ–
            'edge_count_change': 0.2,      # ã‚¨ãƒƒã‚¸æ•°å¤‰åŒ–
            'degree_distribution': 0.15,   # æ¬¡æ•°åˆ†å¸ƒå¤‰åŒ–
            'clustering_coefficient': 0.15, # ã‚¯ãƒ©ã‚¹ã‚¿ä¿‚æ•°å¤‰åŒ–
            'density_change': 0.1,         # ã‚°ãƒ©ãƒ•å¯†åº¦å¤‰åŒ–
            'connectivity_change': 0.1     # é€£çµæ€§å¤‰åŒ–
        }
    
    def calculate(self, graph_before, graph_after, affected_nodes):
        """å±€æ‰€çš„Î”GEDè¨ˆç®—"""
        
        # å±€æ‰€ã‚µãƒ–ã‚°ãƒ©ãƒ•æŠ½å‡º
        subgraph_before = self._extract_local_subgraph(graph_before, affected_nodes)
        subgraph_after = self._extract_local_subgraph(graph_after, affected_nodes)
        
        # å„æ§‹é€ æŒ‡æ¨™ã®å¤‰åŒ–é‡è¨ˆç®—
        structural_changes = {}
        for metric, weight in self.structural_weights.items():
            before_val = self._calculate_metric(subgraph_before, metric)
            after_val = self._calculate_metric(subgraph_after, metric)
            structural_changes[metric] = abs(after_val - before_val) * weight
        
        return sum(structural_changes.values())
```

#### 2.1.3 Î”IGè¨ˆç®—è©³ç´°
```python
class DeltaIGCalculator:
    """æƒ…å ±åˆ©å¾—å¤‰åŒ–é‡ã®è¨ˆç®—"""
    
    def calculate(self, graph_before, graph_after, affected_nodes):
        """ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯Î”IGè¨ˆç®—"""
        
        # æ–°è¦è¿½åŠ ã®å ´åˆ
        if self._is_addition_update(graph_before, graph_after):
            return self._calculate_addition_ig(graph_before, graph_after)
        
        # å‰Šé™¤ã®å ´åˆ  
        elif self._is_removal_update(graph_before, graph_after):
            return self._calculate_removal_ig(graph_before, graph_after)
        
        # çµ±åˆã®å ´åˆ
        elif self._is_merge_update(graph_before, graph_after):
            return self._calculate_merge_ig(graph_before, graph_after)
        
        return 0.0
    
    def _calculate_addition_ig(self, graph_before, graph_after):
        """è¿½åŠ æ™‚ã®Î”IGè¨ˆç®—"""
        
        # æ–°è¦ãƒãƒ¼ãƒ‰ã®æ¤œç´¢æ€§èƒ½å‘ä¸Šãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«
        search_potential = self._estimate_search_improvement(graph_after)
        
        # æ—¢å­˜çŸ¥è­˜ã¨ã®é–¢é€£åº¦
        connection_value = self._estimate_connection_value(graph_after)
        
        # å†—é•·æ€§ãƒšãƒŠãƒ«ãƒ†ã‚£
        redundancy_penalty = self._calculate_redundancy_penalty(graph_after)
        
        return search_potential + connection_value - redundancy_penalty
```

### 2.2 4ç¨®é¡ã®RAGã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…

#### 2.2.1 BaseRAGSystem æŠ½è±¡ã‚¯ãƒ©ã‚¹
```python
class BaseRAGSystem(ABC):
    """RAGã‚·ã‚¹ãƒ†ãƒ ã®å…±é€šã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    def __init__(self, config: ExperimentConfig):
        self.config = config
        self.knowledge_graph = KnowledgeGraph()
        self.retriever = self._create_retriever()
        self.generator = self._create_generator()
        self.evaluator = PerformanceEvaluator()
    
    @abstractmethod
    def should_update_knowledge(self, query: str, response: str) -> bool:
        """çŸ¥è­˜æ›´æ–°ã®åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå„æ‰‹æ³•ã§å®Ÿè£…ï¼‰"""
        pass
    
    @abstractmethod  
    def _create_retriever(self) -> BaseRetriever:
        """æ¤œç´¢å™¨ã®ä½œæˆï¼ˆå„æ‰‹æ³•ã§å®Ÿè£…ï¼‰"""
        pass
    
    def process_query(self, query: str) -> RAGResponse:
        """ã‚¯ã‚¨ãƒªå‡¦ç†ã®å…±é€šãƒ•ãƒ­ãƒ¼"""
        
        # 1. æ¤œç´¢
        retrieved_docs = self.retriever.retrieve(query, k=self.config.top_k)
        
        # 2. ç”Ÿæˆ
        response = self.generator.generate(query, retrieved_docs)
        
        # 3. çŸ¥è­˜æ›´æ–°åˆ¤å®š
        if self.should_update_knowledge(query, response):
            update_result = self._update_knowledge(query, response)
        else:
            update_result = None
        
        # 4. çµæœè¨˜éŒ²
        return RAGResponse(
            query=query,
            response=response,
            retrieved_docs=retrieved_docs,
            update_result=update_result,
            performance_metrics=self._calculate_metrics(query, response)
        )
```

#### 2.2.2 å„RAGã‚·ã‚¹ãƒ†ãƒ ã®å…·ä½“å®Ÿè£…

```python
class StaticRAG(BaseRAGSystem):
    """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: é™çš„çŸ¥è­˜ãƒ™ãƒ¼ã‚¹"""
    
    def should_update_knowledge(self, query: str, response: str) -> bool:
        return False  # å¸¸ã«æ›´æ–°ãªã—
    
    def _create_retriever(self):
        return CosineRetriever(self.knowledge_graph)

class FrequencyBasedRAG(BaseRAGSystem):
    """é »åº¦ãƒ™ãƒ¼ã‚¹RAG: å˜ç´”ãªä½¿ç”¨é »åº¦ã§æ›´æ–°åˆ¤å®š"""
    
    def __init__(self, config):
        super().__init__(config)
        self.access_counts = defaultdict(int)
        self.last_update_time = defaultdict(float)
    
    def should_update_knowledge(self, query: str, response: str) -> bool:
        # é »åº¦ãƒ™ãƒ¼ã‚¹ã®å˜ç´”ãƒ­ã‚¸ãƒƒã‚¯
        query_hash = hashlib.md5(query.encode()).hexdigest()
        self.access_counts[query_hash] += 1
        
        # ä½é »åº¦ã‚¯ã‚¨ãƒªã¯çŸ¥è­˜è¿½åŠ å€™è£œ
        if self.access_counts[query_hash] <= self.config.frequency_threshold:
            return True
            
        # æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°
        current_time = time.time()
        if current_time - self.last_update_time[query_hash] > self.config.time_threshold:
            return True
            
        return False

class CosineOnlyRAG(BaseRAGSystem):
    """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®ã¿RAG: é¡ä¼¼åº¦é–¾å€¤ã§æ›´æ–°åˆ¤å®š"""
    
    def should_update_knowledge(self, query: str, response: str) -> bool:
        query_embedding = self.retriever.embed_query(query)
        
        # æ—¢å­˜çŸ¥è­˜ã¨ã®æœ€å¤§é¡ä¼¼åº¦ã‚’è¨ˆç®—
        similarities = []
        for node in self.knowledge_graph.nodes():
            node_embedding = self.knowledge_graph.get_node_embedding(node)
            similarity = cosine_similarity(query_embedding, node_embedding)
            similarities.append(similarity)
        
        max_similarity = max(similarities) if similarities else 0.0
        
        # é¡ä¼¼åº¦ãŒä½ã„å ´åˆã¯æ–°è¦çŸ¥è­˜ã¨ã—ã¦è¿½åŠ 
        return max_similarity < self.config.cosine_threshold

class GeDIGRAG(BaseRAGSystem):
    """ææ¡ˆæ‰‹æ³•: geDIGè©•ä¾¡ã«ã‚ˆã‚‹RAG"""
    
    def __init__(self, config):
        super().__init__(config)
        self.gedig_evaluator = GeDIGEvaluator(
            k_coefficient=config.gedig_k,
            radius=config.gedig_radius
        )
        self.update_manager = DynamicUpdateManager(config)
    
    def should_update_knowledge(self, query: str, response: str) -> bool:
        # çŸ¥è­˜æ›´æ–°å€™è£œã‚’ç”Ÿæˆ
        proposed_updates = self._generate_update_proposals(query, response)
        
        # geDIGè©•ä¾¡ã§æœ€é©æ›´æ–°ã‚’é¸æŠ
        best_update = None
        best_score = float('-inf')
        
        for update in proposed_updates:
            gedig_result = self.gedig_evaluator.evaluate_update(
                self.knowledge_graph, update
            )
            
            if gedig_result.delta_gedig > best_score:
                best_score = gedig_result.delta_gedig
                best_update = update
        
        # é–¾å€¤ã‚’è¶…ãˆã‚‹å ´åˆã®ã¿æ›´æ–°
        return best_score > self.config.gedig_threshold
    
    def _create_retriever(self):
        return GeDIGAwareRetriever(self.knowledge_graph, self.gedig_evaluator)
```

### 2.3 è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ

#### 2.3.1 GrowthMetricsCalculator
```python
class GrowthMetricsCalculator:
    """é•·æœŸæˆé•·åŠ¹æœã®åˆ†æ"""
    
    def calculate_session_growth(self, session_results: List[SessionResult]) -> GrowthAnalysis:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¯ã®æˆé•·ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        
        growth_curves = {
            'em_scores': [],
            'f1_scores': [],
            'recall_at_k': {k: [] for k in [1, 3, 5, 10]},
            'mrr_scores': [],
            'knowledge_size': [],
            'update_rates': []
        }
        
        for session in session_results:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã®ã‚¯ã‚¨ãƒªæ¯æ€§èƒ½å¤‰åŒ–
            session_em = [result.em_score for result in session.query_results]
            session_f1 = [result.f1_score for result in session.query_results]
            
            growth_curves['em_scores'].append(session_em)
            growth_curves['f1_scores'].append(session_f1)
            
            # ä»–ã®æŒ‡æ¨™ã‚‚åŒæ§˜ã«è¨ˆç®—...
            
        return GrowthAnalysis(
            curves=growth_curves,
            growth_rates=self._calculate_growth_rates(growth_curves),
            saturation_points=self._detect_saturation_points(growth_curves),
            efficiency_metrics=self._calculate_efficiency_metrics(session_results)
        )
    
    def _calculate_growth_rates(self, curves: Dict) -> Dict[str, float]:
        """å„æŒ‡æ¨™ã®æˆé•·ç‡è¨ˆç®—"""
        
        growth_rates = {}
        for metric, curve_data in curves.items():
            if isinstance(curve_data, dict):  # recall_at_k ã®å ´åˆ
                growth_rates[metric] = {}
                for k, k_curves in curve_data.items():
                    growth_rates[metric][k] = self._calculate_linear_growth(k_curves)
            else:
                growth_rates[metric] = self._calculate_linear_growth(curve_data)
        
        return growth_rates
    
    def _calculate_linear_growth(self, curve_data: List[List[float]]) -> float:
        """ç·šå½¢æˆé•·ç‡ã®è¨ˆç®—"""
        
        # å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å¹³å‡æˆé•·ç‡
        session_growth_rates = []
        
        for session_curve in curve_data:
            if len(session_curve) >= 2:
                # ç·šå½¢å›å¸°ã§æˆé•·ç‡ã‚’è¨ˆç®—
                x = np.arange(len(session_curve))
                y = np.array(session_curve)
                slope, _ = np.polyfit(x, y, 1)
                session_growth_rates.append(slope)
        
        return np.mean(session_growth_rates)
```

#### 2.3.2 EfficiencyAnalyzer
```python
class EfficiencyAnalyzer:
    """åŠ¹ç‡æ€§è©•ä¾¡ï¼ˆ1ãƒãƒ¼ãƒ‰è¿½åŠ å½“ãŸã‚Šã®æ”¹å–„åŠ¹æœï¼‰"""
    
    def analyze_update_efficiency(self, experiment_results: Dict[str, List[SessionResult]]) -> EfficiencyReport:
        """æ›´æ–°åŠ¹ç‡æ€§ã®æ¯”è¼ƒåˆ†æ"""
        
        efficiency_data = {}
        
        for method_name, session_results in experiment_results.items():
            method_efficiency = self._calculate_method_efficiency(session_results)
            efficiency_data[method_name] = method_efficiency
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
        significance_tests = self._perform_significance_tests(efficiency_data)
        
        return EfficiencyReport(
            efficiency_per_method=efficiency_data,
            statistical_tests=significance_tests,
            ranking=self._rank_methods_by_efficiency(efficiency_data)
        )
    
    def _calculate_method_efficiency(self, session_results: List[SessionResult]) -> EfficiencyMetrics:
        """æ‰‹æ³•åˆ¥åŠ¹ç‡æ€§æŒ‡æ¨™è¨ˆç®—"""
        
        total_updates = 0
        total_em_improvement = 0
        total_f1_improvement = 0
        
        for session in session_results:
            session_updates = sum(1 for r in session.query_results if r.knowledge_updated)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ãƒ»çµ‚äº†ã§ã®æ€§èƒ½å·®
            start_em = session.query_results[0].em_score
            end_em = session.query_results[-1].em_score
            em_improvement = end_em - start_em
            
            start_f1 = session.query_results[0].f1_score  
            end_f1 = session.query_results[-1].f1_score
            f1_improvement = end_f1 - start_f1
            
            total_updates += session_updates
            total_em_improvement += em_improvement
            total_f1_improvement += f1_improvement
        
        # 1æ›´æ–°å½“ãŸã‚Šã®æ”¹å–„é‡
        em_per_update = total_em_improvement / max(total_updates, 1)
        f1_per_update = total_f1_improvement / max(total_updates, 1)
        
        return EfficiencyMetrics(
            updates_per_session=total_updates / len(session_results),
            em_improvement_per_update=em_per_update,
            f1_improvement_per_update=f1_per_update,
            total_sessions=len(session_results)
        )
```

## 3. å®Ÿé¨“è¨­è¨ˆè©³ç´°

### 3.1 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†

```python
class ExperimentDatasetManager:
    """å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±åˆç®¡ç†"""
    
    def __init__(self, config: ExperimentConfig):
        self.config = config
        self.datasets = {}
    
    def load_hotpot_qa_sample(self, size: int = 1000) -> Dataset:
        """HotpotQAã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        
        # å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        full_dataset = load_dataset("hotpot_qa", "fullwiki")
        sample_indices = random.sample(range(len(full_dataset['train'])), size)
        
        sampled_data = []
        for idx in sample_indices:
            item = full_dataset['train'][idx]
            sampled_data.append({
                'id': f"hotpot_{idx}",
                'question': item['question'],
                'answer': item['answer'],
                'supporting_facts': item['supporting_facts'],
                'context': item['context'],
                'level': item['level'],  # easy/medium/hard
                'type': item['type']     # bridge/comparison
            })
        
        return Dataset(name="hotpot_qa_sample", data=sampled_data)
    
    def load_domain_qa(self) -> Dataset:
        """ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–QAãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆåŒ¿ååŒ–æ¸ˆã¿ï¼‰"""
        
        # æŠ€è¡“æ–‡æ›¸ãƒ™ãƒ¼ã‚¹ã®QAãƒšã‚¢
        domain_data = []
        
        # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆå€‹äººæƒ…å ±é™¤å»æ¸ˆã¿ï¼‰
        with open(self.config.domain_qa_path, 'r') as f:
            raw_data = json.load(f)
        
        for item in raw_data:
            domain_data.append({
                'id': item['id'],
                'question': self._anonymize_text(item['question']),
                'answer': self._anonymize_text(item['answer']),
                'domain': item['domain'],
                'difficulty': item['difficulty'],
                'requires_multimodal': item.get('multimodal', False)
            })
        
        return Dataset(name="domain_qa", data=domain_data)
    
    def create_session_splits(self, dataset: Dataset, n_sessions: int) -> List[Dataset]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†å‰²ï¼ˆæ™‚ç³»åˆ—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’n_sessionsã«åˆ†å‰²
        session_size = len(dataset.data) // n_sessions
        sessions = []
        
        for i in range(n_sessions):
            start_idx = i * session_size
            end_idx = (i + 1) * session_size if i < n_sessions - 1 else len(dataset.data)
            
            session_data = dataset.data[start_idx:end_idx]
            sessions.append(Dataset(
                name=f"{dataset.name}_session_{i+1}",
                data=session_data
            ))
        
        return sessions
```

### 3.2 å®Ÿé¨“å®Ÿè¡Œãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

```python
class ExperimentRunner:
    """å®Ÿé¨“å®Ÿè¡Œã®çµ±åˆç®¡ç†"""
    
    def __init__(self, config: ExperimentConfig):
        self.config = config
        self.dataset_manager = ExperimentDatasetManager(config)
        self.evaluator = ComprehensiveEvaluator()
        
        # 4ç¨®é¡ã®RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.rag_systems = {
            'static': StaticRAG(config),
            'frequency': FrequencyBasedRAG(config),
            'cosine': CosineOnlyRAG(config),
            'gedig': GeDIGRAG(config)
        }
    
    def run_full_experiment(self) -> ExperimentResults:
        """3é€±é–“åˆ†ã®å®Œå…¨å®Ÿé¨“å®Ÿè¡Œ"""
        
        results = {}
        
        # Phase 1: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ
        print("ğŸš€ Phase 1: Baseline Comparison")
        results['phase1'] = self.run_baseline_comparison()
        
        # Phase 2: é•·æœŸæˆé•·å®Ÿé¨“  
        print("ğŸ“ˆ Phase 2: Long-term Growth")
        results['phase2'] = self.run_longterm_sessions()
        
        # Phase 3: ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ
        print("ğŸ”¬ Phase 3: Ablation Analysis") 
        results['phase3'] = self.run_ablation_analysis()
        
        # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("ğŸ“Š Generating Comprehensive Report")
        final_report = self._generate_final_report(results)
        
        return ExperimentResults(
            phase_results=results,
            final_report=final_report,
            config=self.config
        )
    
    def run_baseline_comparison(self) -> BaselineResults:
        """Phase 1: 4æ‰‹æ³•ã®åŸºæœ¬æ€§èƒ½æ¯”è¼ƒ"""
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
        hotpot_data = self.dataset_manager.load_hotpot_qa_sample(size=200)
        domain_data = self.dataset_manager.load_domain_qa()
        
        baseline_results = {}
        
        for method_name, rag_system in self.rag_systems.items():
            print(f"  Running {method_name}...")
            
            method_results = []
            
            # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡
            for dataset in [hotpot_data, domain_data]:
                dataset_result = self._evaluate_rag_system(rag_system, dataset)
                method_results.append(dataset_result)
            
            baseline_results[method_name] = method_results
        
        return BaselineResults(baseline_results)
    
    def run_longterm_sessions(self) -> LongtermResults:
        """Phase 2: 5ã‚»ãƒƒã‚·ãƒ§ãƒ³Ã—20ã‚¯ã‚¨ãƒªã®é•·æœŸå®Ÿé¨“"""
        
        longterm_results = {}
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
        hotpot_data = self.dataset_manager.load_hotpot_qa_sample(size=1000)
        sessions = self.dataset_manager.create_session_splits(hotpot_data, n_sessions=5)
        
        for method_name, rag_system in self.rag_systems.items():
            print(f"  Running long-term {method_name}...")
            
            # è¤‡æ•°ã‚·ãƒ¼ãƒ‰ã§å®Ÿé¨“
            method_sessions = []
            
            for seed in self.config.seeds:
                random.seed(seed)
                np.random.seed(seed)
                
                # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
                rag_system.reset()
                
                # 5ã‚»ãƒƒã‚·ãƒ§ãƒ³é€£ç¶šå®Ÿè¡Œ
                seed_sessions = []
                for session_dataset in sessions:
                    session_result = self._run_session(rag_system, session_dataset)
                    seed_sessions.append(session_result)
                
                method_sessions.append(seed_sessions)
            
            longterm_results[method_name] = method_sessions
        
        return LongtermResults(longterm_results)
```

## 4. çµæœåˆ†æãƒ»å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ 

### 4.1 è«–æ–‡ç”¨å›³è¡¨ç”Ÿæˆå™¨

```python
class PaperFigureGenerator:
    """è«–æ–‡ç”¨å›³è¡¨ã®è‡ªå‹•ç”Ÿæˆ"""
    
    def __init__(self, results: ExperimentResults):
        self.results = results
        self.output_dir = Path("results/paper_figures")
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def generate_all_figures(self):
        """å…¨å›³è¡¨ã®ä¸€æ‹¬ç”Ÿæˆ"""
        
        # Figure 1: ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆæ‰‹å‹•ä½œæˆï¼‰
        
        # Figure 2: æˆé•·æ›²ç·š
        self.generate_growth_curves()
        
        # Figure 3: åŠ¹ç‡æ€§æ¯”è¼ƒ
        self.generate_efficiency_comparison()
        
        # Figure 4: ã‚°ãƒ©ãƒ•æ§‹é€ å¤‰åŒ–
        self.generate_graph_evolution()
        
        # Table 1: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ
        self.generate_baseline_table()
        
        # Table 2: ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
        self.generate_ablation_table()
        
        print(f"ğŸ“Š All figures generated in {self.output_dir}")
    
    def generate_growth_curves(self):
        """Figure 2: ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¥æˆé•·æ›²ç·š"""
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # EM/F1 æˆé•·æ›²ç·š
        self._plot_metric_growth(axes[0, 0], 'em_score', 'EM Score Growth')
        self._plot_metric_growth(axes[0, 1], 'f1_score', 'F1 Score Growth')
        
        # Recall@K æˆé•·æ›²ç·š
        self._plot_recall_growth(axes[1, 0], k=5, title='Recall@5 Growth')
        self._plot_recall_growth(axes[1, 1], k=10, title='Recall@10 Growth')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / "figure2_growth_curves.png", dpi=300, bbox_inches='tight')
        plt.savefig(self.output_dir / "figure2_growth_curves.pdf", bbox_inches='tight')
        plt.close()
    
    def _plot_metric_growth(self, ax, metric: str, title: str):
        """å€‹åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æˆé•·æ›²ç·šæç”»"""
        
        longterm_results = self.results.phase_results['phase2']
        
        for method_name in ['static', 'frequency', 'cosine', 'gedig']:
            method_data = longterm_results.results[method_name]
            
            # å…¨ã‚·ãƒ¼ãƒ‰ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å¹³å‡å€¤è¨ˆç®—
            session_means = []
            session_stds = []
            
            for session_idx in range(5):  # 5ã‚»ãƒƒã‚·ãƒ§ãƒ³
                session_values = []
                for seed_results in method_data:
                    session_result = seed_results[session_idx]
                    session_values.extend([
                        getattr(qr, metric) for qr in session_result.query_results
                    ])
                
                session_means.append(np.mean(session_values))
                session_stds.append(np.std(session_values))
            
            # æç”»
            x = np.arange(1, 6)
            ax.plot(x, session_means, label=method_name.upper(), marker='o', linewidth=2)
            ax.fill_between(x, 
                          np.array(session_means) - np.array(session_stds), 
                          np.array(session_means) + np.array(session_stds),
                          alpha=0.2)
        
        ax.set_xlabel('Session')
        ax.set_ylabel(metric.replace('_', ' ').title())
        ax.set_title(title)
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    def generate_efficiency_comparison(self):
        """Figure 3: åŠ¹ç‡æ€§æ¯”è¼ƒï¼ˆ1ãƒãƒ¼ãƒ‰è¿½åŠ å½“ãŸã‚Šã®æ”¹å–„ï¼‰"""
        
        efficiency_analyzer = EfficiencyAnalyzer()
        efficiency_report = efficiency_analyzer.analyze_update_efficiency(
            self.results.phase_results['phase2'].results
        )
        
        # æ£’ã‚°ãƒ©ãƒ•ä½œæˆ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        methods = list(efficiency_report.efficiency_per_method.keys())
        em_efficiency = [efficiency_report.efficiency_per_method[m].em_improvement_per_update 
                        for m in methods]
        f1_efficiency = [efficiency_report.efficiency_per_method[m].f1_improvement_per_update 
                        for m in methods]
        
        # EMåŠ¹ç‡
        bars1 = ax1.bar(methods, em_efficiency, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
        ax1.set_ylabel('EM Improvement per Update')
        ax1.set_title('EM Efficiency Comparison')
        ax1.set_ylim(0, max(em_efficiency) * 1.2)
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, value in zip(bars1, em_efficiency):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(em_efficiency)*0.01,
                    f'{value:.3f}', ha='center', va='bottom')
        
        # F1åŠ¹ç‡
        bars2 = ax2.bar(methods, f1_efficiency, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
        ax2.set_ylabel('F1 Improvement per Update')
        ax2.set_title('F1 Efficiency Comparison')
        ax2.set_ylim(0, max(f1_efficiency) * 1.2)
        
        for bar, value in zip(bars2, f1_efficiency):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(f1_efficiency)*0.01,
                    f'{value:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / "figure3_efficiency_comparison.png", dpi=300, bbox_inches='tight')
        plt.savefig(self.output_dir / "figure3_efficiency_comparison.pdf", bbox_inches='tight')
        plt.close()
```

## 5. å†ç¾æ€§ãƒ»å“è³ªä¿è¨¼

### 5.1 å®Ÿé¨“è¨­å®šã®å›ºå®šåŒ–

```python
class ReproducibilityManager:
    """å®Ÿé¨“ã®å†ç¾æ€§ç¢ºä¿"""
    
    @staticmethod
    def set_seeds(seed: int = 42):
        """å…¨ã‚·ãƒ¼ãƒ‰å›ºå®š"""
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
    
    @staticmethod
    def save_experiment_config(config: ExperimentConfig, output_path: Path):
        """å®Ÿé¨“è¨­å®šã®ä¿å­˜"""
        config_dict = {
            'gedig_parameters': {
                'k_coefficient': config.gedig_k,
                'radius': config.gedig_radius,
                'thresholds': config.gedig_thresholds.__dict__
            },
            'experiment_parameters': {
                'seeds': config.seeds,
                'sessions': config.n_sessions,
                'queries_per_session': config.queries_per_session
            },
            'model_parameters': {
                'embedding_model': config.embedding_model,
                'generation_model': config.generation_model
            },
            'timestamp': datetime.now().isoformat(),
            'git_commit': subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode().strip()
        }
        
        with open(output_path / "experiment_config.json", 'w') as f:
            json.dump(config_dict, f, indent=2)
```

### 5.2 è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

```python
class ExperimentTestSuite:
    """å®Ÿé¨“ã‚³ãƒ¼ãƒ‰ã®å“è³ªãƒ†ã‚¹ãƒˆ"""
    
    def run_all_tests(self):
        """å…¨ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        
        print("ğŸ§ª Running Experiment Test Suite...")
        
        # å˜ä½“ãƒ†ã‚¹ãƒˆ
        self.test_gedig_calculations()
        self.test_rag_systems()
        self.test_evaluation_metrics()
        
        # çµ±åˆãƒ†ã‚¹ãƒˆ
        self.test_end_to_end_flow()
        
        # æ€§èƒ½ãƒ†ã‚¹ãƒˆ
        self.test_performance_requirements()
        
        print("âœ… All tests passed!")
    
    def test_gedig_calculations(self):
        """geDIGè¨ˆç®—ã®æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ"""
        
        evaluator = GeDIGEvaluator(k_coefficient=0.5)
        
        # ç°¡å˜ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
        graph_before = self._create_test_graph(nodes=3, edges=2)
        graph_after = self._create_test_graph(nodes=4, edges=3)  # ãƒãƒ¼ãƒ‰1å€‹è¿½åŠ 
        
        result = evaluator.evaluate_update(graph_before, graph_after, ['new_node'])
        
        assert result.delta_ged > 0, "Î”GED should be positive for node addition"
        assert result.delta_ig >= 0, "Î”IG should be non-negative"
        assert isinstance(result.delta_gedig, float), "Î”geDIG should be float"
        
        print("  âœ… geDIG calculations test passed")
    
    def test_evaluation_metrics(self):
        """è©•ä¾¡æŒ‡æ¨™è¨ˆç®—ã®æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ"""
        
        # æ¨¡æ“¬å®Ÿé¨“çµæœä½œæˆ
        mock_results = self._create_mock_experiment_results()
        
        # æˆé•·æŒ‡æ¨™è¨ˆç®—
        growth_calculator = GrowthMetricsCalculator()
        growth_analysis = growth_calculator.calculate_session_growth(mock_results)
        
        assert 'em_scores' in growth_analysis.curves
        assert 'f1_scores' in growth_analysis.curves
        assert len(growth_analysis.growth_rates) > 0
        
        print("  âœ… Evaluation metrics test passed")
```

ã“ã®æŠ€è¡“ä»•æ§˜æ›¸ã«ã‚ˆã‚Šã€geDIG-RAG v3ã®è©³ç´°ãªå®Ÿè£…æŒ‡é‡ã¨å“è³ªä¿è¨¼ä½“åˆ¶ãŒç¢ºç«‹ã•ã‚Œã¾ã™ã€‚è«–æ–‡åŒ–ãƒ¬ãƒ™ãƒ«ã®å®Ÿé¨“å®Ÿæ–½ã«å¿…è¦ãªå…¨è¦ç´ ãŒç¶²ç¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚