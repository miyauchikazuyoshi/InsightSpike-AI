item1_id,item1_text,item2_id,item2_text,shared_concepts,n_shared
10,GPU acceleration leverages thousands of CUDA cores...,11,Mixed precision training uses FP16 for forward/bac...,"gpu, optimization, deep_learning",3
1,Python's Global Interpreter Lock (GIL) prevents mu...,2,Python uses reference counting with cycle detectio...,"memory, python",2
5,Convolutional Neural Networks (CNNs) use convoluti...,7,Backpropagation calculates gradients through autom...,"neural_network, deep_learning",2
6,Transformers revolutionized NLP by using self-atte...,8,BERT uses bidirectional transformers with masked l...,"nlp, transformer",2
12,Feature engineering transforms raw data into infor...,13,Data normalization techniques like StandardScaler ...,"preprocessing, data",2
1,Python's Global Interpreter Lock (GIL) prevents mu...,10,GPU acceleration leverages thousands of CUDA cores...,parallelization,1
1,Python's Global Interpreter Lock (GIL) prevents mu...,11,Mixed precision training uses FP16 for forward/bac...,memory,1
2,Python uses reference counting with cycle detectio...,11,Mixed precision training uses FP16 for forward/bac...,memory,1
3,Overfitting occurs when a model learns noise in tr...,4,Gradient descent optimizes model parameters by ite...,machine_learning,1
3,Overfitting occurs when a model learns noise in tr...,12,Feature engineering transforms raw data into infor...,machine_learning,1
4,Gradient descent optimizes model parameters by ite...,7,Backpropagation calculates gradients through autom...,gradient_descent,1
4,Gradient descent optimizes model parameters by ite...,10,GPU acceleration leverages thousands of CUDA cores...,optimization,1
4,Gradient descent optimizes model parameters by ite...,11,Mixed precision training uses FP16 for forward/bac...,optimization,1
4,Gradient descent optimizes model parameters by ite...,12,Feature engineering transforms raw data into infor...,machine_learning,1
4,Gradient descent optimizes model parameters by ite...,13,Data normalization techniques like StandardScaler ...,optimization,1
5,Convolutional Neural Networks (CNNs) use convoluti...,6,Transformers revolutionized NLP by using self-atte...,deep_learning,1
5,Convolutional Neural Networks (CNNs) use convoluti...,10,GPU acceleration leverages thousands of CUDA cores...,deep_learning,1
5,Convolutional Neural Networks (CNNs) use convoluti...,11,Mixed precision training uses FP16 for forward/bac...,deep_learning,1
6,Transformers revolutionized NLP by using self-atte...,7,Backpropagation calculates gradients through autom...,deep_learning,1
6,Transformers revolutionized NLP by using self-atte...,9,Tokenization strategies like BPE and WordPiece bal...,nlp,1
6,Transformers revolutionized NLP by using self-atte...,10,GPU acceleration leverages thousands of CUDA cores...,deep_learning,1
6,Transformers revolutionized NLP by using self-atte...,11,Mixed precision training uses FP16 for forward/bac...,deep_learning,1
7,Backpropagation calculates gradients through autom...,10,GPU acceleration leverages thousands of CUDA cores...,deep_learning,1
7,Backpropagation calculates gradients through autom...,11,Mixed precision training uses FP16 for forward/bac...,deep_learning,1
8,BERT uses bidirectional transformers with masked l...,9,Tokenization strategies like BPE and WordPiece bal...,nlp,1
9,Tokenization strategies like BPE and WordPiece bal...,12,Feature engineering transforms raw data into infor...,preprocessing,1
9,Tokenization strategies like BPE and WordPiece bal...,13,Data normalization techniques like StandardScaler ...,preprocessing,1
10,GPU acceleration leverages thousands of CUDA cores...,13,Data normalization techniques like StandardScaler ...,optimization,1
11,Mixed precision training uses FP16 for forward/bac...,13,Data normalization techniques like StandardScaler ...,optimization,1
