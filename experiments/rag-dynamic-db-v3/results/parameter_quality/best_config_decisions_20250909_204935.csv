query,novelty,similarity,edges,ged,ig,gedig_score,threshold,decision
How does Python's GIL affect multithreading?,0.826460074132839,0.17353992586716108,1,0.5,0.5132300370664195,0.24338498146679027,0.38,False
What causes overfitting in machine learning?,0.7894198759423384,0.21058012405766155,2,0.6499999999999999,0.5947099379711692,0.3526450310144153,0.38,False
How do transformers compare to RNNs for sequence modeling?,0.9369370268759346,0.06306297312406543,0,0.35,0.4684685134379673,0.11576574328101633,0.38,False
What's the relationship between gradient descent and backpropagation?,0.7421464028167466,0.25785359718325346,2,0.6499999999999999,0.5710732014083733,0.3644633992958133,0.38,False
How can we overcome GIL limitations in Python?,0.8395129101068508,0.16048708989314922,1,0.5,0.5197564550534254,0.2401217724732873,0.38,False
What are advanced regularization techniques beyond L1/L2?,0.7333196007924901,0.26668039920750986,1,0.5,0.4666598003962451,0.26667009980187745,0.38,False
How does attention mechanism work in transformers?,0.7421323379915266,0.25786766200847344,1,0.5,0.47106616899576326,0.26446691550211837,0.38,False
What is transfer learning and when to use it?,0.9048257103009294,0.09517428969907059,0,0.35,0.4524128551504647,0.12379357242476763,0.38,False
Explain the vanishing gradient problem,0.9302113183987943,0.06978868160120562,0,0.35,0.46510565919939717,0.11744717040030139,0.38,False
How do GANs generate realistic images?,0.979878521612913,0.020121478387087038,0,0.35,0.4899392608064565,0.10503036959677173,0.38,False
Compare CNN and transformer architectures for vision tasks,0.785378076836984,0.21462192316301593,3,0.7999999999999999,0.692689038418492,0.4536554807907539,0.38,True
When to use LSTM vs GRU vs Transformer?,0.7084759921334096,0.2915240078665904,3,0.7999999999999999,0.6542379960667049,0.4728810019666475,0.38,True
How does automatic differentiation work in PyTorch?,0.7955796221997967,0.20442037780020328,1,0.5,0.4977898110998984,0.2511050944500508,0.38,False
Explain the mathematics behind batch normalization,0.7893837228736762,0.21061627712632378,1,0.5,0.4946918614368381,0.25265406928158096,0.38,False
Best practices for deploying ML models in production,0.8609237863917976,0.13907621360820238,0,0.35,0.4304618931958988,0.1347690534020506,0.38,False
How to handle imbalanced datasets?,0.8147251364155575,0.18527486358444245,2,0.6499999999999999,0.6073625682077788,0.3463187158961105,0.38,False
Deep dive into Python memory management internals,0.7490752704783098,0.2509247295216902,2,0.6499999999999999,0.5745376352391549,0.36273118238042246,0.38,False
Advanced optimization techniques for deep learning,0.8041106113282277,0.19588938867177225,3,0.7999999999999999,0.7020553056641139,0.448972347167943,0.38,True
State-of-the-art NLP architectures beyond BERT,0.8307653338050632,0.16923466619493674,1,0.5,0.5153826669025316,0.24230866654873418,0.38,False
