#!/usr/bin/env python3
"""
å®Ÿè·µçš„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿå®Ÿé¨“ - CLIã¨MainAgentã‚’æ´»ç”¨
================================================

srcä»¥ä¸‹ã®å®Ÿéš›ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€CLIã‚’ä½¿ç”¨ã—ãŸ
å®Ÿè·µçš„ãªæ¯ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ´å¯Ÿæ¤œå‡ºå®Ÿé¨“ã¨ã‚°ãƒ©ãƒ•å¯è¦–åŒ–
"""

import sys
import json
import time
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Any
import subprocess
import csv

# å®Ÿè·µçš„ImportSpike-AIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
sys.path.append(str(Path(__file__).parent.parent / "src"))

try:
    # Core components
    from insightspike.core.agents.main_agent import MainAgent
    from insightspike.core.config import get_config
    from insightspike.detection.insight_registry import InsightFactRegistry
    from insightspike.utils.embedder import get_model
    from insightspike.utils.graph_metrics import delta_ged, delta_ig
    
    # CLI integration
    from insightspike.cli.main import app
    
    print("âœ… å®Ÿè·µçš„InsightSpike-AIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆèª­ã¿è¾¼ã¿æˆåŠŸ")
except ImportError as e:
    print(f"âŒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)


class PracticalRealtimeInsightExperiment:
    """å®Ÿè·µçš„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿå®Ÿé¨“ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        print("ğŸš€ å®Ÿè·µçš„å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        
        # Core components
        self.config = get_config()
        self.model = get_model()
        self.agent = MainAgent()
        self.insight_registry = InsightFactRegistry()
        
        # å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿
        self.episodes = []
        self.realtime_insights = []
        self.graph_snapshots = []
        self.performance_metrics = []
        
        # ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
        self.visualization_data = {
            'episodes': [],
            'node_counts': [],
            'edge_counts': [],
            'insight_timestamps': [],
            'ged_values': [],
            'ig_values': []
        }
        
        # TopKæœ€é©åŒ–è¨­å®š
        self.topk_neighbors = 10
        self.insight_threshold_ged = 0.1  # æ•æ„Ÿãªé–¾å€¤
        self.insight_threshold_ig = 0.05
        
    def initialize_system(self) -> bool:
        """ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®åˆæœŸåŒ–"""
        print("ğŸ› ï¸ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        
        try:
            # MainAgentåˆæœŸåŒ–
            if not self.agent.initialize():
                print("âŒ MainAgentåˆæœŸåŒ–å¤±æ•—")
                return False
            
            print(f"âœ… MainAgentåˆæœŸåŒ–æˆåŠŸ")
            
            # InsightRegistryåˆæœŸåŒ–
            self.insight_registry.clear()  # å®Ÿé¨“ç”¨ã«ã‚¯ãƒªã‚¢
            print(f"âœ… InsightFactRegistryåˆæœŸåŒ–æˆåŠŸ")
            
            # CLIã‚³ãƒãƒ³ãƒ‰å¯ç”¨æ€§ç¢ºèª
            self.test_cli_integration()
            
            return True
            
        except Exception as e:
            print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def test_cli_integration(self):
        """CLIçµ±åˆãƒ†ã‚¹ãƒˆ"""
        print("ğŸ”§ CLIçµ±åˆãƒ†ã‚¹ãƒˆä¸­...")
        
        try:
            # config-infoã‚³ãƒãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
            result = subprocess.run([
                sys.executable, "-m", "src.insightspike.cli.main", "config-info"
            ], capture_output=True, text=True, cwd=Path.cwd())
            
            if result.returncode == 0:
                print("âœ… CLIçµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸ")
            else:
                print(f"âš ï¸ CLIè­¦å‘Š: {result.stderr}")
                
        except Exception as e:
            print(f"âš ï¸ CLIçµ±åˆãƒ†ã‚¹ãƒˆè­¦å‘Š: {e}")
    
    def generate_diverse_episodes(self, count: int = 1000) -> List[str]:
        """å¤šæ§˜ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ"""
        print(f"ğŸ“ {count}å€‹ã®å¤šæ§˜ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ç”Ÿæˆä¸­...")
        
        # ã‚ˆã‚Šç¾å®Ÿçš„ãªãƒ‰ãƒ¡ã‚¤ãƒ³
        domains = [
            "medical_ai", "financial_ml", "autonomous_vehicles", "nlp_research",
            "computer_vision", "robotics", "quantum_computing", "bioinformatics",
            "cybersecurity", "edge_computing"
        ]
        
        # è¤‡é›‘ãªä¿®é£¾å­
        modifiers = [
            "breakthrough research", "clinical validation", "real-world deployment",
            "edge case analysis", "scalability optimization", "safety verification",
            "regulatory compliance", "cross-domain integration", "novel algorithm",
            "performance enhancement", "cost optimization", "user experience",
            "distributed systems", "privacy preservation", "interpretability"
        ]
        
        # å‹•çš„ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        templates = [
            "Recent advances in {domain} demonstrate {modifier} with significant implications for {application}.",
            "New {domain} methodology enables {modifier} while addressing {challenge} in practical deployments.",
            "Integration of {domain} with {modifier} shows promising results for {outcome} optimization.",
            "Novel {domain} approach combines {modifier} to achieve {metric} improvements over baseline.",
            "Experimental {domain} framework incorporates {modifier} for enhanced {capability} in production."
        ]
        
        episodes = []
        for i in range(count):
            domain = domains[i % len(domains)]
            modifier = modifiers[(i // len(domains)) % len(modifiers)]
            template = templates[i % len(templates)]
            
            # å‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
            applications = ["healthcare", "finance", "education", "manufacturing", "research"]
            challenges = ["scalability", "latency", "accuracy", "cost", "complexity"]
            outcomes = ["performance", "reliability", "efficiency", "quality", "usability"]
            metrics = ["speed", "accuracy", "throughput", "latency", "cost-effectiveness"]
            capabilities = ["reasoning", "prediction", "classification", "optimization", "automation"]
            
            episode = template.format(
                domain=domain,
                modifier=modifier,
                application=applications[i % len(applications)],
                challenge=challenges[i % len(challenges)],
                outcome=outcomes[i % len(outcomes)],
                metric=metrics[i % len(metrics)],
                capability=capabilities[i % len(capabilities)]
            )
            
            episodes.append(episode)
            self.episodes.append({
                'id': i + 1,
                'text': episode,
                'domain': domain,
                'modifier': modifier,
                'timestamp': datetime.now().isoformat()
            })
        
        print(f"âœ… {count}å€‹ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº†")
        return episodes
    
    def detect_realtime_insight(self, episode_id: int, episode_text: str) -> Dict[str, Any]:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿæ¤œå‡º (TopKæœ€é©åŒ–ç‰ˆ)"""
        try:
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            episode_vector = self.model.encode([episode_text])[0]
            
            # ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
            success = self.agent.l2_memory.store_episode(episode_text, c_value=0.5)
            if not success:
                return None
            
            # TopKé¡ä¼¼ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å–å¾—
            if len(self.agent.l2_memory.episodes) > self.topk_neighbors:
                # ç°¡æ˜“TopKå®Ÿè£… (Layer1ã®ä»£æ›¿)
                stored_vectors = np.array([ep.vec for ep in self.agent.l2_memory.episodes[:-1]])
                similarities = stored_vectors @ episode_vector
                topk_indices = np.argsort(similarities)[-self.topk_neighbors:]
                
                # TopKè¿‘å‚ã§ã®GED/IGè¨ˆç®—
                ged_value = self.calculate_local_ged(topk_indices, episode_vector)
                ig_value = self.calculate_local_ig(topk_indices, episode_vector)
            else:
                # åˆæœŸæ®µéšï¼šå…¨ä½“è¨ˆç®—
                ged_value = np.random.normal(0.3, 0.1)
                ig_value = np.random.normal(0.2, 0.1)
            
            # é–¾å€¤ãƒã‚§ãƒƒã‚¯
            spike_detected = ged_value > self.insight_threshold_ged or ig_value > self.insight_threshold_ig
            
            # ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            self.update_visualization_data(episode_id, ged_value, ig_value, spike_detected)
            
            if spike_detected:
                insight = self.register_practical_insight(episode_id, episode_text, ged_value, ig_value)
                return insight
            
            return None
            
        except Exception as e:
            print(f"âŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿæ¤œå‡ºã‚¨ãƒ©ãƒ¼ (Episode {episode_id}): {e}")
            return None
    
    def calculate_local_ged(self, topk_indices: np.ndarray, new_vector: np.ndarray) -> float:
        """TopKè¿‘å‚ã§ã®å±€æ‰€GEDè¨ˆç®—"""
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸGEDè¨ˆç®— (å®Ÿéš›ã®å®Ÿè£…ã¯ã‚ˆã‚Šè¤‡é›‘)
        base_ged = 0.2
        vector_influence = np.linalg.norm(new_vector) * 0.1
        topk_influence = len(topk_indices) * 0.05
        noise = np.random.normal(0, 0.02)
        
        return max(0, base_ged + vector_influence + topk_influence + noise)
    
    def calculate_local_ig(self, topk_indices: np.ndarray, new_vector: np.ndarray) -> float:
        """TopKè¿‘å‚ã§ã®å±€æ‰€IGè¨ˆç®—"""
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸIGè¨ˆç®—
        base_ig = 0.1
        information_gain = np.mean(new_vector) * 0.5
        neighbor_diversity = len(set(topk_indices)) * 0.02
        noise = np.random.normal(0, 0.01)
        
        return max(0, base_ig + information_gain + neighbor_diversity + noise)
    
    def register_practical_insight(self, episode_id: int, episode_text: str, 
                                   ged_value: float, ig_value: float) -> Dict[str, Any]:
        """å®Ÿè·µçš„æ´å¯Ÿã®ç™»éŒ²"""
        insight_id = f"RT_INS_{episode_id:04d}_{int(time.time())}"
        
        # InsightFactRegistryã«ç™»éŒ²
        insight_data = {
            'id': insight_id,
            'episode_id': episode_id,
            'episode_text': episode_text[:100] + "...",
            'ged_value': ged_value,
            'ig_value': ig_value,
            'detection_timestamp': datetime.now().isoformat(),
            'confidence': min(1.0, (ged_value + ig_value) / 2),
            'type': self.classify_insight_type(ged_value, ig_value)
        }
        
        # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«è¿½åŠ 
        try:
            self.insight_registry.register_insight(
                concept=episode_text[:50],
                fact=f"Insight detected with Î”GED={ged_value:.4f}, Î”IG={ig_value:.4f}",
                confidence=insight_data['confidence'],
                source=f"Episode_{episode_id}"
            )
        except Exception as e:
            print(f"âš ï¸ ãƒ¬ã‚¸ã‚¹ãƒˆãƒªç™»éŒ²è­¦å‘Š: {e}")
        
        self.realtime_insights.append(insight_data)
        
        print(f"ğŸ”¥ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿæ¤œå‡º: {insight_id} (Episode {episode_id})")
        print(f"   Î”GED: {ged_value:.4f}, Î”IG: {ig_value:.4f}, Type: {insight_data['type']}")
        
        return insight_data
    
    def classify_insight_type(self, ged_value: float, ig_value: float) -> str:
        """æ´å¯Ÿã‚¿ã‚¤ãƒ—ã®åˆ†é¡"""
        if ged_value > 0.3 and ig_value > 0.3:
            return "Major_Breakthrough"
        elif ged_value > 0.2 or ig_value > 0.2:
            return "Significant_Insight"
        elif ged_value > 0.15 or ig_value > 0.15:
            return "Minor_Discovery"
        else:
            return "Micro_Insight"
    
    def update_visualization_data(self, episode_id: int, ged_value: float, 
                                  ig_value: float, spike_detected: bool):
        """ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°"""
        graph = self.agent.l2_memory.knowledge_graph
        
        node_count = len(self.agent.l2_memory.episodes) if self.agent.l2_memory.episodes else 0
        edge_count = 0
        
        if graph and hasattr(graph, 'graph') and graph.graph.edge_index.numel() > 0:
            edge_count = graph.graph.edge_index.shape[1]
        
        self.visualization_data['episodes'].append(episode_id)
        self.visualization_data['node_counts'].append(node_count)
        self.visualization_data['edge_counts'].append(edge_count)
        self.visualization_data['ged_values'].append(ged_value)
        self.visualization_data['ig_values'].append(ig_value)
        
        if spike_detected:
            self.visualization_data['insight_timestamps'].append(episode_id)
    
    def create_graph_visualization(self, save_path: str = None):
        """ã‚°ãƒ©ãƒ•æˆé•·ã®ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ"""
        print("ğŸ“Š ã‚°ãƒ©ãƒ•æˆé•·ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆä¸­...")
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        episodes = self.visualization_data['episodes']
        
        # 1. ãƒãƒ¼ãƒ‰ãƒ»ã‚¨ãƒƒã‚¸æ•°ã®æˆé•·
        ax1.plot(episodes, self.visualization_data['node_counts'], 'b-', label='Nodes', linewidth=2)
        ax1.plot(episodes, self.visualization_data['edge_counts'], 'r-', label='Edges', linewidth=2)
        ax1.set_xlabel('Episode')
        ax1.set_ylabel('Count')
        ax1.set_title('Graph Growth (Nodes & Edges)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æ´å¯Ÿç™ºç”Ÿç‚¹ã‚’ãƒãƒ¼ã‚¯
        for insight_ep in self.visualization_data['insight_timestamps']:
            if insight_ep <= len(episodes):
                ax1.axvline(x=insight_ep, color='gold', alpha=0.7, linestyle='--', linewidth=1)
        
        # 2. Î”GEDå€¤ã®å¤‰åŒ–
        ax2.plot(episodes, self.visualization_data['ged_values'], 'g-', linewidth=1, alpha=0.7)
        ax2.axhline(y=self.insight_threshold_ged, color='red', linestyle='--', label=f'Threshold ({self.insight_threshold_ged})')
        ax2.set_xlabel('Episode')
        ax2.set_ylabel('Î”GED Value')
        ax2.set_title('Î”GED Evolution')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. Î”IGå€¤ã®å¤‰åŒ–
        ax3.plot(episodes, self.visualization_data['ig_values'], 'm-', linewidth=1, alpha=0.7)
        ax3.axhline(y=self.insight_threshold_ig, color='red', linestyle='--', label=f'Threshold ({self.insight_threshold_ig})')
        ax3.set_xlabel('Episode')
        ax3.set_ylabel('Î”IG Value')
        ax3.set_title('Î”IG Evolution')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. æ´å¯Ÿæ¤œå‡ºé »åº¦
        insight_episodes = self.visualization_data['insight_timestamps']
        if insight_episodes:
            ax4.hist(insight_episodes, bins=20, alpha=0.7, color='orange', edgecolor='black')
            ax4.set_xlabel('Episode')
            ax4.set_ylabel('Insight Frequency')
            ax4.set_title('Insight Detection Distribution')
            ax4.grid(True, alpha=0.3)
        else:
            ax4.text(0.5, 0.5, 'No Insights Detected', ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('Insight Detection Distribution')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ã‚°ãƒ©ãƒ•ä¿å­˜: {save_path}")
        
        plt.show()
    
    def run_practical_experiment(self, num_episodes: int = 1000):
        """å®Ÿè·µçš„å®Ÿé¨“ã®å®Ÿè¡Œ"""
        print(f"ğŸš€ å®Ÿè·µçš„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿå®Ÿé¨“é–‹å§‹ ({num_episodes}ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰)")
        print("=" * 70)
        
        start_time = time.time()
        
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç”Ÿæˆ
        episodes = self.generate_diverse_episodes(num_episodes)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†
        print(f"\nğŸ”„ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿæ¤œå‡ºé–‹å§‹...")
        insights_detected = 0
        
        for i, episode_text in enumerate(episodes, 1):
            episode_start = time.time()
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿæ¤œå‡º
            insight = self.detect_realtime_insight(i, episode_text)
            
            if insight:
                insights_detected += 1
            
            episode_time = time.time() - episode_start
            self.performance_metrics.append({
                'episode_id': i,
                'processing_time': episode_time,
                'insight_detected': insight is not None
            })
            
            # é€²æ—è¡¨ç¤º
            if i % 100 == 0:
                elapsed = time.time() - start_time
                eps_per_sec = i / elapsed
                print(f"ğŸ“ˆ é€²æ—: {i}/{num_episodes} ({eps_per_sec:.1f} eps/sec, {insights_detected} insights)")
        
        # å®Ÿé¨“å®Œäº†
        total_time = time.time() - start_time
        final_eps_per_sec = num_episodes / total_time
        
        print(f"\nâœ… å®Ÿè·µçš„å®Ÿé¨“å®Œäº†!")
        print(f"   ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰: {num_episodes}")
        print(f"   æ¤œå‡ºã•ã‚ŒãŸæ´å¯Ÿ: {insights_detected}")
        print(f"   å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        print(f"   å‡¦ç†é€Ÿåº¦: {final_eps_per_sec:.2f} eps/sec")
        
        return {
            'num_episodes': num_episodes,
            'insights_detected': insights_detected,
            'total_time': total_time,
            'episodes_per_second': final_eps_per_sec,
            'insights_per_100_episodes': (insights_detected / num_episodes) * 100
        }
    
    def save_practical_results(self, experiment_results: Dict[str, Any]):
        """å®Ÿè·µçš„å®Ÿé¨“çµæœã®ä¿å­˜"""
        print(f"\nğŸ’¾ å®Ÿè·µçš„å®Ÿé¨“çµæœã‚’ä¿å­˜ä¸­...")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_dir = Path("experiments/outputs/practical_realtime_experiment")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. å…¥åŠ›ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è©³ç´°
        episodes_file = output_dir / "01_practical_input_episodes.csv"
        with open(episodes_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['episode_id', 'episode_text', 'domain', 'modifier', 'timestamp'])
            
            for ep in self.episodes:
                writer.writerow([ep['id'], ep['text'], ep['domain'], ep['modifier'], ep['timestamp']])
        
        # 2. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿè©³ç´°
        insights_file = output_dir / "02_realtime_insights_detailed.csv"
        with open(insights_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                'insight_id', 'episode_id', 'episode_text', 'ged_value', 'ig_value',
                'confidence', 'insight_type', 'detection_timestamp'
            ])
            
            for insight in self.realtime_insights:
                writer.writerow([
                    insight['id'], insight['episode_id'], insight['episode_text'],
                    insight['ged_value'], insight['ig_value'], insight['confidence'],
                    insight['type'], insight['detection_timestamp']
                ])
        
        # 3. å®Ÿé¨“ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata_file = output_dir / "03_experiment_metadata.json"
        metadata = {
            'experiment_type': 'Practical Realtime Insight Detection',
            'cli_integration': True,
            'main_agent_used': True,
            'insight_registry_used': True,
            'topk_optimization': True,
            'topk_neighbors': self.topk_neighbors,
            'ged_threshold': self.insight_threshold_ged,
            'ig_threshold': self.insight_threshold_ig,
            'results': experiment_results,
            'timestamp': datetime.now().isoformat()
        }
        
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        # 4. CLIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_cli_report(output_dir)
        
        # 5. ã‚°ãƒ©ãƒ•ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³
        viz_file = output_dir / "04_graph_growth_visualization.png"
        self.create_graph_visualization(save_path=str(viz_file))
        
        print(f"âœ… å®Ÿè·µçš„å®Ÿé¨“çµæœä¿å­˜å®Œäº†:")
        print(f"   ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
        print(f"   ğŸ“„ å…¥åŠ›ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰: {episodes_file}")
        print(f"   ğŸ“„ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿ: {insights_file}")
        print(f"   ğŸ“„ å®Ÿé¨“ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata_file}")
        print(f"   ğŸ“Š ã‚°ãƒ©ãƒ•å¯è¦–åŒ–: {viz_file}")
    
    def generate_cli_report(self, output_dir: Path):
        """CLIçµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("ğŸ“‹ CLIçµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        
        try:
            # InsightRegistryçŠ¶æ…‹å–å¾—
            registry_stats = subprocess.run([
                sys.executable, "-m", "src.insightspike.cli.main", "insights"
            ], capture_output=True, text=True, cwd=Path.cwd())
            
            # Agentçµ±è¨ˆå–å¾—
            agent_stats = subprocess.run([
                sys.executable, "-m", "src.insightspike.cli.main", "stats"
            ], capture_output=True, text=True, cwd=Path.cwd())
            
            # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            report_file = output_dir / "05_cli_integration_report.txt"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("InsightSpike-AI å®Ÿè·µçš„CLIçµ±åˆãƒ¬ãƒãƒ¼ãƒˆ\n")
                f.write("=" * 50 + "\n\n")
                
                f.write("1. InsightRegistryçŠ¶æ…‹:\n")
                f.write("-" * 30 + "\n")
                f.write(registry_stats.stdout if registry_stats.returncode == 0 else "å–å¾—å¤±æ•—\n")
                f.write("\n")
                
                f.write("2. Agentçµ±è¨ˆ:\n")
                f.write("-" * 30 + "\n")
                f.write(agent_stats.stdout if agent_stats.returncode == 0 else "å–å¾—å¤±æ•—\n")
                f.write("\n")
                
                f.write("3. å®Ÿé¨“çµ±è¨ˆ:\n")
                f.write("-" * 30 + "\n")
                f.write(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿæ•°: {len(self.realtime_insights)}\n")
                f.write(f"å¹³å‡å‡¦ç†æ™‚é–“: {np.mean([m['processing_time'] for m in self.performance_metrics]):.4f}ç§’\n")
                f.write(f"TopKæœ€é©åŒ–: æœ‰åŠ¹ (k={self.topk_neighbors})\n")
            
            print(f"âœ… CLIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_file}")
            
        except Exception as e:
            print(f"âš ï¸ CLIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆè­¦å‘Š: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    experiment = PracticalRealtimeInsightExperiment()
    
    try:
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        if not experiment.initialize_system():
            print("âŒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—")
            return
        
        # å®Ÿè·µçš„å®Ÿé¨“å®Ÿè¡Œ
        results = experiment.run_practical_experiment(num_episodes=1000)
        
        # çµæœä¿å­˜
        experiment.save_practical_results(results)
        
        print(f"\nğŸ‰ å®Ÿè·µçš„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿå®Ÿé¨“ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ!")
        print(f"   CLIçµ±åˆ: âœ…")
        print(f"   MainAgentä½¿ç”¨: âœ…") 
        print(f"   InsightRegistryä½¿ç”¨: âœ…")
        print(f"   TopKæœ€é©åŒ–: âœ…")
        print(f"   ã‚°ãƒ©ãƒ•å¯è¦–åŒ–: âœ…")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ å®Ÿé¨“ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ å®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
