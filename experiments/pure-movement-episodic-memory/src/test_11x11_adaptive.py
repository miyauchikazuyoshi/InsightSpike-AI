#!/usr/bin/env python3
"""
11Ã—11è¿·è·¯ã§ã®é©å¿œçš„geDIGæ·±åº¦é¸æŠãƒ†ã‚¹ãƒˆ
"""

import numpy as np
import time
import json
from datetime import datetime
from pathlib import Path
import sys
import os

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../src'))

from insightspike.environments.proper_maze_generator import ProperMazeGenerator
from pure_memory_agent import PureMemoryAgent
from pure_memory_agent_adaptive import PureMemoryAgentAdaptive


def test_11x11_comparison():
    """11Ã—11è¿·è·¯ã§å›ºå®šæ·±åº¦vsé©å¿œçš„æ·±åº¦ã‚’æ¯”è¼ƒ"""
    
    print("="*70)
    print("ğŸ¯ 11Ã—11è¿·è·¯ é©å¿œçš„geDIGæ·±åº¦é¸æŠ å®Ÿé¨“")
    print("="*70)
    
    # çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_path = Path(f"../results/11x11_adaptive_{timestamp}")
    base_path.mkdir(parents=True, exist_ok=True)
    
    # 11Ã—11è¿·è·¯ç”Ÿæˆ
    generator = ProperMazeGenerator()
    maze = generator.generate_dfs_maze(size=(11, 11), seed=42)
    
    print("\nğŸ—ºï¸ è¿·è·¯ (11Ã—11):")
    for row in maze:
        print(' '.join(['.' if x == 0 else 'â–ˆ' for x in row]))
    
    # æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°
    max_steps = 1000
    
    print(f"\nâš™ï¸ è¨­å®š:")
    print(f"  æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°: {max_steps}")
    print(f"  æ¤œç´¢æ•°(k): 20")
    
    # å®Ÿé¨“çµæœæ ¼ç´
    results = {}
    
    # ============================================================
    # 1. å›ºå®šæ·±åº¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆ3ãƒ›ãƒƒãƒ—ï¼‰
    # ============================================================
    print("\n" + "="*70)
    print("ğŸ“Œ ãƒ†ã‚¹ãƒˆ1: å›ºå®šæ·±åº¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆ3ãƒ›ãƒƒãƒ—å›ºå®šï¼‰")
    print("="*70)
    
    agent_fixed = PureMemoryAgent(
        maze=maze.copy(),
        datastore_path=str(base_path / "fixed_depth"),
        config={
            'max_depth': 3,
            'search_k': 20
        }
    )
    
    print(f"ã‚¹ã‚¿ãƒ¼ãƒˆ: {agent_fixed.position}")
    print(f"ã‚´ãƒ¼ãƒ«: {agent_fixed.goal}")
    
    start_time = time.time()
    
    for step in range(max_steps):
        if agent_fixed.is_goal_reached():
            success_fixed = True
            break
        
        action = agent_fixed.get_action()
        agent_fixed.execute_action(action)
        
        # é€²æ—å ±å‘Š
        if step % 100 == 0 and step > 0:
            stats = agent_fixed.get_statistics()
            print(f"  ã‚¹ãƒ†ãƒƒãƒ— {step}: è·é›¢={stats['distance_to_goal']}, "
                  f"å£è¡çª={stats['wall_hits']}å› "
                  f"({stats['wall_hits']/step*100:.1f}%)")
    else:
        success_fixed = False
    
    time_fixed = time.time() - start_time
    stats_fixed = agent_fixed.get_statistics()
    
    results['fixed'] = {
        'success': success_fixed,
        'steps': step if success_fixed else max_steps,
        'time': time_fixed,
        'wall_hits': stats_fixed['wall_hits'],
        'wall_hit_rate': stats_fixed['wall_hits'] / max(step, 1),
        'episodes': stats_fixed['total_episodes'],
        'path_length': stats_fixed['path_length'],
        'final_distance': stats_fixed['distance_to_goal'],
        'depth_usage': stats_fixed['depth_usage']
    }
    
    if success_fixed:
        print(f"\nâœ… æˆåŠŸï¼ {step}ã‚¹ãƒ†ãƒƒãƒ—ã§åˆ°é”")
    else:
        print(f"\nâŒ å¤±æ•—... æœ€çµ‚è·é›¢: {stats_fixed['distance_to_goal']}")
    
    print(f"  å£è¡çªç‡: {results['fixed']['wall_hit_rate']:.1%}")
    print(f"  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {results['fixed']['episodes']}")
    print(f"  å®Ÿè¡Œæ™‚é–“: {results['fixed']['time']:.2f}ç§’")
    
    # ============================================================
    # 2. é©å¿œçš„æ·±åº¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆgeDIGåŸºæº–ï¼‰
    # ============================================================
    print("\n" + "="*70)
    print("ğŸ§  ãƒ†ã‚¹ãƒˆ2: é©å¿œçš„æ·±åº¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆgeDIGåŸºæº–ï¼‰")
    print("="*70)
    
    agent_adaptive = PureMemoryAgentAdaptive(
        maze=maze.copy(),
        datastore_path=str(base_path / "adaptive_depth"),
        config={
            'max_depth': 5,
            'search_k': 20,
            'gedig_improvement_threshold': 0.05  # 5%æ”¹å–„ã§æ¡ç”¨
        }
    )
    
    print(f"ã‚¹ã‚¿ãƒ¼ãƒˆ: {agent_adaptive.position}")
    print(f"ã‚´ãƒ¼ãƒ«: {agent_adaptive.goal}")
    print(f"geDIGæ”¹å–„é–¾å€¤: 5%")
    
    start_time = time.time()
    
    # æ·±åº¦é¸æŠã®è©³ç´°è¨˜éŒ²
    depth_history = []
    
    for step in range(max_steps):
        if agent_adaptive.is_goal_reached():
            success_adaptive = True
            break
        
        # æ·±åº¦é¸æŠã‚’è¨˜éŒ²
        before_selections = len(agent_adaptive.stats['adaptive_depth_selections'])
        
        action = agent_adaptive.get_action()
        agent_adaptive.execute_action(action)
        
        # æ–°ã—ã„æ·±åº¦é¸æŠãŒã‚ã‚Œã°è¨˜éŒ²
        if len(agent_adaptive.stats['adaptive_depth_selections']) > before_selections:
            selected_depth = agent_adaptive.stats['adaptive_depth_selections'][-1]
            depth_history.append((step, selected_depth))
        
        # é€²æ—å ±å‘Š
        if step % 100 == 0 and step > 0:
            stats = agent_adaptive.get_statistics()
            avg_depth = stats.get('avg_adaptive_depth', 0)
            print(f"  ã‚¹ãƒ†ãƒƒãƒ— {step}: è·é›¢={stats['distance_to_goal']}, "
                  f"å£è¡çª={stats['wall_hits']}å› "
                  f"({stats['wall_hits']/step*100:.1f}%), "
                  f"å¹³å‡æ·±åº¦={avg_depth:.2f}")
    else:
        success_adaptive = False
    
    time_adaptive = time.time() - start_time
    stats_adaptive = agent_adaptive.get_statistics()
    
    results['adaptive'] = {
        'success': success_adaptive,
        'steps': step if success_adaptive else max_steps,
        'time': time_adaptive,
        'wall_hits': stats_adaptive['wall_hits'],
        'wall_hit_rate': stats_adaptive['wall_hits'] / max(step, 1),
        'episodes': stats_adaptive['total_episodes'],
        'path_length': stats_adaptive['path_length'],
        'final_distance': stats_adaptive['distance_to_goal'],
        'depth_usage': stats_adaptive['depth_usage'],
        'avg_adaptive_depth': stats_adaptive.get('avg_adaptive_depth', 0),
        'adaptive_selections': stats_adaptive.get('adaptive_selections', [])
    }
    
    if success_adaptive:
        print(f"\nâœ… æˆåŠŸï¼ {step}ã‚¹ãƒ†ãƒƒãƒ—ã§åˆ°é”")
    else:
        print(f"\nâŒ å¤±æ•—... æœ€çµ‚è·é›¢: {stats_adaptive['distance_to_goal']}")
    
    print(f"  å£è¡çªç‡: {results['adaptive']['wall_hit_rate']:.1%}")
    print(f"  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {results['adaptive']['episodes']}")
    print(f"  å®Ÿè¡Œæ™‚é–“: {results['adaptive']['time']:.2f}ç§’")
    print(f"  å¹³å‡é¸æŠæ·±åº¦: {results['adaptive']['avg_adaptive_depth']:.2f}")
    
    # ============================================================
    # 3. æ¯”è¼ƒåˆ†æ
    # ============================================================
    print("\n" + "="*70)
    print("ğŸ“Š æ¯”è¼ƒçµæœ")
    print("="*70)
    
    # æˆåŠŸç‡
    print("\nğŸ¯ æˆåŠŸ/å¤±æ•—:")
    print(f"  å›ºå®šæ·±åº¦:   {'âœ… æˆåŠŸ' if results['fixed']['success'] else 'âŒ å¤±æ•—'}")
    print(f"  é©å¿œçš„æ·±åº¦: {'âœ… æˆåŠŸ' if results['adaptive']['success'] else 'âŒ å¤±æ•—'}")
    
    # ã‚¹ãƒ†ãƒƒãƒ—æ•°æ¯”è¼ƒ
    if results['fixed']['success'] or results['adaptive']['success']:
        print("\nğŸ“ ã‚´ãƒ¼ãƒ«åˆ°é”ã‚¹ãƒ†ãƒƒãƒ—æ•°:")
        if results['fixed']['success']:
            print(f"  å›ºå®šæ·±åº¦:   {results['fixed']['steps']}ã‚¹ãƒ†ãƒƒãƒ—")
        if results['adaptive']['success']:
            print(f"  é©å¿œçš„æ·±åº¦: {results['adaptive']['steps']}ã‚¹ãƒ†ãƒƒãƒ—")
            
        # æ”¹å–„ç‡è¨ˆç®—
        if results['fixed']['success'] and results['adaptive']['success']:
            improvement = (results['fixed']['steps'] - results['adaptive']['steps']) / results['fixed']['steps'] * 100
            if improvement > 0:
                print(f"  â†’ é©å¿œçš„æ·±åº¦ãŒ {improvement:.1f}% æ”¹å–„ï¼")
            elif improvement < 0:
                print(f"  â†’ å›ºå®šæ·±åº¦ã®æ–¹ãŒ {-improvement:.1f}% è‰¯ã„")
            else:
                print(f"  â†’ åŒã˜ã‚¹ãƒ†ãƒƒãƒ—æ•°")
    
    # å£è¡çªç‡æ¯”è¼ƒ
    print("\nğŸ§± å£è¡çªç‡:")
    print(f"  å›ºå®šæ·±åº¦:   {results['fixed']['wall_hit_rate']:.1%}")
    print(f"  é©å¿œçš„æ·±åº¦: {results['adaptive']['wall_hit_rate']:.1%}")
    wall_improvement = (results['fixed']['wall_hit_rate'] - results['adaptive']['wall_hit_rate']) / results['fixed']['wall_hit_rate'] * 100
    if wall_improvement > 0:
        print(f"  â†’ é©å¿œçš„æ·±åº¦ãŒ {wall_improvement:.1f}% æ”¹å–„ï¼")
    
    # è¨ˆç®—åŠ¹ç‡
    print("\nâ±ï¸ å®Ÿè¡Œæ™‚é–“:")
    print(f"  å›ºå®šæ·±åº¦:   {results['fixed']['time']:.2f}ç§’")
    print(f"  é©å¿œçš„æ·±åº¦: {results['adaptive']['time']:.2f}ç§’")
    
    # æ·±åº¦ä½¿ç”¨åˆ†æï¼ˆé©å¿œçš„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰
    if results['adaptive']['adaptive_selections']:
        print("\nğŸ” é©å¿œçš„æ·±åº¦ã®é¸æŠãƒ‘ã‚¿ãƒ¼ãƒ³:")
        selections = results['adaptive']['adaptive_selections']
        
        # æ·±åº¦åˆ†å¸ƒ
        depth_counts = {}
        for d in selections:
            depth_counts[d] = depth_counts.get(d, 0) + 1
        
        for depth in sorted(depth_counts.keys()):
            percentage = depth_counts[depth] / len(selections) * 100
            bar = 'â–ˆ' * int(percentage / 2)
            print(f"  {depth}ãƒ›ãƒƒãƒ—: {depth_counts[depth]:3d}å› ({percentage:5.1f}%) {bar}")
        
        # åºç›¤ã¨çµ‚ç›¤ã®æ¯”è¼ƒ
        if len(selections) > 20:
            early = selections[:10]
            late = selections[-10:]
            print(f"\n  åºç›¤ã®å¹³å‡æ·±åº¦: {np.mean(early):.2f}")
            print(f"  çµ‚ç›¤ã®å¹³å‡æ·±åº¦: {np.mean(late):.2f}")
            
            change = np.mean(late) - np.mean(early)
            if change > 0.3:
                print("  â†’ ğŸ“ˆ å­¦ç¿’ã¨ã¨ã‚‚ã«æ·±ã„æ¢ç´¢ã‚’æ´»ç”¨")
            elif change < -0.3:
                print("  â†’ ğŸ“‰ å­¦ç¿’ã¨ã¨ã‚‚ã«æµ…ã„æ¢ç´¢ã«åæŸ")
            else:
                print("  â†’ ğŸ“Š å®‰å®šã—ãŸæ·±åº¦é¸æŠ")
    
    # geDIGè©•ä¾¡ã®åˆ†æ
    if agent_adaptive.stats.get('gedig_evaluations'):
        evaluations = agent_adaptive.stats['gedig_evaluations']
        improvements = []
        
        for eval_history in evaluations[:50]:  # æœ€åˆã®50å€‹
            if len(eval_history) > 1:
                base = eval_history[0][1]
                best = min(h[1] for h in eval_history)
                improvement = (base - best) / (base + 0.001)
                improvements.append(improvement)
        
        if improvements:
            print(f"\nğŸ’¡ geDIGæ”¹å–„ç‡:")
            print(f"  å¹³å‡: {np.mean(improvements):.3f}")
            print(f"  æœ€å¤§: {max(improvements):.3f}")
            print(f"  æœ€å°: {min(improvements):.3f}")
    
    # çµæœã‚’JSONä¿å­˜
    with open(base_path / "comparison_results.json", 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ“ çµæœã‚’ä¿å­˜: {base_path}")
    
    return results


if __name__ == "__main__":
    results = test_11x11_comparison()
    
    print("\n" + "="*70)
    print("ğŸ å®Ÿé¨“å®Œäº†ï¼")
    print("="*70)
    
    # æœ€çµ‚è©•ä¾¡
    if results['adaptive']['success'] and not results['fixed']['success']:
        print("â­ é©å¿œçš„æ·±åº¦é¸æŠãŒå„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ï¼")
        print("   å›ºå®šæ·±åº¦ã§ã¯è§£ã‘ãªã‹ã£ãŸè¿·è·¯ã‚’è§£æ±º")
    elif results['adaptive']['success'] and results['fixed']['success']:
        if results['adaptive']['steps'] < results['fixed']['steps']:
            print("âœ¨ é©å¿œçš„æ·±åº¦é¸æŠãŒã‚ˆã‚ŠåŠ¹ç‡çš„ï¼")
            print("   å°‘ãªã„ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚´ãƒ¼ãƒ«ã«åˆ°é”")
        elif results['adaptive']['wall_hit_rate'] < results['fixed']['wall_hit_rate']:
            print("ğŸ¯ é©å¿œçš„æ·±åº¦é¸æŠãŒã‚ˆã‚Šæ­£ç¢ºï¼")
            print("   å£è¡çªãŒå°‘ãªã„")
        else:
            print("ğŸ“Š ä¸¡æ‰‹æ³•ã¨ã‚‚æˆåŠŸã€æ€§èƒ½ã¯åŒç­‰")
    elif not results['adaptive']['success'] and not results['fixed']['success']:
        print("ğŸ”§ ä¸¡æ‰‹æ³•ã¨ã‚‚å¤±æ•—...")
        print("   ã‚ˆã‚Šé•·ã„å­¦ç¿’æ™‚é–“ãŒå¿…è¦ã‹ã‚‚")
    else:
        print("ğŸ“ˆ å›ºå®šæ·±åº¦ã®æ–¹ãŒè‰¯ã„çµæœ")
        print("   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãŒå¿…è¦ã‹ã‚‚")