#!/usr/bin/env python3
"""
OptimizedNumpyIndexã‚’ä½¿ç”¨ã—ãŸç´”ç²‹è¨˜æ†¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ
é«˜é€Ÿæ¤œç´¢ã®æ€§èƒ½è©•ä¾¡
"""

import numpy as np
import time
import sys
import os

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../src'))

from insightspike.environments.proper_maze_generator import ProperMazeGenerator
from pure_memory_agent_optimized import PureMemoryAgentOptimized


def test_performance_comparison():
    """æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
    
    print("="*70)
    print("ğŸš€ OptimizedNumpyIndexæ€§èƒ½è©•ä¾¡")
    print("  ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰ã®é«˜é€Ÿæ¤œç´¢å®Ÿè£…ã‚’æ´»ç”¨")
    print("="*70)
    
    # 15Ã—15è¿·è·¯ã§ãƒ†ã‚¹ãƒˆ
    generator = ProperMazeGenerator()
    maze = generator.generate_dfs_maze(size=(15, 15), seed=456)
    
    print("\nè¿·è·¯ (15Ã—15):")
    for row in maze:
        print(''.join(['.' if x == 0 else 'â–ˆ' for x in row]))
    
    # æœ€é©åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    agent = PureMemoryAgentOptimized(
        maze=maze,
        datastore_path="../results/optimized_test",
        config={
            'max_depth': 5,
            'search_k': 30,
            'gedig_threshold': 0.6,
            'max_edges_per_node': 15
        }
    )
    
    print(f"\nğŸ“ ã‚¹ã‚¿ãƒ¼ãƒˆ: {agent.position}")
    print(f"ğŸ¯ ã‚´ãƒ¼ãƒ«: {agent.goal}")
    print(f"åˆæœŸè·é›¢: {abs(agent.position[0] - agent.goal[0]) + abs(agent.position[1] - agent.goal[1])}")
    print("-" * 50)
    
    # æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
    step_times = []
    search_times_per_100 = []
    gedig_values_per_100 = []
    
    max_steps = 500
    for step in range(max_steps):
        if agent.is_goal_reached():
            print(f"\nâœ… æˆåŠŸï¼ {step}ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚´ãƒ¼ãƒ«åˆ°é”")
            break
        
        # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œæ™‚é–“è¨ˆæ¸¬
        step_start = time.time()
        action = agent.get_action()
        agent.execute_action(action)
        step_time = (time.time() - step_start) * 1000
        step_times.append(step_time)
        
        # 100ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®çµ±è¨ˆ
        if step % 100 == 99:
            stats = agent.get_statistics()
            
            # æ¤œç´¢æ€§èƒ½
            avg_search = stats['avg_search_time_ms']
            search_times_per_100.append(avg_search)
            
            # geDIGå€¤
            avg_gedig = stats['avg_gedig']
            gedig_values_per_100.append(avg_gedig)
            
            print(f"\nğŸ“Š Step {step+1} çµ±è¨ˆ:")
            print(f"  è·é›¢: {stats['distance_to_goal']}")
            print(f"  å£è¡çªç‡: {stats['wall_hit_rate']:.1%}")
            print(f"  å¹³å‡æ¤œç´¢æ™‚é–“: {avg_search:.3f}ms")
            print(f"  å¹³å‡geDIG: {avg_gedig:.3f}")
            print(f"  ã‚°ãƒ©ãƒ•: {stats['graph_nodes']}ãƒãƒ¼ãƒ‰, {stats['graph_edges']}ã‚¨ãƒƒã‚¸")
            print(f"  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {stats['total_episodes']}")
    
    # æœ€çµ‚çµ±è¨ˆ
    final_stats = agent.get_statistics()
    
    print("\n" + "="*70)
    print("ğŸ“ˆ æ€§èƒ½è©•ä¾¡çµæœ")
    print("="*70)
    
    print("\nåŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
    print(f"  ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {final_stats['steps']}")
    print(f"  å£è¡çªç‡: {final_stats['wall_hit_rate']:.1%}")
    print(f"  ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {final_stats['total_episodes']}")
    
    print("\næ¤œç´¢æ€§èƒ½:")
    if step_times:
        print(f"  å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—æ™‚é–“: {np.mean(step_times):.2f}ms")
        print(f"  æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ™‚é–“: {np.max(step_times):.2f}ms")
    
    if search_times_per_100:
        print(f"  å¹³å‡æ¤œç´¢æ™‚é–“: {np.mean(search_times_per_100):.3f}ms")
        print(f"  æ¤œç´¢æ™‚é–“ã®å¤‰åŒ–: {search_times_per_100}")
    
    print("\ngeDIGè©•ä¾¡:")
    if gedig_values_per_100:
        print(f"  å¹³å‡geDIG: {np.mean(gedig_values_per_100):.3f}")
        print(f"  geDIGå€¤ã®å¤‰åŒ–: {[f'{v:.3f}' for v in gedig_values_per_100]}")
    
    print("\næ·±åº¦ä½¿ç”¨:")
    total_depth_usage = sum(final_stats['depth_usage'].values())
    if total_depth_usage > 0:
        for depth, count in final_stats['depth_usage'].items():
            ratio = count / total_depth_usage * 100
            print(f"  {depth}ãƒ›ãƒƒãƒ—: {count}å› ({ratio:.1f}%)")
    
    print("\nã‚°ãƒ©ãƒ•æ§‹é€ :")
    print(f"  ãƒãƒ¼ãƒ‰æ•°: {final_stats['graph_nodes']}")
    print(f"  ã‚¨ãƒƒã‚¸æ•°: {final_stats['graph_edges']}")
    if final_stats['graph_nodes'] > 0:
        avg_degree = 2 * final_stats['graph_edges'] / final_stats['graph_nodes']
        print(f"  å¹³å‡æ¬¡æ•°: {avg_degree:.2f}")
    
    # åŠ¹ç‡æ€§è©•ä¾¡
    print("\nâš¡ åŠ¹ç‡æ€§è©•ä¾¡:")
    
    # O(n) vs O(k)ã®æ”¹å–„
    if final_stats['total_episodes'] > 0:
        theoretical_o_n = final_stats['total_episodes'] * final_stats['steps']
        actual_operations = agent.search_k * final_stats['steps']
        improvement = (theoretical_o_n - actual_operations) / theoretical_o_n * 100
        
        print(f"  ç†è«–çš„O(n)æ“ä½œæ•°: {theoretical_o_n:,}")
        print(f"  å®Ÿéš›ã®O(k)æ“ä½œæ•°: {actual_operations:,}")
        print(f"  æ”¹å–„ç‡: {improvement:.1f}%")
    
    # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡
    print(f"\nãƒ¡ãƒ¢ãƒªåŠ¹ç‡:")
    print(f"  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å½“ãŸã‚Šã®ã‚¨ãƒƒã‚¸æ•°: {final_stats['graph_edges'] / max(1, final_stats['graph_nodes']):.2f}")
    
    return final_stats


def test_scaling():
    """ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆï¼ˆç•°ãªã‚‹ã‚µã‚¤ã‚ºã®è¿·è·¯ï¼‰"""
    
    print("\n" + "="*70)
    print("ğŸ“ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ")
    print("="*70)
    
    sizes = [(7, 7), (11, 11), (15, 15), (21, 21)]
    results = []
    
    for size in sizes:
        print(f"\nğŸ” {size[0]}Ã—{size[1]}è¿·è·¯ã§ãƒ†ã‚¹ãƒˆ...")
        
        generator = ProperMazeGenerator()
        maze = generator.generate_dfs_maze(size=size, seed=789)
        
        agent = PureMemoryAgentOptimized(
            maze=maze,
            datastore_path=f"../results/scaling_test_{size[0]}x{size[1]}",
            config={
                'max_depth': 4,
                'search_k': 20,
                'gedig_threshold': 0.6
            }
        )
        
        # 100ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
        search_times = []
        for _ in range(100):
            if agent.is_goal_reached():
                break
            
            start = time.time()
            action = agent.get_action()
            search_time = (time.time() - start) * 1000
            search_times.append(search_time)
            
            agent.execute_action(action)
        
        stats = agent.get_statistics()
        avg_search = np.mean(search_times) if search_times else 0
        
        results.append({
            'size': size,
            'episodes': stats['total_episodes'],
            'avg_search_ms': avg_search,
            'graph_edges': stats['graph_edges']
        })
        
        print(f"  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {stats['total_episodes']}")
        print(f"  å¹³å‡æ¤œç´¢æ™‚é–“: {avg_search:.3f}ms")
        print(f"  ã‚°ãƒ©ãƒ•ã‚¨ãƒƒã‚¸æ•°: {stats['graph_edges']}")
    
    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ†æ
    print("\nğŸ“Š ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ†æ:")
    print("ã‚µã‚¤ã‚º\tã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰\tæ¤œç´¢æ™‚é–“(ms)\tã‚¨ãƒƒã‚¸æ•°")
    print("-" * 50)
    for r in results:
        print(f"{r['size'][0]}Ã—{r['size'][1]}\t{r['episodes']}\t\t{r['avg_search_ms']:.3f}\t\t{r['graph_edges']}")
    
    # æ¤œç´¢æ™‚é–“ã®å¢—åŠ ç‡ã‚’è¨ˆç®—
    if len(results) > 1:
        time_increase = results[-1]['avg_search_ms'] / results[0]['avg_search_ms']
        episode_increase = results[-1]['episodes'] / results[0]['episodes']
        
        print(f"\næ¤œç´¢æ™‚é–“å¢—åŠ ç‡: {time_increase:.2f}x")
        print(f"ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°å¢—åŠ ç‡: {episode_increase:.2f}x")
        
        if time_increase < episode_increase:
            print("âœ… æ¤œç´¢æ™‚é–“ã®å¢—åŠ ãŒã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ã®å¢—åŠ ã‚ˆã‚Šç·©ã‚„ã‹ï¼ˆO(k)ã®åŠ¹æœï¼‰")
        else:
            print("âš ï¸ æ¤œç´¢æ™‚é–“ãŒã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ã«æ¯”ä¾‹ã—ã¦å¢—åŠ ")


if __name__ == "__main__":
    # æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
    stats = test_performance_comparison()
    
    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
    test_scaling()
    
    print("\n" + "="*70)
    print("ğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("  OptimizedNumpyIndexã«ã‚ˆã‚‹é«˜é€ŸåŒ–ã‚’ç¢ºèª")
    print("="*70)