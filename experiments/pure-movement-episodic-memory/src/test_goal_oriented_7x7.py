#!/usr/bin/env python3
"""
7Ã—7è¿·è·¯ã§ã‚´ãƒ¼ãƒ«æŒ‡å‘ã‚¯ã‚¨ãƒªã‚’ãƒ†ã‚¹ãƒˆ
"""

import numpy as np
import time
import sys
import os

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../src'))

from insightspike.environments.proper_maze_generator import ProperMazeGenerator
from pure_memory_agent_adaptive import PureMemoryAgentAdaptive
from pure_memory_agent_goal_oriented import PureMemoryAgentGoalOriented


def test_7x7_goal_oriented():
    """7Ã—7è¿·è·¯ã§ã‚¯ã‚¨ãƒªæˆ¦ç•¥ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print("="*60)
    print("ğŸ¯ ã‚´ãƒ¼ãƒ«æŒ‡å‘ã‚¯ã‚¨ãƒªå®Ÿé¨“ï¼ˆ7Ã—7è¿·è·¯ï¼‰")
    print("="*60)
    
    # 7Ã—7è¿·è·¯ç”Ÿæˆ
    generator = ProperMazeGenerator()
    maze = generator.generate_dfs_maze(size=(7, 7), seed=42)
    
    print("\nè¿·è·¯:")
    for row in maze:
        print(' '.join(['.' if x == 0 else 'â–ˆ' for x in row]))
    
    max_steps = 100
    
    # ã‚´ãƒ¼ãƒ«æŒ‡å‘ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    print("\n" + "-"*60)
    print("ã‚´ãƒ¼ãƒ«æŒ‡å‘ã‚¯ã‚¨ãƒªï¼ˆè¨ªå•=0ã€ã‚´ãƒ¼ãƒ«=1.0ï¼‰")
    print("-"*60)
    
    agent = PureMemoryAgentGoalOriented(
        maze=maze,
        datastore_path="../results/7x7_goal_test",
        config={
            'max_depth': 3,
            'search_k': 10,
            'gedig_improvement_threshold': 0.05
        }
    )
    
    print(f"ã‚¹ã‚¿ãƒ¼ãƒˆ: {agent.position}")
    print(f"ã‚´ãƒ¼ãƒ«: {agent.goal}")
    
    # å®Ÿè¡Œ
    path = []
    for step in range(max_steps):
        if agent.is_goal_reached():
            print(f"\nâœ… æˆåŠŸï¼ {step}ã‚¹ãƒ†ãƒƒãƒ—ã§åˆ°é”")
            break
        
        # è¡Œå‹•æ±ºå®šã®è©³ç´°ï¼ˆæœ€åˆã®20ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
        if step < 20:
            pos = agent.position
            action = agent.get_action()
            success = agent.execute_action(action)
            
            symbol = "â†’" if action == "right" else "â†" if action == "left" else "â†‘" if action == "up" else "â†“"
            result = "â—‹" if success else "Ã—"
            
            print(f"Step {step:2d}: {pos} {symbol} {result}")
            path.append((pos, action, success))
        else:
            action = agent.get_action()
            agent.execute_action(action)
        
        if step % 20 == 0 and step > 0:
            stats = agent.get_statistics()
            print(f"\né€²æ—: è·é›¢={stats['distance_to_goal']}, "
                  f"å£è¡çªç‡={stats['wall_hits']/step*100:.1f}%")
    else:
        print(f"\nâŒ {max_steps}ã‚¹ãƒ†ãƒƒãƒ—ã§æœªåˆ°é”")
    
    # çµ±è¨ˆ
    stats = agent.get_statistics()
    print("\n" + "="*60)
    print("ğŸ“Š æœ€çµ‚çµ±è¨ˆ")
    print("="*60)
    print(f"æœ€çµ‚è·é›¢: {stats['distance_to_goal']}")
    print(f"å£è¡çªç‡: {stats['wall_hits']/max(step,1)*100:.1f}%")
    print(f"ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰: {stats['total_episodes']}")
    
    # ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ä½¿ç”¨çŠ¶æ³
    qt = stats.get('query_types', {})
    if qt:
        total = sum(qt.values())
        print(f"\nã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—:")
        print(f"  ã‚´ãƒ¼ãƒ«æŒ‡å‘: {qt.get('goal_oriented', 0)} ({qt.get('goal_oriented', 0)/total*100:.1f}%)")
        print(f"  æ¢ç´¢: {qt.get('exploration', 0)} ({qt.get('exploration', 0)/total*100:.1f}%)")
    
    # æ·±åº¦ä½¿ç”¨
    print(f"\næ·±åº¦ä½¿ç”¨:")
    for depth, count in stats['depth_usage'].items():
        if count > 0:
            print(f"  {depth}ãƒ›ãƒƒãƒ—: {count}å›")
    
    return agent.is_goal_reached()


if __name__ == "__main__":
    success = test_7x7_goal_oriented()
    
    print("\n" + "="*60)
    if success:
        print("ğŸ‰ ã‚´ãƒ¼ãƒ«æŒ‡å‘ã‚¯ã‚¨ãƒªã§æˆåŠŸï¼")
        print("   è¨ªå•=0ã€ã‚´ãƒ¼ãƒ«=1.0ã®è¨­å®šãŒæœ‰åŠ¹")
    else:
        print("ğŸ“Š ã•ã‚‰ãªã‚‹èª¿æ•´ãŒå¿…è¦")
    print("="*60)