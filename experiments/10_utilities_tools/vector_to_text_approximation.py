#!/usr/bin/env python3
"""
ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®è¿‘ä¼¼é€†å¤‰æ›å®Ÿé¨“
=====================================

åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚„ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã«è¿‘ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’
è¿‘ä¼¼çš„ã«å¾©å…ƒã™ã‚‹æ‰‹æ³•ã‚’å®Ÿé¨“ã—ã¾ã™ã€‚
"""

import numpy as np
import json
from typing import List, Tuple, Optional
from pathlib import Path
import sys
import os

# InsightSpike-AIã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent / "src"))

from insightspike.utils.embedder import get_model


class VectorToTextApproximator:
    """ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®è¿‘ä¼¼å¤‰æ›å™¨"""
    
    def __init__(self):
        self.model = get_model()
        self.reference_texts = []
        self.reference_vectors = []
        
    def build_reference_database(self, texts: List[str]):
        """å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰"""
        print(f"ğŸ“š å‚ç…§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ä¸­... ({len(texts)}ä»¶)")
        self.reference_texts = texts
        self.reference_vectors = self.model.encode(texts)
        print(f"âœ… å‚ç…§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰å®Œäº†")
        
    def find_nearest_text(self, target_vector: np.ndarray, top_k: int = 5) -> List[Tuple[str, float]]:
        """æœ€è¿‘å‚ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¤œç´¢"""
        if len(self.reference_vectors) == 0:
            return []
            
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
        similarities = self.reference_vectors @ target_vector
        
        # Top-Kå–å¾—
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            results.append((self.reference_texts[idx], similarities[idx]))
            
        return results
    
    def interpolate_meanings(self, vector1: np.ndarray, vector2: np.ndarray, alpha: float = 0.5) -> np.ndarray:
        """2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«é–“ã‚’è£œé–“ã—ã¦æ–°ã—ã„æ„å‘³ã‚’ç”Ÿæˆ"""
        interpolated = alpha * vector1 + (1 - alpha) * vector2
        # æ­£è¦åŒ–
        return interpolated / np.linalg.norm(interpolated)
    
    def semantic_arithmetic(self, base_vector: np.ndarray, add_vector: np.ndarray, 
                          subtract_vector: Optional[np.ndarray] = None) -> np.ndarray:
        """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¼”ç®—ï¼ˆä¾‹: King - Man + Woman = Queençš„ãªï¼‰"""
        result = base_vector + add_vector
        if subtract_vector is not None:
            result = result - subtract_vector
        # æ­£è¦åŒ–
        return result / np.linalg.norm(result)


def run_vector_to_text_experiment():
    """ãƒ™ã‚¯ãƒˆãƒ«â†’ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›å®Ÿé¨“ã‚’å®Ÿè¡Œ"""
    
    print("ğŸ§ª ãƒ™ã‚¯ãƒˆãƒ«â†’ãƒ†ã‚­ã‚¹ãƒˆè¿‘ä¼¼å¤‰æ›å®Ÿé¨“")
    print("=" * 60)
    
    approximator = VectorToTextApproximator()
    
    # 1. InsightSpike-AIã®å®Ÿéš›ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å‚ç…§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä½¿ç”¨
    print("\nğŸ“– 1. å‚ç…§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æº–å‚™")
    
    # CSVã‹ã‚‰å®Ÿéš›ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
    try:
        import pandas as pd
        episodes_df = pd.read_csv("outputs/csv_summaries/input_episodes.csv")
        reference_texts = episodes_df['episode_text'].tolist()[:100]  # æœ€åˆã®100ä»¶ã‚’ä½¿ç”¨
        print(f"âœ… InsightSpike-AIã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {len(reference_texts)}ä»¶ã‚’å‚ç…§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ")
    except Exception as e:
        print(f"âŒ CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆé›†åˆ
        reference_texts = [
            "AI can revolutionize healthcare diagnostics",
            "Machine learning models require high-quality data",
            "Deep learning excels at pattern recognition",
            "Natural language processing enables human-computer interaction",
            "Computer vision systems analyze medical images",
            "åŸºç¤æ¦‚å¿µã®å­¦ç¿’ãŒé‡è¦ã§ã™",
            "æ¦‚å¿µé–“ã®é–¢ä¿‚æ€§ã‚’ç†è§£ã™ã‚‹",
            "çŸ¥è­˜ã®ä½“ç³»åŒ–ã¨çµ±åˆ",
            "å°‚é–€çŸ¥è­˜ã®ç²å¾—ãƒ—ãƒ­ã‚»ã‚¹",
            "ç¶™ç¶šçš„å­¦ç¿’ã«ã‚ˆã‚‹æ”¹å–„"
        ]
    
    approximator.build_reference_database(reference_texts)
    
    # 2. ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã€é€†å¤‰æ›ã‚’è©¦ã™
    print("\nğŸ¯ 2. é€†å¤‰æ›ãƒ†ã‚¹ãƒˆ")
    
    test_cases = [
        "AI can revolutionize healthcare diagnostics",
        "åŸºç¤æ¦‚å¿µã®å­¦ç¿’ãŒé‡è¦ã§ã™",
        "Machine learning models require data"
    ]
    
    for i, original_text in enumerate(test_cases, 1):
        print(f"\n--- ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i} ---")
        print(f"ğŸ”¤ å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: \"{original_text}\"")
        
        # ãƒ†ã‚­ã‚¹ãƒˆ â†’ ãƒ™ã‚¯ãƒˆãƒ«
        vector = approximator.model.encode([original_text])[0]
        print(f"ğŸ”¢ ãƒ™ã‚¯ãƒˆãƒ«åŒ–: {vector.shape} æ¬¡å…ƒ")
        
        # ãƒ™ã‚¯ãƒˆãƒ« â†’ è¿‘ä¼¼ãƒ†ã‚­ã‚¹ãƒˆ
        nearest_texts = approximator.find_nearest_text(vector, top_k=3)
        
        print(f"ğŸ” è¿‘ä¼¼å¾©å…ƒçµæœ:")
        for j, (text, similarity) in enumerate(nearest_texts, 1):
            print(f"  {j}. (é¡ä¼¼åº¦: {similarity:.4f}) \"{text}\"")
    
    # 3. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¼”ç®—å®Ÿé¨“
    print(f"\nğŸ§® 3. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¼”ç®—å®Ÿé¨“")
    
    # ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ã®ä¾‹
    healthcare_vec = approximator.model.encode(["healthcare diagnostics"])[0]
    ai_vec = approximator.model.encode(["artificial intelligence"])[0]
    learning_vec = approximator.model.encode(["machine learning"])[0]
    
    # AI + Healthcare ã®æ„å‘³
    ai_healthcare = approximator.semantic_arithmetic(ai_vec, healthcare_vec)
    print(f"\nğŸ”¬ AI + Healthcare ã®æ„å‘³:")
    nearest = approximator.find_nearest_text(ai_healthcare, top_k=3)
    for j, (text, sim) in enumerate(nearest, 1):
        print(f"  {j}. (é¡ä¼¼åº¦: {sim:.4f}) \"{text}\"")
    
    # 4. è£œé–“å®Ÿé¨“
    print(f"\nğŸ”€ 4. æ„å‘³è£œé–“å®Ÿé¨“")
    
    ai_vec = approximator.model.encode(["artificial intelligence"])[0]
    health_vec = approximator.model.encode(["healthcare"])[0]
    
    for alpha in [0.2, 0.5, 0.8]:
        interpolated = approximator.interpolate_meanings(ai_vec, health_vec, alpha)
        print(f"\nAI({alpha:.1f}) + Healthcare({1-alpha:.1f}):")
        nearest = approximator.find_nearest_text(interpolated, top_k=2)
        for j, (text, sim) in enumerate(nearest, 1):
            print(f"  {j}. (é¡ä¼¼åº¦: {sim:.4f}) \"{text}\"")
    
    # 5. çµè«–
    print(f"\nğŸ“Š 5. å®Ÿé¨“çµè«–")
    print("=" * 40)
    print("âœ… å¯èƒ½ãªè¿‘ä¼¼å¤‰æ›:")
    print("  â€¢ æœ€è¿‘å‚æ¤œç´¢ã«ã‚ˆã‚‹æ„å‘³çš„ã«è¿‘ã„ãƒ†ã‚­ã‚¹ãƒˆã®ç™ºè¦‹")
    print("  â€¢ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¼”ç®—ã«ã‚ˆã‚‹æ–°ã—ã„æ¦‚å¿µã®ç”Ÿæˆ")
    print("  â€¢ ãƒ™ã‚¯ãƒˆãƒ«è£œé–“ã«ã‚ˆã‚‹æ„å‘³ã®æ®µéšçš„å¤‰åŒ–")
    print()
    print("âŒ ä¸å¯èƒ½ãªå®Œå…¨é€†å¤‰æ›:")
    print("  â€¢ å…ƒã®æ­£ç¢ºãªãƒ†ã‚­ã‚¹ãƒˆã®å¾©å…ƒ")
    print("  â€¢ èªå½™ã‚„æ–‡æ³•ã®å®Œå…¨ãªå¾©å…ƒ")
    print("  â€¢ å›ºæœ‰åè©ã‚„æ•°å€¤ã®æ­£ç¢ºãªå¾©å…ƒ")
    print()
    print("ğŸ’¡ InsightSpike-AIã§ã®å¿œç”¨:")
    print("  â€¢ æ´å¯Ÿã®æ¦‚å¿µçš„èª¬æ˜ç”Ÿæˆ")
    print("  â€¢ é¡ä¼¼æ¦‚å¿µã®ç™ºè¦‹ã¨æç¤º")
    print("  â€¢ æ¦‚å¿µé–“ã®é–¢ä¿‚æ€§ã®è¦–è¦šåŒ–")


if __name__ == "__main__":
    run_vector_to_text_experiment()
