{
  "experiment_metadata": {
    "timestamp": "2025-07-24T11:35:37.661741",
    "seed": 42,
    "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "config": {
      "environment": "experiment",
      "pre_warm_models": true,
      "llm": {
        "provider": "local",
        "model": "distilgpt2",
        "max_tokens": 512,
        "temperature": 0.7,
        "top_p": 0.9,
        "timeout": 30,
        "api_base": null,
        "device": "cpu",
        "load_in_8bit": false,
        "system_prompt": null
      },
      "embedding": {
        "model_name": "sentence-transformers/all-MiniLM-L6-v2",
        "dimension": 384,
        "device": "cpu"
      },
      "memory": {
        "max_retrieved_docs": 15,
        "short_term_capacity": 10,
        "working_memory_capacity": 20,
        "episodic_memory_capacity": 100,
        "pattern_cache_capacity": 15
      },
      "graph": {
        "spike_ged_threshold": -0.4,
        "spike_ig_threshold": 0.25,
        "similarity_threshold": 0.35,
        "use_gnn": false,
        "gnn_hidden_dim": 64,
        "ged_algorithm": "hybrid",
        "ig_algorithm": "hybrid",
        "hybrid_weights": {
          "structure": 0.4,
          "semantic": 0.4,
          "quality": 0.2
        },
        "weight_ged": 0.5,
        "weight_ig": 0.5,
        "temperature": 1.0
      },
      "monitoring": {
        "enabled": true,
        "performance_tracking": false,
        "detailed_tracing": false,
        "metrics_port": 9090
      },
      "logging": {
        "level": "INFO",
        "file_path": "/Users/miyauchikazuyoshi/.insightspike/logs",
        "log_to_console": false,
        "max_size_mb": 50,
        "backup_count": 3
      },
      "paths": {
        "data_dir": "data",
        "raw_dir": "data/raw",
        "processed_dir": "data/processed",
        "embeddings_dir": "data/embeddings",
        "cache_dir": "data/cache",
        "models_dir": "data/models",
        "logs_dir": "/Users/miyauchikazuyoshi/.insightspike/logs"
      },
      "processing": {
        "batch_size": 32,
        "max_workers": 4,
        "chunk_size": 500,
        "overlap": 50,
        "min_chunk_size": 100
      },
      "output": {
        "format": "json",
        "include_reasoning": true,
        "include_sources": true,
        "max_sources": 5,
        "max_context_length": 2000,
        "max_documents": 10,
        "include_metadata": true
      }
    }
  },
  "questions": [],
  "raw_results": [
    {
      "question_id": "medium_001",
      "question_text": "If it rains and the ground is dry, then what?",
      "difficulty": "medium",
      "category": "logical",
      "response": "Error in cycle 1: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).",
      "has_spike_detected": false,
      "metrics": {
        "delta_ged": 1.0,
        "delta_ig": 0.0
      },
      "processing_time": 0.06353211402893066,
      "graph_stats": {
        "nodes_before": 0,
        "edges_before": 0,
        "nodes_after": 1,
        "edges_after": 1
      }
    },
    {
      "question_id": "medium_005",
      "question_text": "If it rains and the ground is dry, then what?",
      "difficulty": "medium",
      "category": "logical",
      "response": "Error in cycle 3: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).",
      "has_spike_detected": false,
      "metrics": {
        "delta_ged": 0.0,
        "delta_ig": 0.0
      },
      "processing_time": 0.03762102127075195,
      "graph_stats": {
        "nodes_before": 1,
        "edges_before": 1,
        "nodes_after": 1,
        "edges_after": 1
      }
    },
    {
      "question_id": "easy_001",
      "question_text": "What is 1 \u00d7 5?",
      "difficulty": "easy",
      "category": "mathematical",
      "response": "Error in cycle 5: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).",
      "has_spike_detected": false,
      "metrics": {
        "delta_ged": 0.0,
        "delta_ig": 0.0
      },
      "processing_time": 0.05405426025390625,
      "graph_stats": {
        "nodes_before": 1,
        "edges_before": 1,
        "nodes_after": 1,
        "edges_after": 1
      }
    }
  ],
  "summary": {}
}