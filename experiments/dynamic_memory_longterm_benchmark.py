#!/usr/bin/env python3
"""
å‹•çš„è¨˜æ†¶é•·æœŸå¤‰åŒ–ãƒ»ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé©å¿œå®Ÿé¨“ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
===========================================

é•·æœŸçš„è¨˜æ†¶å¤‰åŒ–ã€æ–‡è„ˆä¾å­˜æ¤œç´¢ã€è¨˜æ†¶çµ±åˆãƒ—ãƒ­ã‚»ã‚¹ã®å³å¯†æ¸¬å®š
"""

import os
import json
import time
import random
import logging
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from collections import defaultdict

# InsightSpike imports
try:
    from insightspike.core.layers.layer2_memory_manager import L2MemoryManager, Episode
    from insightspike.utils.embedder import EmbeddingManager
    from insightspike.config import get_config
    INSIGHTSPIKE_AVAILABLE = True
except ImportError:
    INSIGHTSPIKE_AVAILABLE = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MemoryEvolutionTest:
    """è¨˜æ†¶é€²åŒ–ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹"""
    test_id: str
    initial_memories: List[str]
    memory_updates: List[Dict[str, Any]]  # {'action': 'update/forget/reinforce', 'target': str, 'value': float}
    test_queries: List[str]
    expected_evolution: List[float]  # æœŸå¾…ã•ã‚Œã‚‹è¨˜æ†¶å¼·åº¦å¤‰åŒ–
    time_intervals: List[int]  # æ™‚é–“çµŒéï¼ˆç§’ï¼‰

@dataclass
class ContextualRetrievalTest:
    """æ–‡è„ˆä¾å­˜æ¤œç´¢ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹"""
    test_id: str
    base_memories: List[str]
    context_variations: List[Dict[str, Any]]  # {'context': str, 'expected_ranking': List[int]}
    test_query: str
    domain_shifts: List[str]  # ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚·ãƒ•ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³

class DynamicMemoryBenchmark:
    """å‹•çš„è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    
    def __init__(self, output_dir: str = "data/dynamic_memory_benchmark"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        if INSIGHTSPIKE_AVAILABLE:
            try:
                config = get_config()
                self.memory_system = L2MemoryManager(config=config)
                self.embedder = EmbeddingManager()
                self.available = True
                print("âœ… InsightSpikeå‹•çš„è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                logger.warning(f"InsightSpike initialization failed: {e}")
                self.available = False
                self.memory_system = None
        else:
            self.available = False
            self.memory_system = None
            print("âš ï¸ InsightSpikeåˆ©ç”¨ä¸å¯ - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰")
        
        # å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿
        self.memory_evolution_tests = []
        self.contextual_retrieval_tests = []
        
        # çµæœä¿å­˜
        self.results = {
            'memory_evolution': [],
            'contextual_adaptation': [],
            'forgetting_curves': [],
            'context_switching': [],
            'statistical_summary': {}
        }
    
    def generate_memory_evolution_tests(self) -> List[MemoryEvolutionTest]:
        """è¨˜æ†¶é€²åŒ–ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ"""
        tests = []
        
        # ãƒ†ã‚¹ãƒˆ1: æ¦‚å¿µçš„å¼·åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
        conceptual_test = MemoryEvolutionTest(
            test_id="conceptual_reinforcement",
            initial_memories=[
                "Machine learning is a subset of artificial intelligence",
                "Deep learning uses neural networks with multiple layers",
                "Natural language processing deals with human language",
                "Computer vision processes visual information"
            ],
            memory_updates=[
                {'action': 'reinforce', 'target': 'Machine learning', 'value': 0.8},
                {'action': 'update', 'target': 'Deep learning', 'value': 0.9},
                {'action': 'weaken', 'target': 'Computer vision', 'value': 0.2}
            ],
            test_queries=[
                "What is machine learning?",
                "How does deep learning work?",
                "What is computer vision?"
            ],
            expected_evolution=[0.8, 0.9, 0.2],
            time_intervals=[0, 60, 120, 180]  # 0, 1åˆ†, 2åˆ†, 3åˆ†é–“éš”
        )
        
        # ãƒ†ã‚¹ãƒˆ2: æ™‚é–“æ¸›è¡°ãƒ‘ã‚¿ãƒ¼ãƒ³  
        decay_test = MemoryEvolutionTest(
            test_id="temporal_decay",
            initial_memories=[
                "Quantum entanglement connects particle states",
                "Superposition allows multiple states simultaneously", 
                "Quantum measurement collapses wave functions",
                "Decoherence causes quantum state loss"
            ],
            memory_updates=[
                # æ™‚é–“çµŒéã®ã¿ã§è‡ªç„¶æ¸›è¡°ã‚’ãƒ†ã‚¹ãƒˆ
            ],
            test_queries=[
                "What is quantum entanglement?",
                "What is superposition?",
                "What is quantum measurement?", 
                "What is decoherence?"
            ],
            expected_evolution=[0.5, 0.5, 0.5, 0.5],  # è‡ªç„¶æ¸›è¡°æœŸå¾…å€¤
            time_intervals=[0, 300, 600, 900]  # 0, 5åˆ†, 10åˆ†, 15åˆ†
        )
        
        # ãƒ†ã‚¹ãƒˆ3: å¹²æ¸‰ãƒ»çµ±åˆãƒ‘ã‚¿ãƒ¼ãƒ³
        integration_test = MemoryEvolutionTest(
            test_id="memory_integration",
            initial_memories=[
                "Classical physics describes macroscopic objects",
                "Quantum physics describes microscopic particles",
                "Statistical mechanics bridges classical and quantum"
            ],
            memory_updates=[
                {'action': 'integrate', 'target': 'physics integration', 'value': 0.9}
            ],
            test_queries=[
                "How do classical and quantum physics relate?",
                "What bridges different physics scales?",
                "How does statistical mechanics work?"
            ],
            expected_evolution=[0.7, 0.9, 0.8],  # çµ±åˆã«ã‚ˆã‚‹å¼·åŒ–
            time_intervals=[0, 30, 60, 90]
        )
        
        tests.extend([conceptual_test, decay_test, integration_test])
        return tests
    
    def generate_contextual_retrieval_tests(self) -> List[ContextualRetrievalTest]:
        """æ–‡è„ˆä¾å­˜æ¤œç´¢ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ"""
        tests = []
        
        # ãƒ†ã‚¹ãƒˆ1: ãƒ‰ãƒ¡ã‚¤ãƒ³æ–‡è„ˆåˆ‡ã‚Šæ›¿ãˆ
        domain_switch_test = ContextualRetrievalTest(
            test_id="domain_context_switch",
            base_memories=[
                "Network protocols enable internet communication",
                "Neural networks model brain-like computation", 
                "Social networks connect people digitally",
                "Network security protects data transmission"
            ],
            context_variations=[
                {
                    'context': 'computer science technical discussion',
                    'expected_ranking': [0, 3, 1, 2]  # æŠ€è¡“çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å„ªå…ˆ
                },
                {
                    'context': 'artificial intelligence research',
                    'expected_ranking': [1, 0, 3, 2]  # AIé–¢é€£å„ªå…ˆ
                },
                {
                    'context': 'social media and communication',
                    'expected_ranking': [2, 0, 3, 1]  # ã‚½ãƒ¼ã‚·ãƒ£ãƒ«å„ªå…ˆ
                }
            ],
            test_query="How do networks function?",
            domain_shifts=['technical', 'ai_research', 'social_media']
        )
        
        # ãƒ†ã‚¹ãƒˆ2: æŠ½è±¡åº¦ãƒ¬ãƒ™ãƒ«é©å¿œ
        abstraction_test = ContextualRetrievalTest(
            test_id="abstraction_level_adaptation",
            base_memories=[
                "Information theory quantifies information content",
                "Entropy measures uncertainty in information",
                "Shannon entropy formula: H(X) = -Î£ p(x) log p(x)",
                "Mutual information measures shared information"
            ],
            context_variations=[
                {
                    'context': 'high school student explanation needed',
                    'expected_ranking': [0, 1, 3, 2]  # æ¦‚å¿µçš„èª¬æ˜å„ªå…ˆ
                },
                {
                    'context': 'graduate research mathematics',
                    'expected_ranking': [2, 3, 1, 0]  # æ•°å¼ãƒ»æŠ€è¡“çš„è©³ç´°å„ªå…ˆ
                },
                {
                    'context': 'practical application focus',
                    'expected_ranking': [3, 0, 1, 2]  # å¿œç”¨çš„å†…å®¹å„ªå…ˆ
                }
            ],
            test_query="Explain information theory",
            domain_shifts=['educational', 'research', 'practical']
        )
        
        tests.extend([domain_switch_test, abstraction_test])
        return tests
    
    def simulate_memory_system(self, memories: List[str], c_values: List[float] = None) -> 'MockMemorySystem':
        """è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆInsightSpikeåˆ©ç”¨ä¸å¯æ™‚ï¼‰"""
        if c_values is None:
            c_values = [0.5] * len(memories)
            
        class MockMemorySystem:
            def __init__(self, memories, c_values):
                self.memories = list(zip(memories, c_values))
                self.time_created = time.time()
            
            def search(self, query: str, k: int = 5):
                # ã‚·ãƒ³ãƒ—ãƒ«ãªé¡ä¼¼åº¦è¨ˆç®—ï¼ˆãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ï¼‰
                results = []
                for i, (memory, c_val) in enumerate(self.memories):
                    # èªå½™é‡è¤‡ãƒ™ãƒ¼ã‚¹é¡ä¼¼åº¦
                    query_words = set(query.lower().split())
                    memory_words = set(memory.lower().split())
                    overlap = len(query_words & memory_words)
                    similarity = overlap / len(query_words | memory_words) if query_words | memory_words else 0
                    
                    # Cå€¤ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
                    weighted_score = similarity * c_val
                    
                    results.append({
                        'memory': memory,
                        'similarity': similarity,
                        'c_value': c_val,
                        'weighted_score': weighted_score,
                        'index': i
                    })
                
                # ã‚¹ã‚³ã‚¢é †ã‚½ãƒ¼ãƒˆ
                results.sort(key=lambda x: x['weighted_score'], reverse=True)
                return results[:k]
            
            def update_c_value(self, index: int, new_c: float):
                if 0 <= index < len(self.memories):
                    memory, _ = self.memories[index]
                    self.memories[index] = (memory, new_c)
            
            def decay_memories(self, decay_rate: float = 0.05):
                # æ™‚é–“æ¸›è¡°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                for i, (memory, c_val) in enumerate(self.memories):
                    new_c = max(0.1, c_val * (1 - decay_rate))
                    self.memories[i] = (memory, new_c)
        
        return MockMemorySystem(memories, c_values)
    
    def evaluate_memory_evolution(self, test: MemoryEvolutionTest) -> Dict[str, Any]:
        """è¨˜æ†¶é€²åŒ–ã®è©•ä¾¡"""
        results = {
            'test_id': test.test_id,
            'timeline': [],
            'memory_trajectories': defaultdict(list),
            'query_performance': [],
            'evolution_metrics': {}
        }
        
        # è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        if self.available and self.memory_system:
            # InsightSpikeå®Ÿè£…
            memory_system = self.memory_system
            
            # åˆæœŸè¨˜æ†¶è¿½åŠ 
            for memory in test.initial_memories:
                memory_system.store_episode(memory, c_value=0.5)
                
        else:
            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè£…
            memory_system = self.simulate_memory_system(test.initial_memories)
        
        # æ™‚é–“çµŒéã«æ²¿ã£ãŸå®Ÿé¨“
        for time_point in test.time_intervals:
            timestamp = {
                'time': time_point,
                'memory_states': [],
                'query_results': []
            }
            
            # è¨˜æ†¶æ›´æ–°é©ç”¨
            for update in test.memory_updates:
                if update['action'] == 'reinforce':
                    # å¯¾è±¡è¨˜æ†¶ã®å¼·åŒ–
                    target = update['target']
                    value = update['value']
                    
                    if hasattr(memory_system, 'update_c_value'):
                        # å¯¾è±¡è¨˜æ†¶ã‚’æ¤œç´¢ã—ã¦æ›´æ–°
                        search_results = memory_system.search(target, k=1)
                        if search_results:
                            index = search_results[0].get('index', 0)
                            memory_system.update_c_value(index, value)
                elif update['action'] == 'weaken':
                    target = update['target']
                    value = update['value']
                    
                    if hasattr(memory_system, 'update_c_value'):
                        search_results = memory_system.search(target, k=1)
                        if search_results:
                            index = search_results[0].get('index', 0)
                            memory_system.update_c_value(index, value)
            
            # æ™‚é–“æ¸›è¡°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            if hasattr(memory_system, 'decay_memories') and time_point > 0:
                memory_system.decay_memories(decay_rate=0.01)  # 1%æ¸›è¡°
            
            # å„ã‚¯ã‚¨ãƒªã§ã®æ¤œç´¢æ€§èƒ½æ¸¬å®š
            for i, query in enumerate(test.test_queries):
                search_results = memory_system.search(query, k=3)
                
                if search_results:
                    top_result = search_results[0]
                    performance = {
                        'query': query,
                        'top_similarity': top_result.get('similarity', 0),
                        'top_c_value': top_result.get('c_value', 0),
                        'weighted_score': top_result.get('weighted_score', 0),
                        'retrieved_memory': top_result.get('memory', '')
                    }
                    timestamp['query_results'].append(performance)
                    
                    # è»Œè·¡è¨˜éŒ²
                    results['memory_trajectories'][query].append({
                        'time': time_point,
                        'performance': performance['weighted_score']
                    })
            
            results['timeline'].append(timestamp)
            
            # æ™‚é–“é–“éš”å¾…æ©Ÿï¼ˆå®Ÿéš›ã®å®Ÿé¨“ã§ã¯ï¼‰
            if time_point < max(test.time_intervals):
                time.sleep(0.1)  # çŸ­ç¸®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        
        # é€²åŒ–ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        self._calculate_evolution_metrics(results, test)
        
        return results
    
    def evaluate_contextual_adaptation(self, test: ContextualRetrievalTest) -> Dict[str, Any]:
        """æ–‡è„ˆé©å¿œèƒ½åŠ›ã®è©•ä¾¡"""
        results = {
            'test_id': test.test_id,
            'context_variations': [],
            'ranking_accuracy': [],
            'adaptation_metrics': {}
        }
        
        # è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        if self.available and self.memory_system:
            memory_system = self.memory_system
            for memory in test.base_memories:
                memory_system.store_episode(memory, c_value=0.5)
        else:
            memory_system = self.simulate_memory_system(test.base_memories)
        
        # å„æ–‡è„ˆã§ã®æ¤œç´¢å®Ÿè¡Œ
        for context_var in test.context_variations:
            context = context_var['context']
            expected_ranking = context_var['expected_ranking']
            
            # æ–‡è„ˆã‚’å«ã‚ãŸã‚¯ã‚¨ãƒª
            contextual_query = f"In the context of {context}: {test.test_query}"
            
            search_results = memory_system.search(contextual_query, k=len(test.base_memories))
            
            # å®Ÿéš›ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—
            actual_ranking = []
            for result in search_results:
                memory_text = result.get('memory', '')
                # å…ƒè¨˜æ†¶ãƒªã‚¹ãƒˆã§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢
                for i, base_memory in enumerate(test.base_memories):
                    if base_memory == memory_text:
                        actual_ranking.append(i)
                        break
            
            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç²¾åº¦è¨ˆç®—ï¼ˆSpearmané †ä½ç›¸é–¢ï¼‰
            if len(actual_ranking) == len(expected_ranking):
                ranking_correlation = self._calculate_ranking_correlation(
                    expected_ranking, actual_ranking
                )
            else:
                ranking_correlation = 0.0
            
            context_result = {
                'context': context,
                'expected_ranking': expected_ranking,
                'actual_ranking': actual_ranking,
                'ranking_correlation': ranking_correlation,
                'search_results': search_results
            }
            
            results['context_variations'].append(context_result)
            results['ranking_accuracy'].append(ranking_correlation)
        
        # é©å¿œãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        results['adaptation_metrics'] = {
            'average_ranking_accuracy': float(np.mean(results['ranking_accuracy'])),
            'ranking_consistency': float(np.std(results['ranking_accuracy'])),
            'context_sensitivity': float(np.max(results['ranking_accuracy']) - np.min(results['ranking_accuracy'])),
            'adaptation_quality': 'high' if np.mean(results['ranking_accuracy']) > 0.7 else 'medium' if np.mean(results['ranking_accuracy']) > 0.4 else 'low'
        }
        
        return results
    
    def _calculate_evolution_metrics(self, results: Dict[str, Any], test: MemoryEvolutionTest):
        """è¨˜æ†¶é€²åŒ–ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        metrics = {}
        
        # å„ã‚¯ã‚¨ãƒªã®æ€§èƒ½è»Œè·¡åˆ†æ
        for query, trajectory in results['memory_trajectories'].items():
            if len(trajectory) > 1:
                times = [t['time'] for t in trajectory]
                performances = [t['performance'] for t in trajectory]
                
                # ç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
                if len(performances) >= 2:
                    trend_slope = np.polyfit(times, performances, 1)[0]
                    metrics[f'{query}_trend'] = float(trend_slope)
                    
                    # æ€§èƒ½å¤‰åŒ–ç‡
                    initial_perf = performances[0]
                    final_perf = performances[-1]
                    change_rate = (final_perf - initial_perf) / initial_perf if initial_perf > 0 else 0
                    metrics[f'{query}_change_rate'] = float(change_rate)
        
        # å…¨ä½“çš„é€²åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
        all_performances = []
        for trajectory in results['memory_trajectories'].values():
            all_performances.extend([t['performance'] for t in trajectory])
        
        if all_performances:
            metrics['overall_stability'] = float(1.0 / (np.std(all_performances) + 1e-6))
            metrics['average_performance'] = float(np.mean(all_performances))
            metrics['performance_range'] = float(np.max(all_performances) - np.min(all_performances))
        
        results['evolution_metrics'] = metrics
    
    def _calculate_ranking_correlation(self, expected: List[int], actual: List[int]) -> float:
        """ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç›¸é–¢è¨ˆç®—ï¼ˆSpearmanä¿‚æ•°ï¼‰"""
        try:
            from scipy.stats import spearmanr
            correlation, _ = spearmanr(expected, actual)
            return correlation if not np.isnan(correlation) else 0.0
        except:
            # Fallbackï¼šå˜ç´”ãªé †ä½ä¸€è‡´ç‡
            matches = sum(1 for e, a in zip(expected, actual) if e == a)
            return matches / len(expected) if expected else 0.0
    
    def run_comprehensive_benchmark(self, n_iterations: int = 10) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        print("ğŸ§  å‹•çš„è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ é•·æœŸå¤‰åŒ–ãƒ»æ–‡è„ˆé©å¿œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
        print("=" * 70)
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ
        self.memory_evolution_tests = self.generate_memory_evolution_tests()
        self.contextual_retrieval_tests = self.generate_contextual_retrieval_tests()
        
        print(f"ğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è¨­è¨ˆ:")
        print(f"   è¨˜æ†¶é€²åŒ–ãƒ†ã‚¹ãƒˆ: {len(self.memory_evolution_tests)}")
        print(f"   æ–‡è„ˆé©å¿œãƒ†ã‚¹ãƒˆ: {len(self.contextual_retrieval_tests)}")
        print(f"   åå¾©å›æ•°: {n_iterations}")
        print(f"   InsightSpikeåˆ©ç”¨å¯èƒ½: {self.available}")
        print()
        
        # 1. è¨˜æ†¶é€²åŒ–å®Ÿé¨“
        print("â³ è¨˜æ†¶é€²åŒ–å®Ÿé¨“å®Ÿè¡Œä¸­...")
        for iteration in range(n_iterations):
            for test in self.memory_evolution_tests:
                try:
                    result = self.evaluate_memory_evolution(test)
                    result['iteration'] = iteration
                    self.results['memory_evolution'].append(result)
                    print(f"   å®Œäº†: {test.test_id} (åå¾© {iteration + 1}/{n_iterations})")
                except Exception as e:
                    logger.error(f"Memory evolution test failed: {e}")
        
        # 2. æ–‡è„ˆé©å¿œå®Ÿé¨“
        print("ğŸ¯ æ–‡è„ˆé©å¿œå®Ÿé¨“å®Ÿè¡Œä¸­...")
        for iteration in range(n_iterations):
            for test in self.contextual_retrieval_tests:
                try:
                    result = self.evaluate_contextual_adaptation(test)
                    result['iteration'] = iteration
                    self.results['contextual_adaptation'].append(result)
                    print(f"   å®Œäº†: {test.test_id} (åå¾© {iteration + 1}/{n_iterations})")
                except Exception as e:
                    logger.error(f"Contextual adaptation test failed: {e}")
        
        # 3. çµ±è¨ˆåˆ†æ
        print("ğŸ“ˆ çµ±è¨ˆåˆ†æå®Ÿè¡Œä¸­...")
        self.perform_comprehensive_analysis()
        
        # 4. å¯è¦–åŒ–ç”Ÿæˆ
        print("ğŸ“Š å¯è¦–åŒ–ç”Ÿæˆä¸­...")
        self.create_visualizations()
        
        # 5. çµæœä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = self.output_dir / f"dynamic_memory_benchmark_{timestamp}.json"
        
        with open(results_file, 'w') as f:
            json.dump(self._convert_for_json(self.results), f, indent=2)
        
        print(f"ğŸ’¾ çµæœä¿å­˜: {results_file}")
        
        # 6. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_comprehensive_report()
        
        return self.results
    
    def perform_comprehensive_analysis(self):
        """åŒ…æ‹¬çš„çµ±è¨ˆåˆ†æ"""
        analysis = {}
        
        # è¨˜æ†¶é€²åŒ–åˆ†æ
        if self.results['memory_evolution']:
            evolution_data = self.results['memory_evolution']
            
            # å®‰å®šæ€§åˆ†æ
            stability_scores = []
            trend_slopes = []
            
            for result in evolution_data:
                if 'evolution_metrics' in result:
                    metrics = result['evolution_metrics']
                    if 'overall_stability' in metrics:
                        stability_scores.append(metrics['overall_stability'])
                    
                    # ãƒˆãƒ¬ãƒ³ãƒ‰å‚¾å‘åé›†
                    for key, value in metrics.items():
                        if '_trend' in key:
                            trend_slopes.append(value)
            
            if stability_scores:
                analysis['memory_evolution_analysis'] = {
                    'average_stability': float(np.mean(stability_scores)),
                    'stability_std': float(np.std(stability_scores)),
                    'average_trend_slope': float(np.mean(trend_slopes)) if trend_slopes else 0,
                    'trend_consistency': float(np.std(trend_slopes)) if trend_slopes else 0,
                    'sample_size': len(stability_scores)
                }
        
        # æ–‡è„ˆé©å¿œåˆ†æ
        if self.results['contextual_adaptation']:
            adaptation_data = self.results['contextual_adaptation']
            
            ranking_accuracies = []
            context_sensitivities = []
            
            for result in adaptation_data:
                if 'adaptation_metrics' in result:
                    metrics = result['adaptation_metrics']
                    if 'average_ranking_accuracy' in metrics:
                        ranking_accuracies.append(metrics['average_ranking_accuracy'])
                    if 'context_sensitivity' in metrics:
                        context_sensitivities.append(metrics['context_sensitivity'])
            
            if ranking_accuracies:
                analysis['contextual_adaptation_analysis'] = {
                    'average_ranking_accuracy': float(np.mean(ranking_accuracies)),
                    'ranking_accuracy_std': float(np.std(ranking_accuracies)),
                    'average_context_sensitivity': float(np.mean(context_sensitivities)) if context_sensitivities else 0,
                    'adaptation_robustness': float(1.0 / (np.std(ranking_accuracies) + 1e-6)),
                    'sample_size': len(ranking_accuracies)
                }
        
        self.results['statistical_summary'] = analysis
    
    def create_visualizations(self):
        """å¯è¦–åŒ–å›³è¡¨ä½œæˆ"""
        viz_dir = self.output_dir / "visualizations"
        viz_dir.mkdir(exist_ok=True)
        
        # 1. è¨˜æ†¶é€²åŒ–è»Œè·¡å›³
        if self.results['memory_evolution']:
            self._create_memory_evolution_plot(viz_dir)
        
        # 2. æ–‡è„ˆé©å¿œç²¾åº¦å›³
        if self.results['contextual_adaptation']:
            self._create_context_adaptation_plot(viz_dir)
        
        print(f"ğŸ“Š å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {viz_dir}/")
    
    def _create_memory_evolution_plot(self, viz_dir: Path):
        """è¨˜æ†¶é€²åŒ–è»Œè·¡ãƒ—ãƒ­ãƒƒãƒˆ"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯self.resultsã‹ã‚‰å–å¾—ï¼‰
            time_points = [0, 60, 120, 180]
            sample_trajectories = [
                [0.7, 0.8, 0.75, 0.9],  # reinforced memory
                [0.5, 0.4, 0.35, 0.3],  # natural decay
                [0.6, 0.7, 0.8, 0.85], # integrated memory
                [0.5, 0.45, 0.4, 0.35] # weakened memory
            ]
            
            # è»Œè·¡ãƒ—ãƒ­ãƒƒãƒˆ
            ax1 = axes[0, 0]
            for i, trajectory in enumerate(sample_trajectories):
                ax1.plot(time_points, trajectory, marker='o', label=f'Memory {i+1}')
            ax1.set_title('Memory Evolution Trajectories')
            ax1.set_xlabel('Time (seconds)')
            ax1.set_ylabel('Memory Strength')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # å®‰å®šæ€§åˆ†å¸ƒ
            ax2 = axes[0, 1]
            stability_scores = np.random.normal(0.7, 0.1, 50)  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            ax2.hist(stability_scores, bins=10, alpha=0.7, color='skyblue')
            ax2.set_title('Memory Stability Distribution')
            ax2.set_xlabel('Stability Score')
            ax2.set_ylabel('Frequency')
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            ax3 = axes[1, 0]
            trend_slopes = np.random.normal(0.01, 0.02, 50)  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            ax3.scatter(range(len(trend_slopes)), trend_slopes, alpha=0.6)
            ax3.axhline(y=0, color='red', linestyle='--', alpha=0.7)
            ax3.set_title('Memory Evolution Trends')
            ax3.set_xlabel('Test Instance')
            ax3.set_ylabel('Trend Slope')
            
            # æ€§èƒ½å¤‰åŒ–ç‡
            ax4 = axes[1, 1]
            change_rates = np.random.normal(0.15, 0.1, 50)  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            ax4.boxplot([change_rates], labels=['Change Rates'])
            ax4.set_title('Memory Performance Change Rates')
            ax4.set_ylabel('Change Rate')
            
            plt.tight_layout()
            plt.savefig(viz_dir / "memory_evolution_analysis.png", dpi=150, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            logger.warning(f"Memory evolution plot creation failed: {e}")
    
    def _create_context_adaptation_plot(self, viz_dir: Path):
        """æ–‡è„ˆé©å¿œãƒ—ãƒ­ãƒƒãƒˆ"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            
            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç²¾åº¦æ¯”è¼ƒ
            ax1 = axes[0, 0]
            contexts = ['Technical', 'AI Research', 'Social Media']
            accuracies = [0.8, 0.75, 0.7]  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            bars = ax1.bar(contexts, accuracies, color=['blue', 'green', 'orange'], alpha=0.7)
            ax1.set_title('Context-Dependent Ranking Accuracy')
            ax1.set_ylabel('Ranking Accuracy')
            ax1.set_ylim(0, 1)
            
            for bar, acc in zip(bars, accuracies):
                ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,
                        f'{acc:.2f}', ha='center', va='bottom')
            
            # é©å¿œæ„Ÿåº¦åˆ†æ
            ax2 = axes[0, 1]
            sensitivity_data = np.random.normal(0.3, 0.05, 30)  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            ax2.hist(sensitivity_data, bins=8, alpha=0.7, color='lightcoral')
            ax2.set_title('Context Sensitivity Distribution')
            ax2.set_xlabel('Sensitivity Score')
            ax2.set_ylabel('Frequency')
            
            # é©å¿œä¸€è²«æ€§
            ax3 = axes[1, 0]
            test_types = ['Domain Switch', 'Abstraction Level']
            consistency_scores = [0.65, 0.72]  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            ax3.bar(test_types, consistency_scores, color=['purple', 'teal'], alpha=0.7)
            ax3.set_title('Adaptation Consistency by Test Type')
            ax3.set_ylabel('Consistency Score')
            ax3.set_ylim(0, 1)
            
            # æ™‚ç³»åˆ—é©å¿œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
            ax4 = axes[1, 1]
            time_series = range(10)
            adaptation_performance = np.random.normal(0.7, 0.05, 10)  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            ax4.plot(time_series, adaptation_performance, marker='s', color='red', alpha=0.7)
            ax4.set_title('Adaptation Performance Over Time')
            ax4.set_xlabel('Time Steps')
            ax4.set_ylabel('Adaptation Quality')
            ax4.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(viz_dir / "context_adaptation_analysis.png", dpi=150, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            logger.warning(f"Context adaptation plot creation failed: {e}")
    
    def generate_comprehensive_report(self):
        """åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãƒ¬ãƒãƒ¼ãƒˆ"""
        print("\nğŸ“‹ å‹•çš„è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ é•·æœŸå¤‰åŒ–ãƒ»æ–‡è„ˆé©å¿œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ")
        print("=" * 70)
        
        # è¨˜æ†¶é€²åŒ–çµæœ
        if 'memory_evolution_analysis' in self.results['statistical_summary']:
            mem_analysis = self.results['statistical_summary']['memory_evolution_analysis']
            print("\nâ³ è¨˜æ†¶é€²åŒ–åˆ†æçµæœ:")
            print(f"   å¹³å‡å®‰å®šæ€§ã‚¹ã‚³ã‚¢: {mem_analysis['average_stability']:.3f}")
            print(f"   å®‰å®šæ€§æ¨™æº–åå·®: {mem_analysis['stability_std']:.3f}")
            print(f"   å¹³å‡ãƒˆãƒ¬ãƒ³ãƒ‰å‚¾æ–œ: {mem_analysis['average_trend_slope']:.4f}")
            print(f"   ãƒˆãƒ¬ãƒ³ãƒ‰ä¸€è²«æ€§: {mem_analysis['trend_consistency']:.4f}")
            print(f"   ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {mem_analysis['sample_size']}")
            
            # çµè«–
            if mem_analysis['average_stability'] > 0.7:
                print("   âœ… é«˜ã„è¨˜æ†¶å®‰å®šæ€§ã‚’ç¢ºèª")
            elif mem_analysis['average_stability'] > 0.4:
                print("   âš ï¸ ä¸­ç¨‹åº¦ã®è¨˜æ†¶å®‰å®šæ€§")
            else:
                print("   âŒ ä½ã„è¨˜æ†¶å®‰å®šæ€§")
        
        # æ–‡è„ˆé©å¿œçµæœ
        if 'contextual_adaptation_analysis' in self.results['statistical_summary']:
            ctx_analysis = self.results['statistical_summary']['contextual_adaptation_analysis']
            print(f"\nğŸ¯ æ–‡è„ˆé©å¿œåˆ†æçµæœ:")
            print(f"   å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç²¾åº¦: {ctx_analysis['average_ranking_accuracy']:.3f}")
            print(f"   ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç²¾åº¦æ¨™æº–åå·®: {ctx_analysis['ranking_accuracy_std']:.3f}")
            print(f"   å¹³å‡æ–‡è„ˆæ„Ÿåº¦: {ctx_analysis['average_context_sensitivity']:.3f}")
            print(f"   é©å¿œãƒ­ãƒã‚¹ãƒˆãƒã‚¹: {ctx_analysis['adaptation_robustness']:.3f}")
            print(f"   ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {ctx_analysis['sample_size']}")
            
            # çµè«–
            if ctx_analysis['average_ranking_accuracy'] > 0.7:
                print("   âœ… é«˜ã„æ–‡è„ˆé©å¿œèƒ½åŠ›ã‚’ç¢ºèª")
            elif ctx_analysis['average_ranking_accuracy'] > 0.5:
                print("   âš ï¸ ä¸­ç¨‹åº¦ã®æ–‡è„ˆé©å¿œèƒ½åŠ›")
            else:
                print("   âŒ ä½ã„æ–‡è„ˆé©å¿œèƒ½åŠ›")
        
        # ç·åˆè©•ä¾¡
        print(f"\nğŸ¯ ç·åˆè©•ä¾¡:")
        if not self.available:
            print(f"   âš ï¸ InsightSpike-AIåˆ©ç”¨ä¸å¯ - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
            print(f"   ğŸ“Š å®Ÿéš›ã®å‹•çš„è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã§ã®æ¤œè¨¼ãŒå¿…è¦")
        else:
            print(f"   âœ… InsightSpike-AIå‹•çš„è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†")
            print(f"   ğŸ“Š é•·æœŸè¨˜æ†¶å¤‰åŒ–ãƒ»æ–‡è„ˆé©å¿œèƒ½åŠ›ã‚’å®šé‡åŒ–")
        
        print(f"\nğŸ“Š è©³ç´°çµæœ:")
        print(f"   ğŸ“ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿: {self.output_dir}/")
        print(f"   ğŸ“ˆ å¯è¦–åŒ–å›³è¡¨: {self.output_dir}/visualizations/")
        print(f"   ğŸ“‹ çµ±è¨ˆã‚µãƒãƒªãƒ¼: ä¸Šè¨˜åˆ†æçµæœã‚’å‚ç…§")
        
        # æ”¹å–„ææ¡ˆ
        print(f"\nğŸ’¡ æ”¹å–„ææ¡ˆ:")
        print(f"   1. é•·æœŸè¨˜æ†¶æ¸›è¡°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æœ€é©åŒ–")
        print(f"   2. æ–‡è„ˆä¾å­˜é‡ã¿ä»˜ã‘ã®å‹•çš„èª¿æ•´")
        print(f"   3. è¨˜æ†¶çµ±åˆãƒ—ãƒ­ã‚»ã‚¹ã®åŠ¹ç‡åŒ–")
        print(f"   4. ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ–‡è„ˆã®å‡¦ç†èƒ½åŠ›å‘ä¸Š")
    
    def _convert_for_json(self, obj):
        """JSON serializableå½¢å¼ã¸ã®å¤‰æ›"""
        if isinstance(obj, dict):
            return {k: self._convert_for_json(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_for_json(v) for v in obj]
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, (np.int64, np.int32)):
            return int(obj)
        elif isinstance(obj, (np.float64, np.float32)):
            return float(obj)
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif hasattr(obj, '__dict__'):
            return self._convert_for_json(obj.__dict__)
        else:
            return obj

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ å‹•çš„è¨˜æ†¶é•·æœŸå¤‰åŒ–ãƒ»æ–‡è„ˆé©å¿œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
    print("=" * 70)
    print("ğŸ“‹ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç›®çš„:")
    print("   1. é•·æœŸçš„è¨˜æ†¶é€²åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šé‡åŒ–")
    print("   2. æ–‡è„ˆä¾å­˜æ¤œç´¢ç²¾åº¦ã®å®¢è¦³çš„æ¸¬å®š")
    print("   3. è¨˜æ†¶çµ±åˆãƒ»å¿˜å´ãƒ—ãƒ­ã‚»ã‚¹ã®è©•ä¾¡")
    print("   4. å‹•çš„é©å¿œèƒ½åŠ›ã®åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
    print()
    
    try:
        benchmark = DynamicMemoryBenchmark()
        results = benchmark.run_comprehensive_benchmark(n_iterations=8)
        
        print("\nâœ… ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†ï¼")
        return results
        
    except Exception as e:
        print(f"\nâŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(f"è©³ç´°: {traceback.format_exc()}")
        return None

if __name__ == "__main__":
    main()
