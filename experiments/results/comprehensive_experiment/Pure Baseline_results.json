{
  "Pure Baseline": [
    {
      "trial_id": 0,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 1,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 2,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 3,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 4,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 5,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 6,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 7,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 8,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 9,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 10,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 11,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 12,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 13,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 14,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 15,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 16,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 17,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 18,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    },
    {
      "trial_id": 19,
      "agent_type": "Baseline",
      "config": {
        "experiment_name": "Pure Baseline",
        "num_trials": 20,
        "num_episodes": 50,
        "maze_size": 8,
        "wall_density": 0.25,
        "random_seed": 42,
        "learning_rate": 0.15,
        "exploration_rate": 0.4,
        "exploration_decay": 0.995,
        "dged_threshold": -0.3,
        "dig_threshold": 1.0,
        "insight_reward_scale": 0.0,
        "confidence_level": 0.95,
        "significance_threshold": 0.05
      },
      "episode_rewards": [
        21.209999999999837,
        86.99000000000002,
        86.21000000000001,
        80.04999999999988,
        79.60999999999999,
        61.949999999999946,
        80.28999999999999,
        86.31000000000002,
        84.79000000000002,
        92.61000000000001,
        79.70999999999997,
        94.59,
        90.45000000000002,
        96.59,
        90.21000000000001,
        93.49000000000001,
        93.53,
        93.43,
        98.71,
        89.33000000000001,
        93.57000000000001,
        92.45000000000002,
        96.77,
        95.69,
        90.51,
        94.67,
        95.65,
        95.67,
        96.77,
        97.81,
        98.71,
        97.69,
        95.77000000000001,
        98.85,
        97.77,
        96.61,
        98.83,
        98.81,
        97.83,
        92.67,
        98.85,
        98.79,
        97.71,
        98.85,
        92.75,
        95.81,
        95.85,
        95.83,
        92.83,
        98.83
      ],
      "episode_steps": [
        356,
        114,
        93,
        214,
        159,
        242,
        190,
        83,
        136,
        47,
        149,
        47,
        65,
        45,
        89,
        58,
        54,
        64,
        31,
        78,
        50,
        63,
        27,
        36,
        59,
        39,
        40,
        38,
        27,
        22,
        31,
        34,
        28,
        17,
        26,
        43,
        19,
        21,
        20,
        41,
        17,
        23,
        32,
        17,
        33,
        24,
        20,
        22,
        25,
        19
      ],
      "success_rates": [
        0.0,
        0.5,
        0.6666666666666666,
        0.75,
        0.8,
        0.8333333333333334,
        0.8571428571428571,
        0.875,
        0.8888888888888888,
        0.9,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "total_insights": [],
      "insight_episodes": [],
      "insight_rewards": [],
      "time_to_first_success": 0,
      "average_steps_to_goal": 58.59183673469388,
      "learning_curve_auc": 46.57103174603175,
      "states_visited": 51,
      "exploration_efficiency": 0.796875,
      "mean_reward": 91.3852,
      "std_reward": 12.191799578405174,
      "mean_steps": 64.54,
      "std_steps": 66.55289926066331,
      "final_success_rate": 1.0
    }
  ]
}