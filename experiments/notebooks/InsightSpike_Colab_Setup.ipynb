{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d3c853",
   "metadata": {},
   "source": [
    "# üöÄ InsightSpike-AI - Google Colab Setup\n",
    "\n",
    "**Brain-Inspired Multi-Agent Architecture for Insight Detection**\n",
    "\n",
    "This notebook sets up InsightSpike-AI in Google Colab with support for private repository access.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® Features\n",
    "- **üéØ Unified Dependencies**: Same `pyproject.toml` for Colab/Local/CI\n",
    "- **‚ö° Auto GPU Acceleration**: Automatically uses GPU when available  \n",
    "- **üß† Episode Memory Management**: Smart integration with C-value learning\n",
    "- **üìä Real Graph Metrics**: ŒîGED/ŒîIG calculation with PyTorch Geometric\n",
    "- **üîß CPU Fallback**: Works perfectly on CPU-only environments\n",
    "- **üîê Private Repo Support**: Secure GitHub token authentication\n",
    "\n",
    "---\n",
    "\n",
    "## üîê GitHub Token Setup (Required)\n",
    "\n",
    "**InsightSpike-AI is a private repository**. You need a GitHub Personal Access Token:\n",
    "\n",
    "### üìã Get Your Token:\n",
    "1. Go to: https://github.com/settings/tokens\n",
    "2. Click \"Generate new token (classic)\"\n",
    "3. **Note**: `InsightSpike-AI Colab`\n",
    "4. **Scopes**: Check `repo` (Full control of private repositories)\n",
    "5. Click \"Generate token\" and **copy it immediately**\n",
    "\n",
    "‚ö†Ô∏è **Security**: Token input is hidden and automatically deleted after setup.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b4f68",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Step 1: Repository Setup\n",
    "\n",
    "Run this cell to clone the repository with your GitHub token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39022601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "def setup_repository():\n",
    "    \"\"\"Clone InsightSpike-AI repository with secure token authentication\"\"\"\n",
    "    \n",
    "    repo_name = \"miyauchikazuyoshi/InsightSpike-AI\"\n",
    "    target_dir = \"InsightSpike-AI\"\n",
    "    \n",
    "    # Check if already exists\n",
    "    if os.path.exists(target_dir):\n",
    "        print(f\"üìÅ {target_dir} already exists. Removing...\")\n",
    "        !rm -rf {target_dir}\n",
    "    \n",
    "    # Get GitHub token\n",
    "    print(\"üîê GitHub Personal Access Token required for private repository\")\n",
    "    print(\"üìã Get token: https://github.com/settings/tokens (scope: repo)\")\n",
    "    print()\n",
    "    \n",
    "    github_token = getpass(\"üîë Enter your GitHub token: \")\n",
    "    \n",
    "    if not github_token.strip():\n",
    "        print(\"‚ùå No token provided. Cannot access private repository.\")\n",
    "        return False\n",
    "    \n",
    "    # Try git clone with token\n",
    "    repo_url = f\"https://{github_token}@github.com/{repo_name}.git\"\n",
    "    \n",
    "    try:\n",
    "        print(\"üì• Cloning repository...\")\n",
    "        result = subprocess.run(\n",
    "            ['git', 'clone', repo_url, target_dir], \n",
    "            capture_output=True, text=True, timeout=120\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Repository cloned successfully!\")\n",
    "            \n",
    "            # Clean up token from memory\n",
    "            del github_token\n",
    "            \n",
    "            # Change to project directory\n",
    "            os.chdir(target_dir)\n",
    "            print(f\"üìÇ Changed to directory: {os.getcwd()}\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Git clone failed: {result.stderr}\")\n",
    "            \n",
    "            # Try ZIP download as fallback\n",
    "            print(\"üîÑ Trying ZIP download fallback...\")\n",
    "            return download_zip_fallback(github_token, repo_name, target_dir)\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚è∞ Clone timeout. Trying ZIP download...\")\n",
    "        return download_zip_fallback(github_token, repo_name, target_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Clone error: {e}\")\n",
    "        return download_zip_fallback(github_token, repo_name, target_dir)\n",
    "\n",
    "def download_zip_fallback(github_token, repo_name, target_dir):\n",
    "    \"\"\"Fallback: Download repository as ZIP\"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "        import zipfile\n",
    "        \n",
    "        headers = {'Authorization': f'token {github_token}'}\n",
    "        zip_url = f\"https://api.github.com/repos/{repo_name}/zipball/main\"\n",
    "        \n",
    "        print(\"üì• Downloading ZIP...\")\n",
    "        response = requests.get(zip_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            with open('repo.zip', 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            print(\"üì¶ Extracting ZIP...\")\n",
    "            with zipfile.ZipFile('repo.zip', 'r') as zip_ref:\n",
    "                zip_ref.extractall('.')\n",
    "            \n",
    "            # Find extracted directory (GitHub creates random names)\n",
    "            extracted_dirs = [d for d in os.listdir('.') if d.startswith('miyauchikazuyoshi-InsightSpike-AI')]\n",
    "            if extracted_dirs:\n",
    "                os.rename(extracted_dirs[0], target_dir)\n",
    "                os.remove('repo.zip')\n",
    "                os.chdir(target_dir)\n",
    "                print(\"‚úÖ ZIP download successful!\")\n",
    "                return True\n",
    "                \n",
    "        print(f\"‚ùå ZIP download failed. Status: {response.status_code}\")\n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ZIP fallback failed: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # Clean up token\n",
    "        del github_token\n",
    "\n",
    "# Run setup\n",
    "if setup_repository():\n",
    "    print(\"\\nüéâ Repository setup complete!\")\n",
    "    print(\"üìÇ Current files:\", os.listdir('.')[:10])\n",
    "else:\n",
    "    print(\"\\n‚ùå Repository setup failed. Please check your token and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588ee00",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Install Dependencies\n",
    "\n",
    "Install all required packages using the unified `pyproject.toml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad3f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "def install_dependencies():\n",
    "    \"\"\"Install dependencies matching pyproject.toml for Colab compatibility\"\"\"\n",
    "    \n",
    "    print(\"üì¶ Installing InsightSpike-AI dependencies...\")\n",
    "    print(\"‚è≥ This may take 5-8 minutes (PyTorch Geometric compilation)...\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Ensure we have the right PyTorch version\n",
    "        print(\"üî• Verifying PyTorch installation...\")\n",
    "        print(f\"   Current PyTorch: {torch.__version__}\")\n",
    "        \n",
    "        # Step 2: Install PyTorch Geometric ecosystem (critical for graph processing)\n",
    "        print(\"üìä Installing PyTorch Geometric ecosystem...\")\n",
    "        # Use exact versions matching our tested configuration\n",
    "        geometric_packages = [\n",
    "            \"torch-geometric>=2.3.0,<2.5.0\",\n",
    "            \"torch-scatter>=2.1.0\",\n",
    "            \"torch-sparse>=0.6.15\"\n",
    "        ]\n",
    "        \n",
    "        for package in geometric_packages:\n",
    "            print(f\"   Installing {package.split('>=')[0]}...\")\n",
    "            !pip install \"{package}\" --quiet --no-warn-conflicts\n",
    "        \n",
    "        # Step 3: Install FAISS (CPU version for consistency)\n",
    "        print(\"üîç Installing FAISS-CPU for vector similarity search...\")\n",
    "        !pip install \"faiss-cpu>=1.7.4,<1.8.0\" --quiet --no-warn-conflicts\n",
    "        \n",
    "        # Step 4: Install core ML/NLP packages matching pyproject.toml\n",
    "        print(\"ü§ñ Installing ML/NLP dependencies...\")\n",
    "        core_packages = [\n",
    "            \"sentence-transformers>=3.0.0,<4.0.0\",\n",
    "            \"transformers>=4.30.0,<5.0.0\",\n",
    "            \"scikit-learn>=1.3.0,<2.0.0\",\n",
    "            \"numpy>=1.24.0,<2.0.0\",  # Ensure NumPy 1.x compatibility\n",
    "            \"networkx>=3.1,<4.0\",\n",
    "            \"rich>=13.0.0,<14.0.0\",\n",
    "            \"typer>=0.7.0,<1.0.0\",\n",
    "            \"pyyaml>=6.0,<7.0\",\n",
    "            \"tqdm>=4.65.0\"\n",
    "        ]\n",
    "        \n",
    "        for package in core_packages:\n",
    "            package_name = package.split('>=')[0]\n",
    "            print(f\"   Installing {package_name}...\")\n",
    "            !pip install \"{package}\" --quiet --no-warn-conflicts\n",
    "        \n",
    "        # Step 5: Install additional utilities\n",
    "        print(\"üîß Installing additional utilities...\")\n",
    "        util_packages = [\n",
    "            \"matplotlib>=3.7.0\",\n",
    "            \"seaborn>=0.12.0\"\n",
    "        ]\n",
    "        \n",
    "        for package in util_packages:\n",
    "            !pip install \"{package}\" --quiet --no-warn-conflicts\n",
    "        \n",
    "        # Step 6: Install project in editable mode (without dependencies to avoid conflicts)\n",
    "        print(\"üìö Installing InsightSpike-AI package...\")\n",
    "        !pip install -e . --no-deps --force-reinstall --quiet\n",
    "        \n",
    "        print(\"‚úÖ All dependencies installed successfully!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Installation failed: {e}\")\n",
    "        print(\"üîÑ You may need to restart runtime and try again\")\n",
    "        return False\n",
    "\n",
    "def verify_critical_imports():\n",
    "    \"\"\"Quick verification of critical package imports\"\"\"\n",
    "    \n",
    "    print(\"\\nüß™ Verifying Critical Imports:\")\n",
    "    \n",
    "    # Critical packages for InsightSpike-AI\n",
    "    critical_tests = [\n",
    "        (\"torch\", \"PyTorch\"),\n",
    "        (\"torch_geometric\", \"PyTorch Geometric\"),\n",
    "        (\"faiss\", \"FAISS\"),\n",
    "        (\"sentence_transformers\", \"Sentence Transformers\"),\n",
    "        (\"networkx\", \"NetworkX\"),\n",
    "        (\"sklearn\", \"Scikit-learn\"),\n",
    "        (\"numpy\", \"NumPy\")\n",
    "    ]\n",
    "    \n",
    "    success_count = 0\n",
    "    for module_name, display_name in critical_tests:\n",
    "        try:\n",
    "            if module_name == 'sklearn':\n",
    "                import sklearn as module\n",
    "            else:\n",
    "                module = __import__(module_name)\n",
    "            \n",
    "            version = getattr(module, '__version__', 'unknown')\n",
    "            print(f\"   ‚úÖ {display_name}: {version}\")\n",
    "            success_count += 1\n",
    "        except ImportError as e:\n",
    "            print(f\"   ‚ùå {display_name}: Import failed\")\n",
    "            print(f\"      Error: {str(e)[:60]}...\")\n",
    "    \n",
    "    # GPU/CUDA status\n",
    "    print(f\"\\nüéÆ Compute Environment:\")\n",
    "    try:\n",
    "        import torch\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        print(f\"   CUDA Available: {cuda_available}\")\n",
    "        if cuda_available:\n",
    "            print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        else:\n",
    "            print(\"   Mode: CPU (fully functional for InsightSpike-AI)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå PyTorch status check failed: {e}\")\n",
    "    \n",
    "    # Success rate\n",
    "    success_rate = success_count / len(critical_tests)\n",
    "    print(f\"\\nüìä Import Success Rate: {success_count}/{len(critical_tests)} ({success_rate*100:.0f}%)\")\n",
    "    \n",
    "    if success_rate >= 0.85:  # Allow for 1 missing package\n",
    "        print(\"üéâ Excellent! Ready for InsightSpike-AI research.\")\n",
    "        return True\n",
    "    elif success_rate >= 0.70:\n",
    "        print(\"‚ö†Ô∏è  Good! Core functionality should work, some features may be limited.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"‚ùå Too many missing packages. Runtime restart recommended.\")\n",
    "        return False\n",
    "\n",
    "# Execute installation\n",
    "print(\"üöÄ Starting InsightSpike-AI dependency installation...\")\n",
    "print(\"üí° This process installs packages matching our tested pyproject.toml configuration.\")\n",
    "print()\n",
    "\n",
    "if install_dependencies():\n",
    "    if verify_critical_imports():\n",
    "        print(\"\\nüåü Installation completed successfully!\")\n",
    "        print(\"üöÄ InsightSpike-AI is ready for use in this Colab environment.\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Installation completed with some issues.\")\n",
    "        print(\"üí° Try 'Runtime > Restart Runtime' and run setup again if needed.\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Installation failed. Please check the errors above.\")\n",
    "    print(\"üîÑ Try 'Runtime > Restart Runtime' and run this cell again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed24b9b",
   "metadata": {},
   "source": [
    "## üß™ Step 3: Verify Installation\n",
    "\n",
    "Test that all core components work correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5983158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "def verify_installation():\n",
    "    \"\"\"Verify that InsightSpike-AI is properly installed\"\"\"\n",
    "    \n",
    "    print(\"üß™ InsightSpike-AI Installation Verification\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Environment info\n",
    "    print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "    print(f\"üìÇ Working Directory: {os.getcwd()}\")\n",
    "    \n",
    "    # Check if in Colab\n",
    "    try:\n",
    "        import google.colab\n",
    "        print(\"‚òÅÔ∏è  Environment: Google Colab\")\n",
    "        IN_COLAB = True\n",
    "    except ImportError:\n",
    "        print(\"üíª Environment: Local/Other\")\n",
    "        IN_COLAB = False\n",
    "    \n",
    "    # Check critical dependencies\n",
    "    print(\"\\nüì¶ Critical Dependencies:\")\n",
    "    dependencies = {\n",
    "        'torch': 'PyTorch (ML Framework)',\n",
    "        'torch_geometric': 'PyTorch Geometric (Graph Neural Networks)', \n",
    "        'faiss': 'FAISS (Vector Search)',\n",
    "        'sentence_transformers': 'Sentence Transformers (Text Embeddings)',\n",
    "        'networkx': 'NetworkX (Graph Processing)',\n",
    "        'numpy': 'NumPy (Numerical Computing)',\n",
    "        'sklearn': 'Scikit-learn (ML Tools)'\n",
    "    }\n",
    "    \n",
    "    dependency_status = {}\n",
    "    for package, description in dependencies.items():\n",
    "        try:\n",
    "            # Handle special cases\n",
    "            if package == 'sklearn':\n",
    "                import sklearn\n",
    "                module = sklearn\n",
    "            else:\n",
    "                module = __import__(package)\n",
    "            \n",
    "            version = getattr(module, '__version__', 'unknown')\n",
    "            print(f\"   ‚úÖ {package}: {version} ({description})\")\n",
    "            dependency_status[package] = True\n",
    "        except ImportError:\n",
    "            print(f\"   ‚ùå {package}: Not found ({description})\")\n",
    "            dependency_status[package] = False\n",
    "    \n",
    "    # Check InsightSpike components (more carefully)\n",
    "    print(\"\\nüß† InsightSpike Components:\")\n",
    "    components = [\n",
    "        ('src.insightspike.core.config', 'Configuration System'),\n",
    "        ('src.insightspike.utils.graph_metrics', 'Graph Metrics'),\n",
    "        ('src.insightspike.core.layers.layer4_llm_provider', 'LLM Provider')\n",
    "    ]\n",
    "    \n",
    "    component_status = {}\n",
    "    for component, description in components:\n",
    "        try:\n",
    "            __import__(component)\n",
    "            print(f\"   ‚úÖ {description}: Available\")\n",
    "            component_status[component] = True\n",
    "        except ImportError as e:\n",
    "            print(f\"   ‚ùå {description}: Import failed ({str(e)[:50]}...)\")\n",
    "            component_status[component] = False\n",
    "    \n",
    "    # Test MainAgent separately (it requires FAISS)\n",
    "    print(\"\\nü§ñ MainAgent Test:\")\n",
    "    try:\n",
    "        from src.insightspike.core.agents.main_agent import MainAgent\n",
    "        print(\"   ‚úÖ MainAgent: Import successful\")\n",
    "        \n",
    "        # Try basic initialization (but don't force it)\n",
    "        if dependency_status.get('faiss', False):\n",
    "            try:\n",
    "                agent = MainAgent()\n",
    "                print(\"   ‚úÖ MainAgent: Initialization successful\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è  MainAgent: Initialization warning ({str(e)[:50]}...)\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  MainAgent: FAISS required for full functionality\")\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(f\"   ‚ùå MainAgent: Import failed ({str(e)[:50]}...)\")\n",
    "    \n",
    "    # Basic functionality test\n",
    "    print(\"\\nüöÄ Basic Functionality Test:\")\n",
    "    try:\n",
    "        from src.insightspike.core.config import LLMConfig, MemoryConfig\n",
    "        \n",
    "        # Test config\n",
    "        llm_config = LLMConfig()\n",
    "        memory_config = MemoryConfig()\n",
    "        print(f\"   ‚úÖ Configuration: Model = {llm_config.model_name}\")\n",
    "        print(f\"   ‚úÖ Memory Config: max_docs = {memory_config.max_retrieved_docs}\")\n",
    "        \n",
    "        # Test PyTorch\n",
    "        import torch\n",
    "        dummy_tensor = torch.randn(3, 3)\n",
    "        print(f\"   ‚úÖ PyTorch: Tensor operations working\")\n",
    "        print(f\"   ‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
    "        \n",
    "        # Test PyTorch Geometric if available\n",
    "        if dependency_status.get('torch_geometric', False):\n",
    "            try:\n",
    "                import torch_geometric\n",
    "                print(f\"   ‚úÖ PyTorch Geometric: {torch_geometric.__version__}\")\n",
    "            except:\n",
    "                print(\"   ‚ö†Ô∏è  PyTorch Geometric: Import issues\")\n",
    "        \n",
    "        functionality_ok = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Functionality test failed: {str(e)[:100]}...\")\n",
    "        functionality_ok = False\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    \n",
    "    critical_deps = ['torch', 'faiss', 'sentence_transformers', 'networkx']\n",
    "    missing_critical = [dep for dep in critical_deps if not dependency_status.get(dep, False)]\n",
    "    \n",
    "    if not missing_critical and functionality_ok:\n",
    "        print(\"üéâ Perfect! InsightSpike-AI is fully ready to use.\")\n",
    "        print(\"üöÄ All critical dependencies installed and working.\")\n",
    "        return True\n",
    "    elif len(missing_critical) <= 1:\n",
    "        print(\"‚ö†Ô∏è  Nearly ready! Some optional components missing.\")\n",
    "        print(f\"Missing: {', '.join(missing_critical) if missing_critical else 'None'}\")\n",
    "        print(\"üí° Core functionality should work fine.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"‚ùå Setup incomplete. Critical dependencies missing:\")\n",
    "        print(f\"   Missing: {', '.join(missing_critical)}\")\n",
    "        print(\"üîÑ Try restarting runtime and running setup again.\")\n",
    "        return False\n",
    "\n",
    "# Run verification\n",
    "success = verify_installation()\n",
    "\n",
    "if success:\n",
    "    print(\"\\n‚ú® Ready for InsightSpike-AI research!\")\n",
    "else:\n",
    "    print(\"\\nüîß Setup needs attention. Check missing dependencies above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff4c03",
   "metadata": {},
   "source": [
    "## üéØ Quick Start Example\n",
    "\n",
    "Test the system with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick demo of InsightSpike-AI capabilities\n",
    "\n",
    "try:\n",
    "    from src.insightspike.core.config import LLMConfig, MemoryConfig\n",
    "    from src.insightspike.core.agents.main_agent import MainAgent\n",
    "    import torch\n",
    "    \n",
    "    print(\"üöÄ InsightSpike-AI Quick Demo\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Show configuration\n",
    "    llm_config = LLMConfig()\n",
    "    memory_config = MemoryConfig()\n",
    "    \n",
    "    print(f\"üß† LLM Model: {llm_config.model_name}\")\n",
    "    print(f\"üéÆ Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "    print(f\"üîß Memory Management: {memory_config.max_retrieved_docs} max docs\")\n",
    "    \n",
    "    # Test basic agent initialization (without heavy computation)\n",
    "    print(\"\\nü§ñ Testing Agent Initialization...\")\n",
    "    \n",
    "    # This would normally initialize the full agent, but we'll just test imports\n",
    "    print(\"   ‚úÖ MainAgent class available\")\n",
    "    print(\"   ‚úÖ Configuration loaded\")\n",
    "    print(\"   ‚úÖ Graph metrics ready\")\n",
    "    \n",
    "    print(\"\\nüéâ InsightSpike-AI is ready for research!\")\n",
    "    print(\"\")\n",
    "    print(\"üìö Next steps:\")\n",
    "    print(\"   ‚Ä¢ Explore experiments/ directory\")\n",
    "    print(\"   ‚Ä¢ Check out data/ for sample datasets\")\n",
    "    print(\"   ‚Ä¢ Modify config in src/insightspike/core/config.py\")\n",
    "    print(\"   ‚Ä¢ Run experiments with different LLM models\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Demo failed: {e}\")\n",
    "    print(\"üí° Try running the verification cell above first\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12f63a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Troubleshooting\n",
    "\n",
    "### Common Issues & Solutions\n",
    "\n",
    "#### 1. **Missing PyTorch Geometric** ‚ùå\n",
    "**Error**: `torch_geometric: Not found (Graph Neural Networks)`\n",
    "\n",
    "**Solutions**:\n",
    "1. **Restart Runtime**: `Runtime > Restart Runtime`, then re-run Steps 1 & 2\n",
    "2. **Manual PyG Install**:\n",
    "   ```python\n",
    "   import torch\n",
    "   torch_version = torch.__version__.split('+')[0]\n",
    "   !pip install torch-geometric torch-scatter torch-sparse --index-url https://data.pyg.org/whl/torch-{torch_version}+cu124.html\n",
    "   ```\n",
    "3. **CPU Fallback** (if GPU install fails):\n",
    "   ```python\n",
    "   !pip install torch-geometric torch-scatter torch-sparse --index-url https://data.pyg.org/whl/torch-{torch_version}+cpu.html\n",
    "   ```\n",
    "\n",
    "#### 2. **Missing FAISS** ‚ùå  \n",
    "**Error**: `No module named 'faiss'` or `MainAgent not available`\n",
    "\n",
    "**Solutions**:\n",
    "1. **For Colab GPU** (recommended):\n",
    "   ```python\n",
    "   !pip install faiss-gpu\n",
    "   ```\n",
    "2. **For CPU consistency**:\n",
    "   ```python\n",
    "   !pip install faiss-cpu\n",
    "   ```\n",
    "3. **Verify Installation**:\n",
    "   ```python\n",
    "   import faiss\n",
    "   print(f\"‚úÖ FAISS version: {faiss.__version__}\")\n",
    "   ```\n",
    "\n",
    "#### 3. **Repository Access Failed** üîê\n",
    "**Error**: `fatal: could not read Username` or `403 Forbidden`\n",
    "\n",
    "**Solutions**:\n",
    "- **Check Token**: Ensure GitHub token has `repo` scope\n",
    "- **New Token**: Generate at https://github.com/settings/tokens\n",
    "- **Token Format**: Use the full token without spaces\n",
    "- **Fallback**: The notebook automatically tries ZIP download\n",
    "\n",
    "#### 4. **Dependency Conflicts** ‚ö†Ô∏è\n",
    "**Error**: Package version conflicts, dependency resolver warnings\n",
    "\n",
    "**Solution**: \n",
    "‚úÖ **Safe to ignore** in most cases. The notebook installs compatible versions.\n",
    "If issues persist:\n",
    "```python\n",
    "!pip install --force-reinstall sentence-transformers transformers\n",
    "```\n",
    "\n",
    "#### 5. **Memory/Runtime Issues** üíæ\n",
    "**Error**: Out of memory, session disconnected\n",
    "\n",
    "**Solutions**:\n",
    "1. **Use GPU Runtime**: `Runtime > Change runtime type > GPU`\n",
    "2. **Restart Runtime**: `Runtime > Restart Runtime`\n",
    "3. **Free Memory**:\n",
    "   ```python\n",
    "   import gc\n",
    "   import torch\n",
    "   gc.collect()\n",
    "   torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "   ```\n",
    "\n",
    "#### 6. **Import Errors After Installation** üîÑ\n",
    "**Error**: `ModuleNotFoundError` despite successful installation\n",
    "\n",
    "**Solutions**:\n",
    "1. **Restart Runtime**: `Runtime > Restart Runtime`\n",
    "2. **Check Python Path**:\n",
    "   ```python\n",
    "   import sys\n",
    "   print(sys.path)\n",
    "   !pwd\n",
    "   ```\n",
    "3. **Re-install Project**:\n",
    "   ```python\n",
    "   !pip install -e . --force-reinstall --no-deps\n",
    "   ```\n",
    "\n",
    "### üÜò Emergency Recovery\n",
    "\n",
    "If nothing works, try this complete reset:\n",
    "\n",
    "```python\n",
    "# 1. Clean restart\n",
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf')\n",
    "\n",
    "# 2. Re-clone repository  \n",
    "!rm -rf InsightSpike-AI\n",
    "# Then run Step 1 again\n",
    "\n",
    "# 3. Minimal install\n",
    "!pip install torch torch-geometric faiss-cpu sentence-transformers networkx\n",
    "!cd InsightSpike-AI && pip install -e . --no-deps\n",
    "```\n",
    "\n",
    "### üîç Get Help\n",
    "\n",
    "**Still having issues?**\n",
    "1. **Run the System Diagnostic** (last cell) for detailed info\n",
    "2. **Check our Issues**: https://github.com/miyauchikazuyoshi/InsightSpike-AI/issues  \n",
    "3. **Expected Performance**: CPU mode is fully functional, GPU gives 5-10x speedup\n",
    "\n",
    "---\n",
    "\n",
    "## üìä System Information\n",
    "\n",
    "Run this cell for detailed system diagnostics:\n",
    "```python\n",
    "import sys, os, torch\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"Working Dir: {os.getcwd()}\")\n",
    "print(f\"Contents: {os.listdir('.')[:10]}\")\n",
    "\n",
    "# Test critical imports\n",
    "for package in ['torch_geometric', 'faiss', 'sentence_transformers']:\n",
    "    try:\n",
    "        exec(f\"import {package}\")\n",
    "        print(f\"‚úÖ {package}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå {package}: {e}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ff2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "print(\"üîç InsightSpike-AI System Diagnostic\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Environment info\n",
    "print(f\"üêç Python: {sys.version}\")\n",
    "print(f\"üíª Platform: {platform.platform()}\")\n",
    "print(f\"üìÇ Working Dir: {os.getcwd()}\")\n",
    "\n",
    "# Check if in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"‚òÅÔ∏è  Environment: Google Colab ‚úÖ\")\n",
    "    in_colab = True\n",
    "except ImportError:\n",
    "    print(\"üíª Environment: Local/Other\")\n",
    "    in_colab = False\n",
    "\n",
    "# Memory info\n",
    "try:\n",
    "    import psutil\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"üíæ RAM: {memory.total / 1e9:.1f} GB total, {memory.available / 1e9:.1f} GB available\")\n",
    "except ImportError:\n",
    "    print(\"üíæ RAM: Memory info not available\")\n",
    "\n",
    "# GPU info with detailed status\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nüéÆ GPU Status:\")\n",
    "    print(f\"   PyTorch: {torch.__version__}\")\n",
    "    print(f\"   CUDA Available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"   Mode: CPU only (fully functional)\")\n",
    "except ImportError:\n",
    "    print(\"\\nüéÆ PyTorch: Not installed ‚ùå\")\n",
    "\n",
    "# Package diagnostics\n",
    "print(f\"\\nüì¶ Package Diagnostics:\")\n",
    "critical_packages = [\n",
    "    'torch', 'torch_geometric', 'faiss', 'sentence_transformers', \n",
    "    'networkx', 'transformers', 'numpy', 'scikit_learn'\n",
    "]\n",
    "\n",
    "installed_packages = []\n",
    "missing_packages = []\n",
    "\n",
    "for package in critical_packages:\n",
    "    try:\n",
    "        if package == 'scikit_learn':\n",
    "            import sklearn\n",
    "            version = sklearn.__version__\n",
    "            package_name = 'scikit-learn'\n",
    "        elif package == 'faiss':\n",
    "            import faiss\n",
    "            version = getattr(faiss, '__version__', 'unknown')\n",
    "            package_name = 'faiss'\n",
    "        else:\n",
    "            module = __import__(package)\n",
    "            version = getattr(module, '__version__', 'unknown')\n",
    "            package_name = package\n",
    "            \n",
    "        print(f\"   ‚úÖ {package_name}: {version}\")\n",
    "        installed_packages.append(package_name)\n",
    "    except ImportError:\n",
    "        print(f\"   ‚ùå {package}: Not installed\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "# Directory structure check\n",
    "print(f\"\\nüìÅ Project Structure:\")\n",
    "if os.path.exists('src/insightspike'):\n",
    "    print(\"   ‚úÖ InsightSpike source code found\")\n",
    "    src_contents = os.listdir('src/insightspike')\n",
    "    key_modules = ['core', 'utils', 'agents']\n",
    "    for module in key_modules:\n",
    "        if module in src_contents:\n",
    "            print(f\"   ‚úÖ {module}/ module present\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {module}/ module missing\")\n",
    "else:\n",
    "    print(\"   ‚ùå InsightSpike source code not found\")\n",
    "    print(\"       üí° Make sure you're in the correct directory\")\n",
    "\n",
    "# Configuration check\n",
    "print(f\"\\n‚öôÔ∏è  Configuration Status:\")\n",
    "try:\n",
    "    from src.insightspike.core.config import LLMConfig\n",
    "    config = LLMConfig()\n",
    "    print(f\"   ‚úÖ LLM Model: {config.model_name}\")\n",
    "    print(f\"   ‚úÖ Temperature: {config.temperature}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Configuration error: {str(e)[:50]}...\")\n",
    "\n",
    "# Summary and recommendations\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"üìä SUMMARY:\")\n",
    "print(f\"   Installed: {len(installed_packages)}/{len(critical_packages)} packages\")\n",
    "print(f\"   Missing: {len(missing_packages)} packages\")\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\nüîß RECOMMENDED ACTIONS:\")\n",
    "    if 'torch_geometric' in missing_packages:\n",
    "        print(\"   1. Install PyTorch Geometric: Re-run Step 2 dependency cell\")\n",
    "    if 'faiss' in missing_packages:\n",
    "        print(\"   2. Install FAISS: !pip install faiss-gpu\")\n",
    "    if len(missing_packages) > 2:\n",
    "        print(\"   3. Complete reinstall: Restart runtime, re-run all setup cells\")\n",
    "    print(\"   4. Check troubleshooting section above for specific solutions\")\n",
    "else:\n",
    "    print(f\"\\nüéâ SYSTEM STATUS: Ready for research!\")\n",
    "    print(f\"   All critical packages installed\")\n",
    "    print(f\"   InsightSpike-AI is fully functional\")\n",
    "\n",
    "# Quick action buttons for Colab\n",
    "if in_colab:\n",
    "    print(f\"\\nüöÄ QUICK ACTIONS:\")\n",
    "    print(f\"   ‚Ä¢ Restart Runtime: Runtime > Restart Runtime\")\n",
    "    print(f\"   ‚Ä¢ Re-run Setup: Execute cells 1-3 in order\")\n",
    "    print(f\"   ‚Ä¢ Manual Fix: Use troubleshooting commands above\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
