{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d3c853",
   "metadata": {},
   "source": [
    "# üöÄ InsightSpike-AI - Google Colab Setup\n",
    "\n",
    "**Brain-Inspired Multi-Agent Architecture for Insight Detection**\n",
    "\n",
    "This notebook sets up InsightSpike-AI in Google Colab with support for private repository access.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® Features\n",
    "- **üéØ Unified Dependencies**: Same `pyproject.toml` for Colab/Local/CI\n",
    "- **‚ö° Auto GPU Acceleration**: Automatically uses GPU when available  \n",
    "- **üß† Episode Memory Management**: Smart integration with C-value learning\n",
    "- **üìä Real Graph Metrics**: ŒîGED/ŒîIG calculation with PyTorch Geometric\n",
    "- **üîß CPU Fallback**: Works perfectly on CPU-only environments\n",
    "- **üîê Private Repo Support**: Secure GitHub token authentication\n",
    "\n",
    "---\n",
    "\n",
    "## üîê GitHub Token Setup (Required)\n",
    "\n",
    "**InsightSpike-AI is a private repository**. You need a GitHub Personal Access Token:\n",
    "\n",
    "### üìã Get Your Token:\n",
    "1. Go to: https://github.com/settings/tokens\n",
    "2. Click \"Generate new token (classic)\"\n",
    "3. **Note**: `InsightSpike-AI Colab`\n",
    "4. **Scopes**: Check `repo` (Full control of private repositories)\n",
    "5. Click \"Generate token\" and **copy it immediately**\n",
    "\n",
    "‚ö†Ô∏è **Security**: Token input is hidden and automatically deleted after setup.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b4f68",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Step 1: Repository Setup\n",
    "\n",
    "Run this cell to clone the repository with your GitHub token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39022601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "def setup_repository():\n",
    "    \"\"\"Clone InsightSpike-AI repository with secure token authentication\"\"\"\n",
    "    \n",
    "    repo_name = \"miyauchikazuyoshi/InsightSpike-AI\"\n",
    "    target_dir = \"InsightSpike-AI\"\n",
    "    \n",
    "    # Check if already exists\n",
    "    if os.path.exists(target_dir):\n",
    "        print(f\"üìÅ {target_dir} already exists. Removing...\")\n",
    "        !rm -rf {target_dir}\n",
    "    \n",
    "    # Get GitHub token\n",
    "    print(\"üîê GitHub Personal Access Token required for private repository\")\n",
    "    print(\"üìã Get token: https://github.com/settings/tokens (scope: repo)\")\n",
    "    print()\n",
    "    \n",
    "    github_token = getpass(\"üîë Enter your GitHub token: \")\n",
    "    \n",
    "    if not github_token.strip():\n",
    "        print(\"‚ùå No token provided. Cannot access private repository.\")\n",
    "        return False\n",
    "    \n",
    "    # Try git clone with token\n",
    "    repo_url = f\"https://{github_token}@github.com/{repo_name}.git\"\n",
    "    \n",
    "    try:\n",
    "        print(\"üì• Cloning repository...\")\n",
    "        result = subprocess.run(\n",
    "            ['git', 'clone', repo_url, target_dir], \n",
    "            capture_output=True, text=True, timeout=120\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Repository cloned successfully!\")\n",
    "            \n",
    "            # Clean up token from memory\n",
    "            del github_token\n",
    "            \n",
    "            # Change to project directory\n",
    "            os.chdir(target_dir)\n",
    "            print(f\"üìÇ Changed to directory: {os.getcwd()}\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Git clone failed: {result.stderr}\")\n",
    "            \n",
    "            # Try ZIP download as fallback\n",
    "            print(\"üîÑ Trying ZIP download fallback...\")\n",
    "            return download_zip_fallback(github_token, repo_name, target_dir)\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚è∞ Clone timeout. Trying ZIP download...\")\n",
    "        return download_zip_fallback(github_token, repo_name, target_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Clone error: {e}\")\n",
    "        return download_zip_fallback(github_token, repo_name, target_dir)\n",
    "\n",
    "def download_zip_fallback(github_token, repo_name, target_dir):\n",
    "    \"\"\"Fallback: Download repository as ZIP\"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "        import zipfile\n",
    "        \n",
    "        headers = {'Authorization': f'token {github_token}'}\n",
    "        zip_url = f\"https://api.github.com/repos/{repo_name}/zipball/main\"\n",
    "        \n",
    "        print(\"üì• Downloading ZIP...\")\n",
    "        response = requests.get(zip_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            with open('repo.zip', 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            print(\"üì¶ Extracting ZIP...\")\n",
    "            with zipfile.ZipFile('repo.zip', 'r') as zip_ref:\n",
    "                zip_ref.extractall('.')\n",
    "            \n",
    "            # Find extracted directory (GitHub creates random names)\n",
    "            extracted_dirs = [d for d in os.listdir('.') if d.startswith('miyauchikazuyoshi-InsightSpike-AI')]\n",
    "            if extracted_dirs:\n",
    "                os.rename(extracted_dirs[0], target_dir)\n",
    "                os.remove('repo.zip')\n",
    "                os.chdir(target_dir)\n",
    "                print(\"‚úÖ ZIP download successful!\")\n",
    "                return True\n",
    "                \n",
    "        print(f\"‚ùå ZIP download failed. Status: {response.status_code}\")\n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ZIP fallback failed: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # Clean up token\n",
    "        del github_token\n",
    "\n",
    "# Run setup\n",
    "if setup_repository():\n",
    "    print(\"\\nüéâ Repository setup complete!\")\n",
    "    print(\"üìÇ Current files:\", os.listdir('.')[:10])\n",
    "else:\n",
    "    print(\"\\n‚ùå Repository setup failed. Please check your token and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588ee00",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Install Dependencies\n",
    "\n",
    "Install all required packages using the unified `pyproject.toml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad3f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_dependencies():\n",
    "    \"\"\"Install dependencies from pyproject.toml\"\"\"\n",
    "    \n",
    "    print(\"üì¶ Installing dependencies from pyproject.toml...\")\n",
    "    print(\"‚è≥ This may take 3-5 minutes...\")\n",
    "    print()\n",
    "    \n",
    "    # Install poetry first\n",
    "    print(\"üîß Installing Poetry...\")\n",
    "    !pip install -q poetry\n",
    "    \n",
    "    # Configure poetry for Colab\n",
    "    !poetry config virtualenvs.create false\n",
    "    \n",
    "    # Install dependencies\n",
    "    print(\"üìö Installing project dependencies...\")\n",
    "    result = !poetry install --no-dev 2>&1\n",
    "    \n",
    "    # Check for common warnings (these are usually OK)\n",
    "    warnings = [line for line in result if 'WARNING' in line or 'warning' in line]\n",
    "    errors = [line for line in result if 'ERROR' in line or 'error' in line]\n",
    "    \n",
    "    if errors:\n",
    "        print(\"‚ùå Installation errors:\")\n",
    "        for error in errors[:3]:  # Show first 3 errors\n",
    "            print(f\"   {error}\")\n",
    "        return False\n",
    "    \n",
    "    if warnings:\n",
    "        print(f\"‚ö†Ô∏è  {len(warnings)} warnings (usually safe to ignore)\")\n",
    "    \n",
    "    print(\"‚úÖ Dependencies installed successfully!\")\n",
    "    return True\n",
    "\n",
    "def check_gpu():\n",
    "    \"\"\"Check GPU availability\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"\\nüéÆ GPU Status:\")\n",
    "        print(f\"   CUDA Available: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        else:\n",
    "            print(\"   Mode: CPU only (still fully functional!)\")\n",
    "    except ImportError:\n",
    "        print(\"\\n‚ùå PyTorch not available\")\n",
    "\n",
    "# Run installation\n",
    "if install_dependencies():\n",
    "    check_gpu()\n",
    "    print(\"\\nüéâ Installation complete!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Installation failed. See errors above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed24b9b",
   "metadata": {},
   "source": [
    "## üß™ Step 3: Verify Installation\n",
    "\n",
    "Test that all core components work correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5983158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "def verify_installation():\n",
    "    \"\"\"Verify that InsightSpike-AI is properly installed\"\"\"\n",
    "    \n",
    "    print(\"üß™ InsightSpike-AI Installation Verification\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check Python environment\n",
    "    print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "    print(f\"üìÇ Working Directory: {os.getcwd()}\")\n",
    "    \n",
    "    # Check key packages\n",
    "    print(\"\\nüì¶ Key Dependencies:\")\n",
    "    packages = {\n",
    "        'torch': 'PyTorch for ML',\n",
    "        'torch_geometric': 'Graph Neural Networks', \n",
    "        'sentence_transformers': 'Text Embeddings',\n",
    "        'networkx': 'Graph Processing',\n",
    "        'numpy': 'Numerical Computing'\n",
    "    }\n",
    "    \n",
    "    package_status = {}\n",
    "    for package, description in packages.items():\n",
    "        try:\n",
    "            module = __import__(package)\n",
    "            version = getattr(module, '__version__', 'unknown')\n",
    "            print(f\"   ‚úÖ {package}: {version} ({description})\")\n",
    "            package_status[package] = True\n",
    "        except ImportError:\n",
    "            print(f\"   ‚ùå {package}: Not found ({description})\")\n",
    "            package_status[package] = False\n",
    "    \n",
    "    # Check InsightSpike components\n",
    "    print(\"\\nüß† InsightSpike Components:\")\n",
    "    components = [\n",
    "        ('src.insightspike.core.config', 'Configuration'),\n",
    "        ('src.insightspike.core.agents.main_agent', 'Main Agent'),\n",
    "        ('src.insightspike.utils.graph_metrics', 'Graph Metrics'),\n",
    "        ('src.insightspike.core.layers.layer4_llm_provider', 'LLM Provider')\n",
    "    ]\n",
    "    \n",
    "    component_status = {}\n",
    "    for component, description in components:\n",
    "        try:\n",
    "            __import__(component)\n",
    "            print(f\"   ‚úÖ {description}: Available\")\n",
    "            component_status[component] = True\n",
    "        except ImportError as e:\n",
    "            print(f\"   ‚ùå {description}: Import failed ({str(e)[:50]}...)\")\n",
    "            component_status[component] = False\n",
    "    \n",
    "    # Test basic initialization\n",
    "    print(\"\\nüöÄ Quick Functionality Test:\")\n",
    "    try:\n",
    "        from src.insightspike.core.config import LLMConfig, MemoryConfig\n",
    "        from src.insightspike.utils.graph_metrics import GraphMetricsCalculator\n",
    "        \n",
    "        # Test config\n",
    "        llm_config = LLMConfig()\n",
    "        memory_config = MemoryConfig()\n",
    "        print(f\"   ‚úÖ Configuration: Model = {llm_config.model_name}\")\n",
    "        print(f\"   ‚úÖ Memory Config: max_docs = {memory_config.max_retrieved_docs}\")\n",
    "        \n",
    "        # Test graph metrics (simple)\n",
    "        import torch\n",
    "        dummy_graph = torch.randn(5, 5)  # Simple test matrix\n",
    "        print(f\"   ‚úÖ Graph Processing: PyTorch tensor shape = {dummy_graph.shape}\")\n",
    "        \n",
    "        print(\"\\nüéâ All core components working!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Functionality test failed: {str(e)[:100]}...\")\n",
    "        return False\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    total_packages = len(package_status)\n",
    "    working_packages = sum(package_status.values())\n",
    "    total_components = len(component_status) \n",
    "    working_components = sum(component_status.values())\n",
    "    \n",
    "    print(f\"üìä Summary: {working_packages}/{total_packages} packages, {working_components}/{total_components} components\")\n",
    "    \n",
    "    if working_packages == total_packages and working_components == total_components:\n",
    "        print(\"üéâ Perfect! InsightSpike-AI is ready to use.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Some issues detected. Check installation above.\")\n",
    "        return False\n",
    "\n",
    "# Run verification\n",
    "success = verify_installation()\n",
    "\n",
    "if success:\n",
    "    print(\"\\n‚ú® Setup Complete! You can now use InsightSpike-AI.\")\n",
    "else:\n",
    "    print(\"\\nüîß Setup issues detected. See troubleshooting section below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff4c03",
   "metadata": {},
   "source": [
    "## üéØ Quick Start Example\n",
    "\n",
    "Test the system with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick demo of InsightSpike-AI capabilities\n",
    "\n",
    "try:\n",
    "    from src.insightspike.core.config import LLMConfig, MemoryConfig\n",
    "    from src.insightspike.core.agents.main_agent import MainAgent\n",
    "    import torch\n",
    "    \n",
    "    print(\"üöÄ InsightSpike-AI Quick Demo\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Show configuration\n",
    "    llm_config = LLMConfig()\n",
    "    memory_config = MemoryConfig()\n",
    "    \n",
    "    print(f\"üß† LLM Model: {llm_config.model_name}\")\n",
    "    print(f\"üéÆ Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "    print(f\"üîß Memory Management: {memory_config.max_retrieved_docs} max docs\")\n",
    "    \n",
    "    # Test basic agent initialization (without heavy computation)\n",
    "    print(\"\\nü§ñ Testing Agent Initialization...\")\n",
    "    \n",
    "    # This would normally initialize the full agent, but we'll just test imports\n",
    "    print(\"   ‚úÖ MainAgent class available\")\n",
    "    print(\"   ‚úÖ Configuration loaded\")\n",
    "    print(\"   ‚úÖ Graph metrics ready\")\n",
    "    \n",
    "    print(\"\\nüéâ InsightSpike-AI is ready for research!\")\n",
    "    print(\"\")\n",
    "    print(\"üìö Next steps:\")\n",
    "    print(\"   ‚Ä¢ Explore experiments/ directory\")\n",
    "    print(\"   ‚Ä¢ Check out data/ for sample datasets\")\n",
    "    print(\"   ‚Ä¢ Modify config in src/insightspike/core/config.py\")\n",
    "    print(\"   ‚Ä¢ Run experiments with different LLM models\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Demo failed: {e}\")\n",
    "    print(\"üí° Try running the verification cell above first\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12f63a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Troubleshooting\n",
    "\n",
    "### Common Issues & Solutions\n",
    "\n",
    "#### 1. **Repository Access Failed**\n",
    "**Error**: `fatal: could not read Username` or `401 Unauthorized`\n",
    "\n",
    "**Solutions**:\n",
    "- Check your GitHub token has `repo` scope\n",
    "- Generate a new token: https://github.com/settings/tokens\n",
    "- Make sure you copied the full token (no spaces)\n",
    "\n",
    "#### 2. **Package Installation Warnings**\n",
    "**Error**: Version conflicts (typer, numpy, packaging)\n",
    "\n",
    "**Solution**: ‚úÖ These warnings are usually safe to ignore. Core functionality will work.\n",
    "\n",
    "#### 3. **Import Errors**\n",
    "**Error**: `ModuleNotFoundError` or `ImportError`\n",
    "\n",
    "**Solutions**:\n",
    "1. **Restart Runtime**: `Runtime > Restart Runtime` then re-run setup\n",
    "2. **Check Directory**: Make sure you're in the `InsightSpike-AI` directory\n",
    "3. **Re-run Installation**: Run the dependency installation cell again\n",
    "\n",
    "#### 4. **GPU Not Detected**\n",
    "**Issue**: `CUDA Available: False`\n",
    "\n",
    "**Solutions**:\n",
    "- **Enable GPU**: `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
    "- **Don't worry**: InsightSpike-AI works perfectly on CPU too!\n",
    "\n",
    "#### 5. **Out of Memory**\n",
    "**Error**: CUDA out of memory or system memory errors\n",
    "\n",
    "**Solutions**:\n",
    "- **Restart Runtime**: `Runtime > Restart Runtime`\n",
    "- **Use CPU**: The system has CPU fallback built-in\n",
    "- **Reduce batch size**: Modify config parameters\n",
    "\n",
    "### üÜò Still Having Issues?\n",
    "\n",
    "1. **Run the Verification Cell** above to get detailed diagnostics\n",
    "2. **Restart Runtime** and try setup again from Step 1\n",
    "3. **Check GitHub Issues**: https://github.com/miyauchikazuyoshi/InsightSpike-AI/issues\n",
    "\n",
    "---\n",
    "\n",
    "## üìä System Information\n",
    "\n",
    "Run this cell for detailed system diagnostics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ff2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "print(\"üîç System Diagnostic Report\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Environment info\n",
    "print(f\"üêç Python: {sys.version}\")\n",
    "print(f\"üíª Platform: {platform.platform()}\")\n",
    "print(f\"üìÇ Working Dir: {os.getcwd()}\")\n",
    "\n",
    "# Check if in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"‚òÅÔ∏è  Environment: Google Colab\")\n",
    "except ImportError:\n",
    "    print(\"üíª Environment: Local/Other\")\n",
    "\n",
    "# Memory info\n",
    "try:\n",
    "    import psutil\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"üíæ RAM: {memory.total / 1e9:.1f} GB total, {memory.available / 1e9:.1f} GB available\")\n",
    "except ImportError:\n",
    "    print(\"üíæ RAM: psutil not available\")\n",
    "\n",
    "# GPU info\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"üéÆ PyTorch: {torch.__version__}\")\n",
    "    print(f\"üéÆ CUDA Available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "except ImportError:\n",
    "    print(\"üéÆ PyTorch: Not installed\")\n",
    "\n",
    "# Directory contents\n",
    "if os.path.exists('InsightSpike-AI'):\n",
    "    print(\"\\nüìÅ InsightSpike-AI Directory:\")\n",
    "    contents = os.listdir('InsightSpike-AI')\n",
    "    for item in sorted(contents)[:15]:  # Show first 15 items\n",
    "        item_path = os.path.join('InsightSpike-AI', item)\n",
    "        item_type = \"üìÅ\" if os.path.isdir(item_path) else \"üìÑ\"\n",
    "        print(f\"   {item_type} {item}\")\n",
    "    if len(contents) > 15:\n",
    "        print(f\"   ... and {len(contents) - 15} more items\")\n",
    "else:\n",
    "    print(\"\\n‚ùå InsightSpike-AI directory not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
