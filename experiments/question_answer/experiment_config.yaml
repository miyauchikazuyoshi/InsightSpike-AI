# Question-Answer Experiment Configuration

experiment:
  name: "question_answer"
  description: "Evaluate InsightSpike's ability to generate insights with 500 knowledge entries and 100 questions"
  seed: 42  # For reproducibility
  
# Data configuration
data:
  knowledge_base_path: "data/input/knowledge_base/knowledge_500.json"
  questions_path: "data/input/questions/questions_100.json"
  output_dir: "results/outputs"
  snapshot_dir: "data_snapshots"
  
# Model configuration
model:
  provider: "anthropic"
  model: "claude-3-sonnet-20240229"
  temperature: 0.7
  max_tokens: 1000
  api_key: "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"
      
# InsightSpike configuration
insightspike:
  datastore:
    type: "filesystem"
    base_path: "data/experiment_temp"
  memory:
    max_episodes: 1000
    vector_dim: 384
  graph:
    enable_message_passing: true
    message_passing:
      alpha: 0.3
      iterations: 2
      max_hops: 2  # Enable 2-hop evaluation
    enable_graph_search: true
    algorithms:
      metrics:
        ged: "advanced"  # Use gedig_core for multihop support
        ig: "advanced"   # Use gedig_core for multihop support
    metrics:
      use_multihop_gedig: true
      max_hops: 2
      decay_factor: 0.5  # Weight decay for 2nd hop
  spike_detection:
    ged_threshold: -0.5
    ig_threshold: 0.2
  algorithms:
    gedig:
      w1: 0.5
      kT: 1.0
      
      # Enable normalization for testing
      normalization:
        enabled: true  # 二段階正規化を有効
        mode: "conservation"
        
        # Three main parameters
        size_normalization:
          beta: 0.5  # Node weight coefficient
          
        reward:
          lambda_ig: 1.0  # IG coefficient
          mu_ged: 0.5     # GED coefficient
          
        # Sign consistency check
        spike_detection:
          mode: "threshold"
          threshold: 0.3  # Spike when R < 0.3
          
        # Z-transform settings
        z_transform:
          use_running_stats: true
          window_size: 100
    
# Experiment parameters
parameters:
  total_knowledge: 500
  total_questions: 100
  question_distribution:
    easy: 30
    medium: 40
    hard: 20
    very_hard: 10
  
# Evaluation settings
evaluation:
  metrics:
    - "accuracy"
    - "spike_rate"
    - "processing_time"
    - "memory_usage"
    - "insight_quality"
  human_evaluation:
    enabled: false  # Set to true for manual evaluation
    criteria:
      - "correctness"
      - "creativity"
      - "coherence"
      
# Output configuration
output:
  formats: ["json", "csv"]
  save_vectors: true
  save_prompts: true
  save_intermediate: true
  
# Branching detection settings
branching:
  enabled: true
  threshold: 0.8
  min_branches: 2
  max_gap: 0.15
  
# Logging configuration
logging:
  level: "INFO"
  save_conversations: true
  save_graphs: true
  save_metrics: true