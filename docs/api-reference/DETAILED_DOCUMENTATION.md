# Detailed Documentation

This document contains comprehensive information about InsightSpike-AI's implementation, configuration, and advanced features.

## ğŸ“ Project Structure

```text
InsightSpike-AI/
â”œâ”€â”€ src/insightspike/           # Core 4-layer architecture implementation
â”‚   â”œâ”€â”€ core/                   # InsightSpikeSystem, Memory Manager, Graph Reasoner
â”‚   â”œâ”€â”€ models/                 # geDIG algorithm, neural networks, vector quantization
â”‚   â”œâ”€â”€ memory/                 # FAISS-indexed episodic memory with C-value weighting
â”‚   â”œâ”€â”€ graph/                  # PyTorch Geometric GNN reasoning
â”‚   â””â”€â”€ utils/                  # Utilities and helper functions
â”œâ”€â”€ scripts/                    # Production utilities & enterprise tools
â”‚   â”œâ”€â”€ debugging/              # System diagnostics
â”‚   â”œâ”€â”€ testing/                # Component tests
â”‚   â”œâ”€â”€ validation/             # Quality assurance
â”‚   â”œâ”€â”€ production/             # Production deployment tools
â”‚   â”œâ”€â”€ utilities/              # Data restore
â”‚   â”œâ”€â”€ ci/                     # CI support
â”‚   â””â”€â”€ git-hooks/              # Pre-push validation automation
â”œâ”€â”€ monitoring/                 # Real-time system monitoring
â”‚   â”œâ”€â”€ production_monitor.py   # System health metrics
â”‚   â””â”€â”€ performance_dashboard.py # Web dashboard
â”œâ”€â”€ templates/                  # Production integration templates
â”‚   â”œâ”€â”€ production_integration_template.py
â”‚   â””â”€â”€ generated/              # Enterprise, Research, Educational, Content, Real-time
â”œâ”€â”€ benchmarks/                 # Performance benchmarking suite
â”‚   â”œâ”€â”€ performance_suite.py    # Comprehensive testing
â”‚   â””â”€â”€ results/                # Benchmark execution history
â”œâ”€â”€ data/                       # Core data & enterprise backup system
â”‚   â”œâ”€â”€ clean_backup/           # Clean state backup & restore
â”‚   â”œâ”€â”€ episodes.json           # Episode memory
â”‚   â”œâ”€â”€ graph_pyg.pt            # PyTorch graph data
â”‚   â”œâ”€â”€ index.faiss             # FAISS vector index
â”‚   â”œâ”€â”€ index.json              # Metadata index
â”‚   â””â”€â”€ *.db                    # SQLite databases
â”œâ”€â”€ english_insight_experiment/ # Latest experimental results
â”œâ”€â”€ docs/                       # Documentation & research
â”œâ”€â”€ experiments/                # Research validation & analysis
â””â”€â”€ tests/                      # Comprehensive test suite
```

## âš™ï¸ Configuration & Settings

### ğŸ“„ YAML Configuration File

InsightSpike-AI uses flexible configuration management:

#### **Configuration Locations**

1. **User Home** (Personal settings):
   ```bash
   ~/.insightspike/config.yaml
   ```

2. **Project Root** (Project-specific):
   ```bash
   ./config.yaml
   export INSIGHTSPIKE_CONFIG_PATH="./config.yaml"
   ```

3. **Custom Path** (Environment-specific):
   ```bash
   export INSIGHTSPIKE_CONFIG_PATH="/path/to/your/config.yaml"
   ```

### ğŸ”§ Configuration Sections

#### **Core Language Model Settings**

```yaml
core:
  model_name: "paraphrase-MiniLM-L6-v2"  # Embedding model (384-dim)
  llm_provider: "local"                   # local, openai, anthropic
  llm_model: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  max_tokens: 256                         # LLM response length
  temperature: 0.3                        # Response creativity (0.0-1.0)
  device: "cpu"                          # cpu, cuda, mps
  use_gpu: false                         # Enable GPU acceleration
  safe_mode: false                       # Use mock providers for testing
```

#### **Memory System Configuration**

```yaml
memory:
  max_retrieved_docs: 15                 # Maximum documents per retrieval
  short_term_capacity: 10                # Recent interactions buffer
  working_memory_capacity: 20            # Active processing capacity
  episodic_memory_capacity: 60           # Long-term episode storage
  pattern_cache_capacity: 15             # Pattern recognition cache
```

#### **geDIG Algorithm Parameters**

```yaml
reasoning:
  # Core geDIG Weights
  weight_ged: 1.0                       # Graph Edit Distance weight
  weight_ig: 1.0                        # Information Gain weight
  weight_conflict: 0.5                  # Conflict detection weight
  
  # Episode Integration (Smart Memory)
  episode_integration_similarity_threshold: 0.85  # Vector similarity â‰¥ 0.85
  episode_integration_content_threshold: 0.4      # Content overlap â‰¥ 0.4
  episode_integration_c_threshold: 0.3            # C-value difference â‰¤ 0.3
  
  # Episode Management
  episode_merge_threshold: 0.8          # Merge similar episodes
  episode_split_threshold: 0.3          # Split conflicting episodes
  episode_prune_threshold: 0.1          # Remove low-value episodes
```

#### **Graph Processing & Spike Detection**

```yaml
graph:
  spike_ged_threshold: 0.5              # GED threshold for "Aha!" moments
  spike_ig_threshold: 0.2               # IG threshold for insights
  use_gnn: false                        # Enable Graph Neural Networks
  gnn_hidden_dim: 64                    # GNN layer dimensions
```

### ğŸ›ï¸ Configuration Priority

Settings are applied in the following order (later overrides earlier):

1. **Default Values** (`src/insightspike/core/config.py`)
2. **YAML File** (`~/.insightspike/config.yaml`)
3. **Environment Variables** (`INSIGHTSPIKE_*`)
4. **CLI Arguments** (`--option value`)

### ğŸ“‹ Configuration Presets

**Research Mode (High Accuracy):**
```yaml
retrieval:
  top_k: 25
  similarity_threshold: 0.25
reasoning:
  episode_integration_similarity_threshold: 0.9
  weight_ged: 1.2
  weight_ig: 1.2
```

**Production Mode (Fast Response):**
```yaml
retrieval:
  top_k: 10
  similarity_threshold: 0.4
reasoning:
  episode_integration_similarity_threshold: 0.8
processing:
  batch_size: 16
  timeout_seconds: 120
```

**Educational Mode (Explainable):**
```yaml
output:
  verbose: true
  generate_visualizations: true
  save_results: true
core:
  temperature: 0.5
reasoning:
  weight_conflict: 0.8  # Emphasize conflict detection
```

## ğŸ”§ Advanced Usage

### CLI Command Reference

#### New Improved CLI (`spike`) - Recommended âœ¨

```bash
# Query the knowledge base
poetry run spike query "What is quantum computing?"
poetry run spike q "What is quantum computing?"  # alias

# Embed documents into the knowledge base (with graph updates)
poetry run spike embed path/to/documents.txt
poetry run spike e path/to/documents.txt  # alias

# Interactive chat mode
poetry run spike chat
poetry run spike c  # alias

# Configuration management
poetry run spike config show                    # Show current config
poetry run spike config set safe_mode false     # Change settings
poetry run spike config preset experiment       # Use preset
poetry run spike config save my_config.json    # Save config
poetry run spike config load my_config.json    # Load config

# Show statistics and insights
poetry run spike stats                         # Agent statistics
poetry run spike insights                      # Show discovered insights
poetry run spike insights-search "quantum"     # Search insights by concept

# Interactive demo
poetry run spike demo                          # Run guided demo

# Run experiments
poetry run spike experiment --name simple --episodes 10
poetry run spike experiment --name insight --episodes 5
poetry run spike experiment --name math --episodes 7

# Show version and help
poetry run spike version                       # Version info
poetry run spike --help                        # Show all commands
```

#### Legacy CLI (`insightspike`) - Limited Functionality

```bash
# Basic commands (with deprecation warnings)
poetry run insightspike legacy-ask "What is quantum computing?"
poetry run insightspike legacy-stats

# Limited functionality commands
poetry run insightspike load-documents path/to/documents.txt  # No graph update
poetry run insightspike config-info                           # Show config
poetry run insightspike deps list                            # Dependency management

# Show help
poetry run insightspike --help
```

### Python API Reference

#### Standard Data Management for Experiments

```python
import shutil
from datetime import datetime

# 1. Backup existing data before experiment
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
shutil.copytree("data", f"data_backup_{timestamp}")

# 2. Initialize fresh agent for clean experiment
agent = MainAgent()
agent.initialize()

# 3. Run your experiment
# ... experiment code ...

# 4. Save experiment results
experiment_results = {
    "timestamp": timestamp,
    "metrics": agent.get_stats(),
    # ... other results ...
}

# 5. Optionally restore original data
# shutil.rmtree("data")
# shutil.copytree(f"data_backup_{timestamp}", "data")
```

#### Data Growth Example

```python
from insightspike.core.agents.main_agent import MainAgent

agent = MainAgent()
agent.initialize()

# Load test data
documents = [
    "Machine learning is a subset of artificial intelligence.",
    "Deep learning uses neural networks with multiple layers.",
    "Transformers revolutionized natural language processing."
]

# Add with graph updates
for doc in documents:
    result = agent.add_episode_with_graph_update(doc)
    if result['success']:
        print(f"âœ“ Added: {doc[:50]}...")

# Check growth
initial_stats = agent.get_stats()
print(f"Total episodes: {initial_stats['episodes']}")
print(f"Graph nodes: {initial_stats['graph_nodes']}")

# MUST save to persist
agent.save_state()
```

### Key API Differences

| Feature | CLI | Python API |
|---------|-----|------------|
| Add documents | âœ“ | âœ“ |
| Update graph | âœ— | âœ“ (with `add_episode_with_graph_update`) |
| Save data | âœ— | âœ“ (with `save_state`) |
| Query processing | âœ“ | âœ“ |
| Full control | âœ— | âœ“ |

### Data Storage Structure

InsightSpike-AI uses a structured data directory system:

- `data/episodes.json` - Episode memory (text, embeddings, metadata)
- `data/graph_pyg.pt` - PyTorch Geometric graph structure
- `data/index.faiss` - FAISS vector index for similarity search
- `data/insight_facts.db` - SQLite database for discovered insights
- `data/learning/` - Auto-learning system data

## ğŸ”§ Development Setup

### Enable Pre-Push Validation

```bash
# Enable pre-push validation (recommended for contributors)
cp scripts/git-hooks/pre-push .git/hooks/
chmod +x .git/hooks/pre-push

# Restore clean data state if needed
python scripts/utilities/restore_clean_data.py

# Monitor system health
python monitoring/production_monitor.py

# Run performance benchmarks
python benchmarks/performance_suite.py
```

### Environment Troubleshooting

**Common Issues & Solutions:**

**1. CLI commands not found:**
```bash
# Make sure you're in Poetry shell
poetry shell
spike --help

# OR use poetry run prefix
poetry run spike --help

# If still not working, reinstall
poetry install
```

**2. Import errors in local development:**
```bash
# Activate Poetry environment first
poetry shell
# OR run commands within Poetry environment
poetry run python your_script.py
poetry run jupyter lab

# Manual PYTHONPATH (fallback only)
export PYTHONPATH="${PYTHONPATH}:/path/to/InsightSpike-AI/src"
```

**3. Version conflicts (especially NumPy/PyTorch):**
```bash
# Check conflicting versions
pip check

# Clean reinstall
poetry lock --no-update
poetry install
```

**4. Package installation fails:**
```bash
# Update pip and poetry
pip install --upgrade pip poetry poetry-core

# Clean Poetry cache
poetry cache clear --all pypi

# Alternative installation
pip install torch torchvision torchaudio faiss-cpu typer click pydantic
pip install -e .
```

## ğŸ“Š Experimental Results Details

### ğŸ¯ Latest Production Validation (January 2025)

#### **Integrated Production System**

- âœ… **Data Integrity**: Clean backup system with 5 core data files validated
- âœ… **Monitoring Infrastructure**: Production-ready system health monitoring
- âœ… **Git Integration**: Pre-push validation hooks ensure code quality
- âœ… **Production Templates**: 5 deployment scenarios validated
- âœ… **Performance Benchmarking**: CI-compatible testing suite

#### **Core System Validation Results**

**Architecture Component Testing:**

- ğŸ”§ **Memory Manager**: Episode integration thresholds (0.85 similarity, 0.7 content) validated
- ğŸ“Š **Graph Reasoner**: PyTorch Geometric implementation with 1-node baseline
- âš¡ **Vector Search**: FAISS-indexed 384-dimensional embeddings optimized
- ğŸ¯ **System Integration**: All 4 layers functioning in production environment

#### **Smart Episode Integration**

- **Threshold-based Decision**: Vector similarity â‰¥ 0.85, Content overlap â‰¥ 0.7
- **Integration Score**: 0.5Ã—Similarity + 0.3Ã—Content + 0.2Ã—C-Value
- **Dynamic Memory**: FAISS-indexed efficient search with C-value weighting

### ğŸ“Š Historical Experimental Results

**Proof-of-Concept Validation (2025-06-30):**

- **Performance Improvement**: +133.3% quality increase in controlled experiments
- **Insight Detection**: Unique capability demonstrated vs baseline systems
- **Processing Efficiency**: Significant speed improvements observed
- **Statistical Confidence**: Results significant at p < 0.001 level

## ğŸ—ï¸ Technical Architecture Details

### Core Architecture Layers

1. **Error Monitor** (Cerebellum analog) - Query analysis and validation
2. **Memory Manager** (Hippocampus analog) - Graph-centric episodic memory (C-value free)
3. **Graph Reasoner** (Prefrontal cortex analog) - Scalable PyTorch Geometric GNN with geDIG
4. **Language Interface** (Language area analog) - Natural language synthesis and interaction

### Scalable Graph Implementation

**Hierarchical Architecture for Large-Scale Processing:**

```text
IntegratedHierarchicalManager
â”œâ”€â”€ GraphCentricMemoryManager (Episode Management)
â”‚   â”œâ”€â”€ Dynamic importance from graph structure
â”‚   â”œâ”€â”€ Graph-informed integration/splitting
â”‚   â””â”€â”€ No C-values - pure graph-based
â””â”€â”€ HierarchicalGraphBuilder (Scalable Search)
    â”œâ”€â”€ Level 0: Individual episodes
    â”œâ”€â”€ Level 1: Topic clusters (âˆšn size)
    â””â”€â”€ Level 2: Super-clusters
```

**Performance Characteristics:**

| Dataset Size | Build Time | Search Time | Compression |
|-------------|------------|-------------|-------------|
| 1,000       | 150ms      | 0.5ms       | 100x        |
| 10,000      | 1.5s       | 2ms         | 200x        |
| 100,000     | 15s        | 5ms         | 500x        |

### Key Technologies

- **geDIG Algorithm**: Graph Edit Distance + Information Gain for insight detection
- **Scalable Graph Builder**: FAISS-based O(n log n) construction, O(log n) search
- **Graph-Centric Memory**: Dynamic importance, no C-values, self-attention-like behavior
- **Hierarchical Management**: 3-layer structure for 100K+ episode handling
- **Vector Quantization**: FAISS-indexed 384-dimensional embeddings
- **Dynamic Reasoning**: PyTorch Geometric graph neural networks

## ğŸ™ Acknowledgments

This research builds on insights from neuroscience, graph theory, and bio-inspired computing. Special thanks to the open-source community for foundational tools and libraries.