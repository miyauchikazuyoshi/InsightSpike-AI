# `InsightDecoder` Design Discussion

*Date: 2025-07-21*
*Status: Proposal*

## 1. The Problem: The "Evaluation Wall"

The `geDIG` metric is designed to quantify "insight" by measuring structural improvement and information integration in a knowledge graph. However, a major challenge is validating its output. How can we prove that a high `geDIG` score corresponds to a change that a human would perceive as a meaningful insight? Creating a large-scale, human-annotated ground truth dataset is difficult and expensive.

## 2. Core Concept: Analysis-by-Synthesis with geDIG

Instead of relying on external validation, we propose an internal, self-validating mechanism. We will treat `geDIG` not just as a passive metric, but as an **active, generative objective function**.

The core idea is **Analysis-by-Synthesis**: if our system can *synthesize* a human-readable explanation whose structure *analyzes* to a low-loss `geDIG` score, it demonstrates that the metric is aligned with meaningful, communicable concepts.

This leads to the design of the `InsightDecoder`.

## 3. Architecture: The `InsightDecoder`

The `InsightDecoder` is a component responsible for translating an abstract graph transformation (i.e., an "insight") into natural language.

**Components:**
- **LLM (`BaseLLM`)**: The text generator.
- **geDIG Calculator (`GeDIGCore`)**: The objective function, used as a "loss function".
- **NLP Parser (`spaCy`)**: A tool to convert generated text into a syntactic dependency graph.

## 4. Workflow: Iterative Generation and Refinement

The decoding process is an iterative loop that seeks to minimize the `geDIG` "loss" between a target graph and a graph synthesized from generated text.

1.  **Initial Prompt**: Start with a generic prompt asking the LLM to explain the conceptual leap from `graph_before` to `target_insight_graph`.
2.  **Generate**: The LLM generates a candidate text explanation.
3.  **Synthesize Graph**: The candidate text is parsed by `spaCy` to create a syntactic dependency graph (`generated_graph`). This graph represents the structure of the explanation.
4.  **Evaluate (Calculate Loss)**: `geDIG` is calculated between the `generated_graph` and the `target_insight_graph`. A lower `geDIG` value means the text's structure is a better representation of the insight's structure.
5.  **Refine Prompt**: The prompt for the next iteration is updated based on the `geDIG` score.
6.  **Loop**: Repeat for `max_iterations` or until the "loss" converges.

## 5. Key Innovation: Meta-Cognitive Prompt Refinement

To make the refinement process more "life-like" and intelligent, we will implement a meta-cognitive feedback loop. Instead of simply trying a new angle on failure, we ask the LLM to analyze its own failure.

```python
# ... inside the loop ...
if current_gedig < min_gedig:
    # Positive reinforcement: build on what worked
    min_gedig = current_gedig
    best_text = candidate_text
    prompt = f"This is a good explanation: '{best_text}'. Refine it to be even more clear and structured, focusing on the connection between concepts."
else:
    # Meta-cognitive refinement: ask the LLM to analyze its own failure
    failure_analysis_prompt = f"The explanation '{candidate_text}' did not structurally match the target insight. What was wrong with its structure? Suggest a better angle to explain the connection."
    analysis = self.llm.generate(failure_analysis_prompt)
    print(f"DEBUG: Failure analysis by LLM: {analysis}")
    prompt = f"Previous attempt was flawed. New angle based on analysis: {analysis}. Now, explain the conceptual leap from graph A to B."
```

This forces the LLM to reason about *why* its explanation was structurally poor, leading to more targeted and intelligent refinement in the next step.

## 6. Implications

This approach addresses the "Evaluation Wall" by:
- **Creating a self-contained validation loop**: The system uses its own first principles (`geDIG`) to generate and validate its outputs.
- **Providing an interpretable "decoding"**: It gives us a way to understand what the abstract graph changes "mean" in natural language.
- **Turning `geDIG` into a creative force**: The metric is no longer just for analysis; it actively drives the synthesis of new, structured information.

## 7. Next Steps

1.  Implement the `InsightDecoder` class in `src/insightspike/synthesis/decoder.py`.
2.  Integrate `spaCy` for text-to-graph conversion.
3.  Develop a robust prompt engineering strategy for the meta-cognitive loop.
4.  Create an experiment to test the decoder's ability to generate coherent explanations for known graph transformations.

